{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vi2LlIiMU2dp"
   },
   "source": [
    "# Weights & Biasesã§ChatGPT-3.5ã¨GPT-4ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹\n",
    "\n",
    "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{openai-finetune-gpt35} -->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/Fine_tune_GPT_3_with_Weights_&_Biases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "**æ³¨æ„:** ã“ã®colabã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯[OpenAI APIã‚­ãƒ¼](https://platform.openai.com/account/api-keys)ãŒå¿…è¦ã§ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OKB1NaA3U2dp"
   },
   "source": [
    "OpenAIã®APIã‚’ä½¿ç”¨ã—ã¦[ChatGPT-3.5ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](https://platform.openai.com/docs/guides/fine-tuning)ã™ã‚‹å ´åˆã€W&Bçµ±åˆã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸­å¤®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§è¿½è·¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "å¿…è¦ãªã®ã¯ãŸã£ãŸ1è¡Œã®ã‚³ãƒãƒ³ãƒ‰ã§ã™ï¼š`openai wandb sync`\n",
    "\n",
    "çµ±åˆã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€Weights & Biasesãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®[OpenAIã‚»ã‚¯ã‚·ãƒ§ãƒ³](https://wandb.me/openai-docs)ã‚’ã”è¦§ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AebZsbWrU2dp"
   },
   "outputs": [],
   "source": [
    "!pip install -Uq openai tiktoken datasets tenacity wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_qbldX6U2dq"
   },
   "outputs": [],
   "source": [
    "# Remove once this PR is merged: https://github.com/openai/openai-python/pull/590 and openai release is made\n",
    "!pip uninstall -y openai -qq \\\n",
    "&& pip install git+https://github.com/morganmcg1/openai-python.git@update_wandb_logger -qqq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "STVFg2SMU2dq"
   },
   "source": [
    "## ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ChatGPT-3.5ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "\n",
    "è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å®Ÿé¨“ã™ã‚‹æ–¹ãŒå¸¸ã«æ¥½ã—ã„ã‚‚ã®ã§ã™ã€‚æ—¢ã«OpenAI APIã‚’ä½¿ç”¨ã—ã¦OpenAIãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ãŸã“ã¨ãŒã‚ã‚‹å ´åˆã¯ã€ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ãã†ã§ãªã‘ã‚Œã°ã€æ³•å¾‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ChatGPT-3.5ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0G1keRuTU2dq"
   },
   "source": [
    "### ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆæœŸè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpRQxo1QU2dq"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X7h1WmYRU2dr"
   },
   "source": [
    "Weights & Biasesã®å®Ÿè¡Œã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãŠæŒã¡ã§ãªã„å ´åˆã¯ã€www.wandb.ai ã§ç„¡æ–™ã§ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5fPfbPCU2dr"
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"OpenAI-Fine-Tune\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AKc9uwv_U2dr"
   },
   "source": [
    "### APIã‚­ãƒ¼ã®è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDs2cWLfU2dr"
   },
   "outputs": [],
   "source": [
    "# # Enter credentials\n",
    "openai_key = \"YOUR_API_KEY\"\n",
    "\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YQhM025QU2dr"
   },
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™\n",
    "\n",
    "æ³•çš„æ¨è«–ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚‹[LegalBench](https://hazyresearch.stanford.edu/legalbench/)ã‹ã‚‰ã€å…·ä½“çš„ã«ã¯[Contract NLI Explicit Identification task](https://github.com/HazyResearch/legalbench/tree/main/tasks/contract_nli_explicit_identification)ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã¯åˆè¨ˆ117ã®ä¾‹ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã‹ã‚‰ç‹¬è‡ªã®è¨“ç·´ç”¨ãŠã‚ˆã³ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THyWwbMyU2ds"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Download the data, merge into a single dataset and shuffle\n",
    "dataset = load_dataset(\"nguha/legalbench\", \"contract_nli_explicit_identification\")\n",
    "\n",
    "data = []\n",
    "for d in dataset[\"train\"]:\n",
    "  data.append(d)\n",
    "\n",
    "for d in dataset[\"test\"]:\n",
    "  data.append(d)\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "for idx, d in enumerate(data):\n",
    "  d[\"new_index\"] = idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JPDSyx9AU2ds"
   },
   "source": [
    "ã„ãã¤ã‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6NZj5SZU2ds",
    "outputId": "527c1836-cb2b-474d-c0c6-d646e4fd087b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,\n",
       " [{'answer': 'No',\n",
       "   'index': '94',\n",
       "   'text': 'Recipient shall use the Confidential Information exclusively for HySafe purposes, especially to advice the Governing Board of HySafe. ',\n",
       "   'document_name': 'NDA_V3.pdf',\n",
       "   'new_index': 0},\n",
       "  {'answer': 'No',\n",
       "   'index': '53',\n",
       "   'text': '3. In consideration of each and every disclosure of CONFIDENTIAL INFORMATION, the Parties agree to: (c) make no disclosures of any CONFIDENTIAL INFORMATION to any party other than officers and employees of a Party to this IRA; (d) limit access to CONFIDENTIAL INFORMATION to those officers and employees having a reasonable need for such INFORMATION and being boUnd by a written obligation to maintain the confidentiality of such INFORMATION; and ',\n",
       "   'document_name': '1084000_0001144204-06-046785_v056501_ex10-16.txt',\n",
       "   'new_index': 1}])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), data[0:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VSUkLGT0U2ds"
   },
   "source": [
    "### ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n",
    "LegalBenchã‚¿ã‚¹ã‚¯ã®`base_prompt`ã‚’ä¿®æ­£ã—ã¦ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€few-shotãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ä»£ã‚ã‚Šã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPCxFBbEU2ds"
   },
   "outputs": [],
   "source": [
    "base_prompt_zero_shot = \"Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jJFhwJjXU2ds"
   },
   "source": [
    "æ¬¡ã«ã€ã“ã‚Œã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚30ã‚µãƒ³ãƒ—ãƒ«ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€æ®‹ã‚Šã§ãƒ†ã‚¹ãƒˆã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-2oiwxIU2ds"
   },
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "n_test = len(data) - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYhlg7wJU2ds",
    "outputId": "c0121d63-7c1e-48cd-82c7-b9efeb663df5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " 87,\n",
       " 87,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`'},\n",
       "   {'role': 'user',\n",
       "    'content': '2. The Contractor shall not, without the Stateâ€™s prior written consent, copy, disclose, publish, release, transfer, disseminate, use, or allow access for any purpose or in any form, any Confidential Information except for the sole and exclusive purpose of performing under the Contract.  '},\n",
       "   {'role': 'assistant', 'content': 'No'}]})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_messages = []\n",
    "test_messages = []\n",
    "\n",
    "for d in data:\n",
    "  prompts = []\n",
    "  prompts.append({\"role\": \"system\", \"content\": base_prompt_zero_shot})\n",
    "  prompts.append({\"role\": \"user\", \"content\": d[\"text\"]})\n",
    "  prompts.append({\"role\": \"assistant\", \"content\": d[\"answer\"]})\n",
    "\n",
    "  if int(d[\"new_index\"]) < n_train:\n",
    "    train_messages.append({'messages': prompts})\n",
    "  else:\n",
    "    test_messages.append({'messages': prompts})\n",
    "\n",
    "len(train_messages), len(test_messages), n_test, train_messages[5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ul1lOV8U2dt"
   },
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã‚’Weights & Biasesã«ä¿å­˜ã™ã‚‹\n",
    "\n",
    "ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ã‚’trainãƒ•ã‚¡ã‚¤ãƒ«ã¨testãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_kbcPDtU2dt"
   },
   "outputs": [],
   "source": [
    "train_file_path = 'encoded_train_data.jsonl'\n",
    "with open(train_file_path, 'w') as file:\n",
    "    for item in train_messages:\n",
    "        line = json.dumps(item)\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "test_file_path = 'encoded_test_data.jsonl'\n",
    "with open(test_file_path, 'w') as file:\n",
    "    for item in test_messages:\n",
    "        line = json.dumps(item)\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C58GZECzU2dt"
   },
   "source": [
    "æ¬¡ã«ã€[OpenAI fine-tuning documentation](https://platform.openai.com/docs/guides/fine-tuning/)ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ã„å½¢å¼ã«ãªã£ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awSfo7T4U2dt"
   },
   "outputs": [],
   "source": [
    "# Next, we specify the data path and open the JSONL file\n",
    "\n",
    "def openai_validate_data(dataset_path):\n",
    "  data_path = dataset_path\n",
    "\n",
    "  # Load dataset\n",
    "  with open(data_path) as f:\n",
    "      dataset = [json.loads(line) for line in f]\n",
    "\n",
    "  # We can inspect the data quickly by checking the number of examples and the first item\n",
    "\n",
    "  # Initial dataset stats\n",
    "  print(\"Num examples:\", len(dataset))\n",
    "  print(\"First example:\")\n",
    "  for message in dataset[0][\"messages\"]:\n",
    "      print(message)\n",
    "\n",
    "  # Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
    "\n",
    "  # Format error checks\n",
    "  format_errors = defaultdict(int)\n",
    "\n",
    "  for ex in dataset:\n",
    "      if not isinstance(ex, dict):\n",
    "          format_errors[\"data_type\"] += 1\n",
    "          continue\n",
    "\n",
    "      messages = ex.get(\"messages\", None)\n",
    "      if not messages:\n",
    "          format_errors[\"missing_messages_list\"] += 1\n",
    "          continue\n",
    "\n",
    "      for message in messages:\n",
    "          if \"role\" not in message or \"content\" not in message:\n",
    "              format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "          if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "              format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "              format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "          content = message.get(\"content\", None)\n",
    "          if not content or not isinstance(content, str):\n",
    "              format_errors[\"missing_content\"] += 1\n",
    "\n",
    "      if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "          format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "  if format_errors:\n",
    "      print(\"Found errors:\")\n",
    "      for k, v in format_errors.items():\n",
    "          print(f\"{k}: {v}\")\n",
    "  else:\n",
    "      print(\"No errors found\")\n",
    "\n",
    "  # Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
    "\n",
    "  # Token counting functions\n",
    "  encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "  # not exact!\n",
    "  # simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "  def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += tokens_per_message\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":\n",
    "                  num_tokens += tokens_per_name\n",
    "      num_tokens += 3\n",
    "      return num_tokens\n",
    "\n",
    "  def num_assistant_tokens_from_messages(messages):\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          if message[\"role\"] == \"assistant\":\n",
    "              num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "      return num_tokens\n",
    "\n",
    "  def print_distribution(values, name):\n",
    "      print(f\"\\n#### Distribution of {name}:\")\n",
    "      print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "      print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "      print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "  # Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
    "\n",
    "  # Warnings and tokens counts\n",
    "  n_missing_system = 0\n",
    "  n_missing_user = 0\n",
    "  n_messages = []\n",
    "  convo_lens = []\n",
    "  assistant_message_lens = []\n",
    "\n",
    "  for ex in dataset:\n",
    "      messages = ex[\"messages\"]\n",
    "      if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "          n_missing_system += 1\n",
    "      if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "          n_missing_user += 1\n",
    "      n_messages.append(len(messages))\n",
    "      convo_lens.append(num_tokens_from_messages(messages))\n",
    "      assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "  print(\"Num examples missing system message:\", n_missing_system)\n",
    "  print(\"Num examples missing user message:\", n_missing_user)\n",
    "  print_distribution(n_messages, \"num_messages_per_example\")\n",
    "  print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "  print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "  n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "  print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "  # Pricing and default n_epochs estimate\n",
    "  MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "  MIN_TARGET_EXAMPLES = 100\n",
    "  MAX_TARGET_EXAMPLES = 25000\n",
    "  TARGET_EPOCHS = 3\n",
    "  MIN_EPOCHS = 1\n",
    "  MAX_EPOCHS = 25\n",
    "\n",
    "  n_epochs = TARGET_EPOCHS\n",
    "  n_train_examples = len(dataset)\n",
    "  if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "      n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "  elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "      n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "  n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "  print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "  print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "  print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "  print(\"See pricing page to estimate total costs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wmC69bJkU2dt"
   },
   "source": [
    "è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vej4HKR7U2dt",
    "outputId": "170ed230-8d7c-4e35-94d4-864db843beb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 30\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`'}\n",
      "{'role': 'user', 'content': 'Recipient shall use the Confidential Information exclusively for HySafe purposes, especially to advice the Governing Board of HySafe. '}\n",
      "{'role': 'assistant', 'content': 'No'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 69, 319\n",
      "mean / median: 143.46666666666667, 122.0\n",
      "p5 / p95: 82.10000000000001, 235.10000000000002\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 1, 1\n",
      "mean / median: 1.0, 1.0\n",
      "p5 / p95: 1.0, 1.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~4304 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~12912 tokens\n",
      "See pricing page to estimate total costs\n"
     ]
    }
   ],
   "source": [
    "openai_validate_data(train_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C83jxUI9U2dt"
   },
   "source": [
    "Weights & Biases Artifactsã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°ã—ã¦ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚’è¡Œã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ep-aT9NKU2dt",
    "outputId": "5d8fc8a3-8734-4878-b249-d7e9695fe584"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/examples/colabs/openai/wandb/run-20230830_113853-ivu21mjl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ivu21mjl' target=\"_blank\">mild-surf-1</a></strong> to <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ivu21mjl' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ivu21mjl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-surf-1</strong> at: <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ivu21mjl' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ivu21mjl</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230830_113853-ivu21mjl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    # entity=\"prompt-eng\",\n",
    "    job_type=\"log-data\",\n",
    "    config = {'n_train': n_train,\n",
    "              'n_valid': n_test})\n",
    "\n",
    "wandb.log_artifact(train_file_path,\n",
    "                   \"legalbench-contract_nli_explicit_identification-train\",\n",
    "                   type=\"train-data\")\n",
    "\n",
    "wandb.log_artifact(test_file_path,\n",
    "                   \"legalbench-contract_nli_explicit_identification-test\",\n",
    "                   type=\"test-data\")\n",
    "\n",
    "# keep entity (typically your wandb username) for reference of artifact later in this demo\n",
    "entity = wandb.run.entity\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hD2g6q3GU2dt"
   },
   "source": [
    "### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4MlVEQTaU2du"
   },
   "source": [
    "OpenAI APIã‚’ä½¿ç”¨ã—ã¦ChatGPT-3.5ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "\n",
    "ã¾ãšã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¨æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€`my_data`ã¨ã„ã†åå‰ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¾ã—ã‚‡ã†ã€‚ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®`latest`ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—ã—ã¾ã™ãŒã€`v0`ã€`v1`ã€ã¾ãŸã¯é–¢é€£ä»˜ã‘ãŸä»»æ„ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "dabd1490c65148978081fa0aedb0913b"
     ]
    },
    "id": "K54fvZFTU2du",
    "outputId": "adbcc0c2-c149-4dac-e7be-34253e66788e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabd1490c65148978081fa0aedb0913b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016751802766035932, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/examples/colabs/openai/wandb/run-20230830_113907-1ili9l51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/1ili9l51' target=\"_blank\">jumping-water-2</a></strong> to <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/1ili9l51' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/1ili9l51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'my_data/encoded_train_data.jsonl'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT,\n",
    "          #  entity=\"prompt-eng\",\n",
    "           job_type=\"finetune\")\n",
    "\n",
    "artifact_train = wandb.use_artifact(\n",
    "    f'{entity}/{WANDB_PROJECT}/legalbench-contract_nli_explicit_identification-train:latest',\n",
    "    type='train-data')\n",
    "train_file = artifact_train.get_path(train_file_path).download(\"my_data\")\n",
    "\n",
    "train_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh86AmJuU2du"
   },
   "source": [
    "ãã®å¾Œã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’OpenAIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚OpenAIãŒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã«å¿œã˜ã¦æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaviUxz7U2du",
    "outputId": "bf00b2e6-6045-4fca-be7d-9e3b0dd86421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-spPASR6VWco54SqfN2yo7T8v> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-spPASR6VWco54SqfN2yo7T8v\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 24059,\n",
       "  \"created_at\": 1693388388,\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_train_file_info = openai.File.create(\n",
    "  file=open(train_file, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "\n",
    "# you may need to wait a couple of minutes for OpenAI to process the file\n",
    "openai_train_file_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "woiHI6KoU2du"
   },
   "source": [
    "### ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ™‚é–“ã§ã™ï¼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YvP8ZGqWU2du"
   },
   "source": [
    "ChatGPT-3.5ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4sV1wohU2du"
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo'\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cju9ZZCZU2du",
    "outputId": "75155c4f-f260-4099-dac0-150a98dffc16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-x4tl83IlSGolkUF3fCFyZNGs> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-x4tl83IlSGolkUF3fCFyZNGs\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1693388447,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-WnF2wEqNkV1Nj65CzDxr6iUm\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"created\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-spPASR6VWco54SqfN2yo7T8v\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3\n",
       "  },\n",
       "  \"trained_tokens\": null\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_ft_job_info = openai.FineTuningJob.create(\n",
    "    training_file=openai_train_file_info[\"id\"],\n",
    "    model=model,\n",
    "    hyperparameters={\"n_epochs\": n_epochs}\n",
    ")\n",
    "\n",
    "ft_job_id = openai_ft_job_info[\"id\"]\n",
    "\n",
    "openai_ft_job_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dP68_bGSU2du"
   },
   "source": [
    "> ã“ã‚Œã¯è¨“ç·´ã«ç´„5åˆ†ã‹ã‹ã‚Šã€å®Œäº†ã™ã‚‹ã¨OpenAIã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ãŒå±Šãã¾ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X8R7ILU2du"
   },
   "source": [
    "**ä»¥ä¸Šã§ã™ï¼**\n",
    "\n",
    "ã“ã‚Œã§ã€ã‚ãªãŸã®ãƒ¢ãƒ‡ãƒ«ãŒOpenAIã®ãƒã‚·ãƒ³ä¸Šã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0os7HN9fU2du",
    "outputId": "f67adb43-c91d-4185-8fac-8d1a281a3666"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('succeeded',\n",
       " 12732,\n",
       " 1693389024,\n",
       " 'ft:gpt-3.5-turbo-0613:weights-biases::7tC85HcX')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = openai.FineTuningJob.retrieve(ft_job_id)\n",
    "state[\"status\"], state[\"trained_tokens\"], state[\"finished_at\"], state[\"fine_tuned_model\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "59RBnpywU2du"
   },
   "source": [
    "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®æœ€è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¡¨ç¤ºã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X0nX-5HU2du",
    "outputId": "b3a64f02-3fff-4bc1-b166-7783208ca1a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-5x9Y6Payk6fIdyJyMRY5um1v\",\n",
       "      \"created_at\": 1693389024,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tuning job successfully completed\",\n",
       "      \"data\": null,\n",
       "      \"type\": \"message\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-i16NTGNakv9P0RkOtJ7vvvoG\",\n",
       "      \"created_at\": 1693389022,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo-0613:weights-biases::7tC85HcX\",\n",
       "      \"data\": null,\n",
       "      \"type\": \"message\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-MkLrJQ8sDgaC67CdmFMwsIjV\",\n",
       "      \"created_at\": 1693389017,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Step 90/90: training loss=0.00\",\n",
       "      \"data\": {\n",
       "        \"step\": 90,\n",
       "        \"train_loss\": 2.5828578600339824e-06,\n",
       "        \"train_mean_token_accuracy\": 1.0\n",
       "      },\n",
       "      \"type\": \"metrics\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-3sRpTRSjK3TfFRZY88HEASpX\",\n",
       "      \"created_at\": 1693389015,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Step 89/90: training loss=0.00\",\n",
       "      \"data\": {\n",
       "        \"step\": 89,\n",
       "        \"train_loss\": 2.5828578600339824e-06,\n",
       "        \"train_mean_token_accuracy\": 1.0\n",
       "      },\n",
       "      \"type\": \"metrics\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-HtS6tJMVPOmazquZ82a1iCdV\",\n",
       "      \"created_at\": 1693389015,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Step 88/90: training loss=0.00\",\n",
       "      \"data\": {\n",
       "        \"step\": 88,\n",
       "        \"train_loss\": 2.5828578600339824e-06,\n",
       "        \"train_mean_token_accuracy\": 1.0\n",
       "      },\n",
       "      \"type\": \"metrics\"\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": true\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list_events(id=ft_job_id, limit=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q31LUKh3U2dv"
   },
   "source": [
    "ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„ã€ã•ã‚‰ã«ã¯ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ã„ãã¤ã‹ã®ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hCvmrDWMU2dv"
   },
   "source": [
    "## OpenAIãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’Weights & Biasesã«ãƒ­ã‚°ã™ã‚‹"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ehXJW997U2dv"
   },
   "source": [
    "ä»¥ä¸‹ã®ç°¡å˜ãªã‚³ãƒãƒ³ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "851RDhDBU2dv",
    "outputId": "6512e9ea-f58d-425f-d068-df405cc3ccd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: openai wandb sync [-h] [-i ID] [-n N_FINE_TUNES] [--project PROJECT]\n",
      "                         [--entity ENTITY] [--force] [--legacy]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i ID, --id ID        The id of the fine-tune job (optional)\n",
      "  -n N_FINE_TUNES, --n_fine_tunes N_FINE_TUNES\n",
      "                        Number of most recent fine-tunes to log when an id is\n",
      "                        not provided. By default, every fine-tune is synced.\n",
      "  --project PROJECT     Name of the Weights & Biases project where you're\n",
      "                        sending runs. By default, it is \"OpenAI-Fine-Tune\".\n",
      "  --entity ENTITY       Weights & Biases username or team name where you're\n",
      "                        sending runs. By default, your default entity is used,\n",
      "                        which is usually your username.\n",
      "  --force               Forces logging and overwrite existing wandb run of the\n",
      "                        same fine-tune.\n",
      "  --legacy              Log results from legacy OpenAI /v1/fine-tunes api\n"
     ]
    }
   ],
   "source": [
    "!openai wandb sync --help"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cfnhSQY1U2dv"
   },
   "source": [
    "`openai wandb sync`ã‚’å‘¼ã³å‡ºã™ã¨ã€ã™ã¹ã¦ã®æœªåŒæœŸã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ãŒW&Bã«ãƒ­ã‚°ã•ã‚Œã¾ã™\n",
    "\n",
    "ä»¥ä¸‹ã§ã¯1ã¤ã®ã‚¸ãƒ§ãƒ–ã®ã¿ã‚’ãƒ­ã‚°ã—ã¦ãŠã‚Šã€æ¬¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¦ã„ã¾ã™ï¼š\n",
    "- ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ã®OpenAIã‚­ãƒ¼\n",
    "- ãƒ­ã‚°ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®ID\n",
    "- ãƒ­ã‚°å…ˆã®W&Bãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "\n",
    "çµ±åˆã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€Weights & Biasesãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®[OpenAIã‚»ã‚¯ã‚·ãƒ§ãƒ³](https://wandb.me/openai-docs)ã‚’å‚ç…§ã—ã¦ãã ã•ã„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl58wxsfU2dv",
    "outputId": "acfe2d6d-3796-4c33-eb9e-7576ea7e69bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving fine-tune job...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/tcapelle/work/examples/colabs/openai/wandb/run-20230830_115915-ftjob-x4tl83IlSGolkUF3fCFyZNGs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mftjob-x4tl83IlSGolkUF3fCFyZNGs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/OpenAI-Fine-Tune\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ftjob-x4tl83IlSGolkUF3fCFyZNGs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy â–â–â–â–â–â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss â–ˆâ–‡â–†â–‚â–‚â–â–‚â–â–…â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: fine_tuned_model ft:gpt-3.5-turbo-061...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           status succeeded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_accuracy 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_loss 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mftjob-x4tl83IlSGolkUF3fCFyZNGs\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/capecape/OpenAI-Fine-Tune/runs/ftjob-x4tl83IlSGolkUF3fCFyZNGs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230830_115915-ftjob-x4tl83IlSGolkUF3fCFyZNGs/logs\u001b[0m\n",
      "ğŸ‰ wandb sync completed successfully\n"
     ]
    }
   ],
   "source": [
    "!OPENAI_API_KEY={openai_key} openai wandb sync --id {ft_job_id} --project {WANDB_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b21fd890682b4bf786b2346dd18cae9a"
     ]
    },
    "id": "LWHLs2oBU2dv",
    "outputId": "cd141916-2a25-43e7-a66b-3bc9cfe19df2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21fd890682b4bf786b2346dd18cae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.050 MB of 0.050 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n",
      "upload_file exception https://storage.googleapis.com/wandb-production.appspot.com/capecape/OpenAI-Fine-Tune/1ili9l51/requirements.txt?Expires=1693475972&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=NzF9wj2gS8rMEwRT9wlft2lNubemw67f2qrz9Zy90Bjxg5xCL9pIu%2FRbBGjRwLA2v64PuiP23Au5Dho26Tnw3UjUS1apqTkaOgjWDTlCCiDLzvMUsqHf0lhhWIgGMZcsA4gPpOi%2Bc%2ByJm4z6JE7D6RJ7r8y4fI0Jg6fX9KSWpzh8INiM6fQZiQjUChLVdtNJQZ2gfu7xRc%2BZIUEjgDuUqmS705pIUOgJXA9MS3%2Fhewkc7CxWay4ReMJixBZgaqLIRqHQnyzb38I5nPrRS3JrwrigQyX6tOsK05LDLA0o%2Bs0K11664%2F1ZxO6mSTfOaw7tXUmbUUWFOp33Qq8KXNz9Zg%3D%3D: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "upload_file request headers: {'User-Agent': 'python-requests/2.28.2', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '4902'}\n",
      "upload_file response body: \n",
      "upload_file exception https://storage.googleapis.com/wandb-production.appspot.com/capecape/OpenAI-Fine-Tune/1ili9l51/conda-environment.yaml?Expires=1693475972&GoogleAccessId=gorilla-files-url-signer-man%40wandb-production.iam.gserviceaccount.com&Signature=wKnFdg7z7CiJOMn4WSvt6GSj2hPnMr0Xc4KuwAXa8akLucmw700x%2FWF87jmWaqnp%2FK4%2BF6JTRghQAokXF9jxCcXBSYhgFhCVACrOVyN%2BSTZ4u8tDgD6Dm%2FEFwWObiH%2BALSS1N0FmG7i6kL9Evyng3yPc4noEz%2FkLNIDIascAPgUe9UkPaBCRc9j7OxzYJx07bpeL4HaGe4yaCvk2mSVr4l%2FUfsICBI6E4KKrLDvtZvFFFUB4MgqXp0Sxc0k0pOxaw9zZhiNQQELDnhnuNY4wi78EPiXN1BpU6bTgIYaHe5mkS%2B7M5HiFs83ML98JI2OeRiAjAGtIIETT4xDjTYWVpA%3D%3D: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "upload_file request headers: {'User-Agent': 'python-requests/2.28.2', 'Accept-Encoding': 'gzip, deflate, br', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8450'}\n",
      "upload_file response body: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-water-2</strong> at: <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/1ili9l51' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/1ili9l51</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230830_113907-1ili9l51/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eashAVIvU2dv"
   },
   "source": [
    "This is a great example of integrating OpenAI's fine-tuning capabilities with Weights & Biases for experiment tracking! The screenshot shows that your fine-tuned models are now successfully synced to your W&B dashboard.\n",
    "\n",
    "Here are some key benefits of this integration:\n",
    "\n",
    "## Experiment Tracking Benefits\n",
    "\n",
    "1. **Centralized Monitoring**: All your fine-tuning experiments are now visible in one dashboard\n",
    "2. **Performance Comparison**: You can easily compare different fine-tuned models side-by-side\n",
    "3. **Metrics Visualization**: Training metrics, validation scores, and other performance indicators are automatically logged\n",
    "4. **Reproducibility**: Complete experiment history with hyperparameters and results\n",
    "\n",
    "## What You Can Do Next\n",
    "\n",
    "With your fine-tunes synced to W&B, you can:\n",
    "\n",
    "- **Compare Models**: Use W&B's comparison tools to see which fine-tuning approach works best\n",
    "- **Track Performance**: Monitor how your models perform over time\n",
    "- **Share Results**: Easily share experiment results with your team\n",
    "- **Optimize Hyperparameters**: Use W&B's hyperparameter optimization tools for future fine-tuning runs\n",
    "\n",
    "## Automated Syncing\n",
    "\n",
    "The `openai wandb sync` command makes it easy to keep your dashboard up-to-date. You can:\n",
    "- Run it manually after each fine-tuning job\n",
    "- Integrate it into your training pipeline\n",
    "- Set up automated syncing for continuous monitoring\n",
    "\n",
    "This integration provides excellent visibility into your fine-tuning experiments and will help you make data-driven decisions about model performance and optimization strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xfX_af2EU2dz"
   },
   "source": [
    "## è©•ä¾¡ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9tvlkGoOU2dz"
   },
   "source": [
    "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹æœ€è‰¯ã®æ–¹æ³•ã¯ã€è©•ä¾¡ã‚»ãƒƒãƒˆã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã§ã™ã€‚\n",
    "\n",
    "ã„ãã¤ã‹ã®æ¨è«–ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã¦W&Bã«ãƒ­ã‚°ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ChatGPT-3.5ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SI00xE9nU2d0",
    "outputId": "1f01df3d-0360-49e8-c92e-40ea8df73639"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tcapelle/work/examples/colabs/openai/wandb/run-20230830_115947-iepk19m2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/iepk19m2' target=\"_blank\">ethereal-energy-4</a></strong> to <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/iepk19m2' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/iepk19m2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87 test examples\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT,\n",
    "           job_type='eval')\n",
    "\n",
    "artifact_valid = wandb.use_artifact(\n",
    "    f'{entity}/{WANDB_PROJECT}/legalbench-contract_nli_explicit_identification-test:latest',\n",
    "    type='test-data')\n",
    "test_file = artifact_valid.get_path(test_file_path).download(\"my_data\")\n",
    "\n",
    "with open(test_file) as f:\n",
    "    test_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"There are {len(test_dataset)} test examples\")\n",
    "wandb.config.update({\"num_test_samples\":len(test_dataset)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFUUHVMFU2d0"
   },
   "source": [
    "### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã®è©•ä¾¡å®Ÿè¡Œ\n",
    "ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã®OpenAIå‘¼ã³å‡ºã—ã‚’è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FagY6Ev_U2d0"
   },
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(60))\n",
    "def call_openai(messages=\"\", model=\"gpt-3.5-turbo\"):\n",
    "  return openai.ChatCompletion.create(model=model, messages=messages, max_tokens=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9PB5SJrJU2d0"
   },
   "source": [
    "è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®IDã‚’å–å¾—ã—ã¾ã—ã‚‡ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8vNiUlFU2d0",
    "outputId": "d196a4f1-4c47-4977-b2bd-2f0e485075f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:weights-biases::7tC85HcX'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = openai.FineTuningJob.retrieve(ft_job_id)\n",
    "ft_model_id = state[\"fine_tuned_model\"]\n",
    "ft_model_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0ncxuaqBU2d0"
   },
   "source": [
    "W&Bã«è©•ä¾¡ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ãƒ­ã‚°ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "683c7db769d044f79cf9409f00af137d"
     ]
    },
    "id": "6YF8ED9HU2d0",
    "outputId": "c952c07f-d972-4201-8b62-ee1409dd8f9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683c7db769d044f79cf9409f00af137d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_table = wandb.Table(columns=['messages', 'completion', 'target'])\n",
    "\n",
    "eval_data = []\n",
    "\n",
    "for row in tqdm(test_dataset):\n",
    "    messages = row['messages'][:2]\n",
    "    target = row[\"messages\"][2]\n",
    "\n",
    "    # res = call_openai(model=ft_model_id, messages=messages)\n",
    "    res = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=10)\n",
    "    completion = res.choices[0].message.content\n",
    "\n",
    "    eval_data.append([messages, completion, target])\n",
    "    prediction_table.add_data(messages[1]['content'], completion, target[\"content\"])\n",
    "\n",
    "wandb.log({'predictions': prediction_table})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2BKojUKMU2d0"
   },
   "source": [
    "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è¨ˆç®—ã—ã€W&Bã«ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n02OqDO9U2d0",
    "outputId": "7b3a9bd1-6af6-4f27-b9e1-186d204cc55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8390804597701149\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for e in eval_data:\n",
    "  if e[1].lower() == e[2][\"content\"].lower():\n",
    "    correct+=1\n",
    "\n",
    "accuracy = correct / len(eval_data)\n",
    "\n",
    "print(f\"Accuracy is {accuracy}\")\n",
    "wandb.log({\"eval/accuracy\": accuracy})\n",
    "wandb.summary[\"eval/accuracy\"] = accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MtlZPVG2U2d0"
   },
   "source": [
    "### æ¯”è¼ƒã®ãŸã‚ã«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "ç§ãŸã¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹`gpt-3.5-turbo`ã¨æ¯”è¼ƒã—ã¦ã¿ã¾ã—ã‚‡ã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "56a6a14b0c1346149c973f6c71d31b6c"
     ]
    },
    "id": "9E0IRSTfU2d0",
    "outputId": "0d016d12-1aa7-40aa-9403-3b0864acbc62"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6a14b0c1346149c973f6c71d31b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_prediction_table = wandb.Table(columns=['messages', 'completion', 'target'])\n",
    "baseline_eval_data = []\n",
    "\n",
    "for row in tqdm(test_dataset):\n",
    "    messages = row['messages'][:2]\n",
    "    target = row[\"messages\"][2]\n",
    "\n",
    "    res = call_openai(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    completion = res.choices[0].message.content\n",
    "\n",
    "    baseline_eval_data.append([messages, completion, target])\n",
    "    baseline_prediction_table.add_data(messages[1]['content'], completion, target[\"content\"])\n",
    "\n",
    "wandb.log({'baseline_predictions': baseline_prediction_table})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i98CsZJ1U2d1"
   },
   "source": [
    "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è¨ˆç®—ã—ã€W&Bã«ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sl4zmPwU2d1",
    "outputId": "7fd58a23-d4ee-4f7b-d8dc-03e208e1a5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accurcy is: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "baseline_correct = 0\n",
    "for e in baseline_eval_data:\n",
    "  if e[1].lower() == e[2][\"content\"].lower():\n",
    "    baseline_correct+=1\n",
    "\n",
    "baseline_accuracy = baseline_correct / len(baseline_eval_data)\n",
    "print(f\"Baseline Accurcy is: {baseline_accuracy}\")\n",
    "wandb.log({\"eval/baseline_accuracy\": baseline_accuracy})\n",
    "wandb.summary[\"eval/baseline_accuracy\"] =  baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e7fa6b38a02847758fdd424affbc74c1"
     ]
    },
    "id": "EbeRF7vEU2d1",
    "outputId": "0b679cda-7740-42d9-bbe6-feb11d69ea6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fa6b38a02847758fdd424affbc74c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.248 MB of 0.248 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/baseline_accuracy</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83908</td></tr><tr><td>eval/baseline_accuracy</td><td>0.7931</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-energy-4</strong> at: <a href='https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/iepk19m2' target=\"_blank\">https://wandb.ai/capecape/OpenAI-Fine-Tune/runs/iepk19m2</a><br/>Synced 7 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230830_115947-iepk19m2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A9nh4b15U2d1"
   },
   "source": [
    "ã“ã‚Œã§å®Œäº†ã§ã™ï¼ã“ã®ä¾‹ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã€Weights & Biasesã«ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦OpenAIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€çµæœã‚’Weights & Biasesã«ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã€æœ€å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚\n",
    "\n",
    "ã“ã“ã‹ã‚‰ã€ã‚ˆã‚Šå¤§è¦æ¨¡ã§è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ãŸã‚Šã€ç•°ãªã‚‹ãƒˆãƒ¼ãƒ³ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€å¿œç­”ã‚’ä¸ãˆã‚‹ãªã©ã€ChatGPT-3.5ã‚’å¤‰æ›´ã™ã‚‹ä»–ã®æ–¹æ³•ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aVtXGnB_U2d1"
   },
   "source": [
    "# ãƒªã‚½ãƒ¼ã‚¹\n",
    "\n",
    "* [OpenAI Fine-Tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)\n",
    "* [W&B Integration with OpenAI API Documentation](https://wandb.me/openai-docs)\n",
    "* [W&B Report: GPT-3 exploration & fine-tuning tips](http://wandb.me/openai-report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
