{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Action Library: AWS RedShift\n",
    "\n",
    "## 概要\n",
    "\n",
    "このGPT Actionは、AWS RedShiftデータウェアハウスとの統合を可能にします。ユーザーはGPTを通じてRedShiftクラスターに対してSQLクエリを実行し、データの取得、分析、レポート生成を行うことができます。\n",
    "\n",
    "## 主な機能\n",
    "\n",
    "- **SQLクエリ実行**: RedShiftクラスターに対してSELECT、INSERT、UPDATE、DELETE文を実行\n",
    "- **スキーマ探索**: データベースのテーブル、カラム、データ型の情報を取得\n",
    "- **データ分析**: 集計、グループ化、結合などの複雑なクエリをサポート\n",
    "- **結果のフォーマット**: クエリ結果をJSON、CSV、テーブル形式で表示\n",
    "\n",
    "## 設定要件\n",
    "\n",
    "### 前提条件\n",
    "\n",
    "1. AWS RedShiftクラスターが稼働していること\n",
    "2. 適切なIAMロールとポリシーが設定されていること\n",
    "3. RedShiftクラスターへのネットワークアクセスが可能であること\n",
    "\n",
    "### 必要な認証情報\n",
    "\n",
    "- AWS Access Key ID\n",
    "- AWS Secret Access Key\n",
    "- RedShiftクラスターエンドポイント\n",
    "- データベース名\n",
    "- ユーザー名とパスワード\n",
    "\n",
    "## 使用例\n",
    "\n",
    "### 基本的なデータ取得\n",
    "\n",
    "```sql\n",
    "SELECT * FROM sales_data \n",
    "WHERE date >= '2024-01-01' \n",
    "LIMIT 100;\n",
    "```\n",
    "\n",
    "### 集計クエリ\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    product_category,\n",
    "    SUM(revenue) as total_revenue,\n",
    "    COUNT(*) as transaction_count\n",
    "FROM sales_data \n",
    "GROUP BY product_category\n",
    "ORDER BY total_revenue DESC;\n",
    "```\n",
    "\n",
    "### テーブル情報の取得\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    table_name,\n",
    "    column_name,\n",
    "    data_type\n",
    "FROM information_schema.columns \n",
    "WHERE table_schema = 'public';\n",
    "```\n",
    "\n",
    "## セキュリティ考慮事項\n",
    "\n",
    "- 最小権限の原則に従ってIAMポリシーを設定\n",
    "- 機密データへのアクセスを制限\n",
    "- クエリログの監視とモニタリング\n",
    "- VPCエンドポイントの使用を推奨\n",
    "\n",
    "## 制限事項\n",
    "\n",
    "- 大量データの取得時は結果セットのサイズ制限に注意\n",
    "- DDL文（CREATE、DROP等）の実行は慎重に行う\n",
    "- 同時接続数の上限を考慮\n",
    "- クエリタイムアウトの設定\n",
    "\n",
    "## トラブルシューティング\n",
    "\n",
    "### 接続エラー\n",
    "\n",
    "- ネットワーク設定とセキュリティグループの確認\n",
    "- 認証情報の検証\n",
    "- クラスターの稼働状態確認\n",
    "\n",
    "### パフォーマンス問題\n",
    "\n",
    "- クエリの最適化\n",
    "- インデックスの活用\n",
    "- 適切なディストリビューションキーの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このページでは、特定のアプリケーション向けのGPT Actionを構築する開発者向けの手順とガイドを提供します。進める前に、まず以下の情報をよく理解しておいてください：\n",
    "\n",
    "- [GPT Actionsの紹介](https://platform.openai.com/docs/actions)\n",
    "- [GPT Actionsライブラリの紹介](https://platform.openai.com/docs/actions/actions-library)\n",
    "- [GPT Actionをゼロから構築する例](https://platform.openai.com/docs/actions/getting-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この解決策は、GPTアクションがRedshiftからデータを取得し、データ分析を実行することを可能にします。AWS Functionsを使用し、AWSエコシステムとネットワークからすべてのアクションを実行します。ミドルウェア（AWS関数）はSQLクエリを実行し、その完了を待機してデータをファイルとして返します。提供されているコードは情報提供のみを目的としており、ニーズに応じて修正する必要があります。\n",
    "\n",
    "この解決策は、[アクションでファイルを取得する](https://platform.openai.com/docs/actions/sending-files)機能を使用し、会話に直接アップロードしたかのようにファイルを使用します。\n",
    "\n",
    "この解決策はRedshift serverlessへの接続を強調しており、プロビジョニングされたRedshiftとの統合では、ネットワークの取得と接続のセットアップが若干異なる場合がありますが、全体的なコードと（最小限の）統合は類似しているはずです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 価値とビジネス活用事例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**価値**: ChatGPTの自然言語機能を活用してRedshiftのDWHに接続する。\n",
    "\n",
    "**使用例**:\n",
    "- データサイエンティストがテーブルに接続し、ChatGPTのデータ分析機能を使用してデータ分析を実行できる\n",
    "- 一般的なデータユーザーがトランザクションデータに関する基本的な質問を行うことができる\n",
    "- ユーザーがデータや潜在的な異常値についてより多くの可視性を得ることができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アプリケーション情報"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アプリケーションの前提条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始する前に、以下を確認してください：\n",
    "- Redshift環境にアクセスできること\n",
    "- 同じVPC（Virtual Private Network）内にAWS関数をデプロイする権限があること\n",
    "- AWS CLIが認証されていること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミドルウェア情報"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なライブラリのインストール\n",
    "- AWS CLIをインストールする（AWS SAMに必要）（[ドキュメント](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html#getting-started-install-instructions)）\n",
    "- AWS SAM CLIをインストールする（[ドキュメント](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html)）\n",
    "- Pythonをインストールする\n",
    "- yqをインストールする（[ドキュメント](https://github.com/mikefarah/yq?tab=readme-ov-file#install)）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ミドルウェア関数\n",
    "\n",
    "関数を作成するには、[AWS Middleware Action cookbook](https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/gpt_middleware_aws_function)の手順に従ってください。\n",
    "\n",
    "特にRedshiftに接続するアプリケーションをデプロイするには、Middleware AWS Function cookbookで参照されている「hello-world」GitHubリポジトリの代わりに、以下のコードを使用してください。リポジトリをクローンするか、以下に貼り付けられたコードを取得して、ニーズに合わせて修正することができます。\n",
    "\n",
    "> このコードは方向性を示すものです - そのまま動作するはずですが、あなたのニーズに合わせてカスタマイズするように設計されています（このドキュメントの最後にある例を参照してください）。\n",
    "\n",
    "コードを取得するには、openai-cookbookリポジトリをクローンして、redshift-middlewareディレクトリに移動してください。\n",
    "\n",
    "```\n",
    "git clone https://github.com/pap-openai/redshift-middleware\n",
    "cd redshift-middleware\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import os\n",
    "import base64\n",
    "import tempfile\n",
    "import csv\n",
    "\n",
    "# Fetch Redshift credentials from environment variables\n",
    "host = os.environ['REDSHIFT_HOST']\n",
    "port = os.environ['REDSHIFT_PORT']\n",
    "user = os.environ['REDSHIFT_USER']\n",
    "password = os.environ['REDSHIFT_PASSWORD']\n",
    "database = os.environ['REDSHIFT_DB']\n",
    "\n",
    "def execute_statement(sql_statement):\n",
    "    try:\n",
    "        # Establish connection\n",
    "        conn = psycopg2.connect(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            dbname=database\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql_statement)\n",
    "        conn.commit()\n",
    "\n",
    "        # Fetch all results\n",
    "        if cur.description:\n",
    "            columns = [desc[0] for desc in cur.description]\n",
    "            result = cur.fetchall()\n",
    "        else:\n",
    "            columns = []\n",
    "            result = []\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return columns, result\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Database query failed: {str(e)}\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        data = json.loads(event['body'])\n",
    "        sql_statement = data['sql_statement']\n",
    "\n",
    "        # Execute the statement and fetch results\n",
    "        columns, result = execute_statement(sql_statement)\n",
    "        \n",
    "        # Create a temporary file to save the result as CSV\n",
    "        with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.csv', newline='') as tmp_file:\n",
    "            csv_writer = csv.writer(tmp_file)\n",
    "            if columns:\n",
    "                csv_writer.writerow(columns)  # Write the header\n",
    "            csv_writer.writerows(result)  # Write all rows\n",
    "            tmp_file_path = tmp_file.name\n",
    "\n",
    "        # Read the file and encode its content to base64\n",
    "        with open(tmp_file_path, 'rb') as f:\n",
    "            file_content = f.read()\n",
    "            encoded_content = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "        response = {\n",
    "            'openaiFileResponse': [\n",
    "                {\n",
    "                    'name': 'query_result.csv',\n",
    "                    'mime_type': 'text/csv',\n",
    "                    'content': encoded_content\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'headers': {\n",
    "                'Content-Type': 'application/json'\n",
    "            },\n",
    "            'body': json.dumps(response)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({'error': str(e)})\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VPC情報の取得\n",
    "\n",
    "関数をRedshiftに接続する必要があるため、Redshiftで使用されているネットワークを見つける必要があります。これは、AWSコンソールのRedshiftインターフェースで、Amazon Redshift Serverless > Workgroup configuration > `your_workgroup` > Data accessから確認するか、CLIを通じて確認できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws redshift-serverless get-workgroup --workgroup-name default-workgroup --query 'workgroup.{address: endpoint.address, port: endpoint.port, SecurityGroupIds: securityGroupIds, SubnetIds: subnetIds}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS関数の設定\n",
    "\n",
    "`env.sample.yaml`を`env.yaml`にコピーし、上記で取得した値に置き換えてください。DB/スキーマにアクセス権限を持つRedshiftユーザーが必要です。\n",
    "\n",
    "```\n",
    "cp env.sample.yaml env.yaml\n",
    "```\n",
    "\n",
    "前のコマンドで取得した値とRedshiftの認証情報を使用して`env.yaml`に記入してください。\n",
    "または、`env.yaml`という名前のファイルを手動で作成し、以下の変数を記入することもできます：\n",
    "\n",
    "```\n",
    "RedshiftHost: default-workgroup.xxxxx.{region}.redshift-serverless.amazonaws.com\n",
    "RedshiftPort: 5439\n",
    "RedshiftUser: username\n",
    "RedshiftPassword: password\n",
    "RedshiftDb: my-db\n",
    "SecurityGroupId: sg-xx\n",
    "SubnetId1: subnet-xx\n",
    "SubnetId2: subnet-xx\n",
    "SubnetId3: subnet-xx\n",
    "SubnetId4: subnet-xx\n",
    "SubnetId5: subnet-xx\n",
    "SubnetId6: subnet-xx\n",
    "```\n",
    "\n",
    "このファイルは、以下に示すようにパラメータを使用して関数をデプロイするために使用されます：\n",
    "\n",
    "```\n",
    "PARAM_FILE=\"env.yaml\"\n",
    "PARAMS=$(yq eval -o=json $PARAM_FILE | jq -r 'to_entries | map(\"\\(.key)=\\(.value|tostring)\") | join(\" \")')\n",
    "sam deploy --template-file template.yaml --stack-name redshift-middleware --capabilities CAPABILITY_IAM --parameter-overrides $PARAMS\n",
    "```\n",
    "\n",
    "template.yamlには以下の内容が含まれています："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWSTemplateFormatVersion: '2010-09-09'\n",
    "Transform: AWS::Serverless-2016-10-31\n",
    "Description: >\n",
    "  redshift-middleware\n",
    "\n",
    "  Middleware to fetch RedShift data and return it through HTTP as files\n",
    "\n",
    "Globals:\n",
    "  Function:\n",
    "    Timeout: 3\n",
    "\n",
    "Parameters:\n",
    "  RedshiftHost:\n",
    "    Type: String\n",
    "  RedshiftPort:\n",
    "    Type: String\n",
    "  RedshiftUser:\n",
    "    Type: String\n",
    "  RedshiftPassword:\n",
    "    Type: String\n",
    "  RedshiftDb:\n",
    "    Type: String\n",
    "  SecurityGroupId:\n",
    "    Type: String\n",
    "  SubnetId1:\n",
    "    Type: String\n",
    "  SubnetId2:\n",
    "    Type: String\n",
    "  SubnetId3:\n",
    "    Type: String\n",
    "  SubnetId4:\n",
    "    Type: String\n",
    "  SubnetId5:\n",
    "    Type: String\n",
    "  SubnetId6:\n",
    "    Type: String\n",
    "  CognitoUserPoolName:\n",
    "    Type: String\n",
    "    Default: MyCognitoUserPool\n",
    "  CognitoUserPoolClientName:\n",
    "    Type: String\n",
    "    Default: MyCognitoUserPoolClient\n",
    "\n",
    "Resources:\n",
    "  MyCognitoUserPool:\n",
    "    Type: AWS::Cognito::UserPool\n",
    "    Properties:\n",
    "      UserPoolName: !Ref CognitoUserPoolName\n",
    "      Policies:\n",
    "        PasswordPolicy:\n",
    "          MinimumLength: 8\n",
    "      UsernameAttributes:\n",
    "        - email\n",
    "      Schema:\n",
    "        - AttributeDataType: String\n",
    "          Name: email\n",
    "          Required: false\n",
    "\n",
    "  MyCognitoUserPoolClient:\n",
    "    Type: AWS::Cognito::UserPoolClient\n",
    "    Properties:\n",
    "      UserPoolId: !Ref MyCognitoUserPool\n",
    "      ClientName: !Ref CognitoUserPoolClientName\n",
    "      GenerateSecret: true\n",
    "\n",
    "  RedshiftMiddlewareApi:\n",
    "    Type: AWS::Serverless::Api\n",
    "    Properties:\n",
    "      StageName: Prod\n",
    "      Cors: \"'*'\"\n",
    "      Auth:\n",
    "        DefaultAuthorizer: MyCognitoAuthorizer\n",
    "        Authorizers:\n",
    "          MyCognitoAuthorizer:\n",
    "            AuthorizationScopes:\n",
    "              - openid\n",
    "              - email\n",
    "              - profile\n",
    "            UserPoolArn: !GetAtt MyCognitoUserPool.Arn\n",
    "        \n",
    "  RedshiftMiddlewareFunction:\n",
    "    Type: AWS::Serverless::Function\n",
    "    Properties:\n",
    "      CodeUri: redshift-middleware/\n",
    "      Handler: app.lambda_handler\n",
    "      Runtime: python3.11\n",
    "      Timeout: 45\n",
    "      Architectures:\n",
    "        - x86_64\n",
    "      Events:\n",
    "        SqlStatement:\n",
    "          Type: Api\n",
    "          Properties:\n",
    "            Path: /sql_statement\n",
    "            Method: post\n",
    "            RestApiId: !Ref RedshiftMiddlewareApi\n",
    "      Environment:\n",
    "        Variables:\n",
    "          REDSHIFT_HOST: !Ref RedshiftHost\n",
    "          REDSHIFT_PORT: !Ref RedshiftPort\n",
    "          REDSHIFT_USER: !Ref RedshiftUser\n",
    "          REDSHIFT_PASSWORD: !Ref RedshiftPassword\n",
    "          REDSHIFT_DB: !Ref RedshiftDb\n",
    "      VpcConfig:\n",
    "        SecurityGroupIds:\n",
    "          - !Ref SecurityGroupId\n",
    "        SubnetIds:\n",
    "          - !Ref SubnetId1\n",
    "          - !Ref SubnetId2\n",
    "          - !Ref SubnetId3\n",
    "          - !Ref SubnetId4\n",
    "          - !Ref SubnetId5\n",
    "          - !Ref SubnetId6\n",
    "\n",
    "Outputs:\n",
    "  RedshiftMiddlewareApi:\n",
    "    Description: \"API Gateway endpoint URL for Prod stage for SQL Statement function\"\n",
    "    Value: !Sub \"https://${RedshiftMiddlewareApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/sql_statement/\"\n",
    "  RedshiftMiddlewareFunction:\n",
    "    Description: \"SQL Statement Lambda Function ARN\"\n",
    "    Value: !GetAtt RedshiftMiddlewareFunction.Arn\n",
    "  RedshiftMiddlewareFunctionIamRole:\n",
    "    Description: \"Implicit IAM Role created for SQL Statement function\"\n",
    "    Value: !GetAtt RedshiftMiddlewareFunctionRole.Arn\n",
    "  CognitoUserPoolArn:\n",
    "    Description: \"ARN of the Cognito User Pool\"\n",
    "    Value: !GetAtt MyCognitoUserPool.Arn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前のコマンド出力からURL情報を取得し、cURLリクエストを実行すると、ファイル形式でデータが返されます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST https://<your_url>/Prod/sql_statement/ \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{ \"sql_statement\": \"SELECT * FROM customers LIMIT 10\", \"workgroup_name\": \"default-workgroup\", \"database_name\": \"pap-db\" }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT ステップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタムGPT指示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom GPTを作成したら、以下のテキストをInstructionsパネルにコピーしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "**Context**: You are an expert at writing Redshift SQL queries. You will initially retrieve the table schema that you will use thoroughly. Every attributes, table names or data type will be known by you.\n",
    "\n",
    "**Instructions**:\n",
    "1. No matter the user's question, start by running `runQuery` operation using this query: \"SELECT table_name, column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema = 'public' ORDER BY table_name, ordinal_position;\"  It will help you understand how to query the data. A CSV will be returned with all the attributes and their table. Make sure to read it fully and understand all available tables & their attributes before querying. You don't have to show this to the user.\n",
    "2. Convert the user's question into a SQL statement that leverages the step above and run the `runQuery` operation on that SQL statement to confirm the query works. Let the user know which table you will use/query.\n",
    "3. Execute the query and show him the data. Show only the first few rows.\n",
    "\n",
    "**Additional Notes**: If the user says \"Let's get started\", explain they can ask a question they want answered about data that we have access to. If the user has no ideas, suggest that we have transactions data they can query - ask if they want you to query that.\n",
    "**Important**: Never make up a table name or table attribute. If you don't know, go back to the data you've retrieved to check what is available. If you think no table or attribute is available, then tell the user you can't perform this query for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAPI スキーマ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom GPTを作成したら、以下のテキストをActionsパネルにコピーしてください。\n",
    "\n",
    "これは、[こちら](https://platform.openai.com/docs/actions/sending-files)のドキュメントにあるファイル取得構造と一致するレスポンスを期待し、実行するパラメータとして`query`を渡します。\n",
    "\n",
    "認証を設定するために、[AWS Middlewareクックブック](https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/gpt_middleware_aws_function)の手順に従ってください。\n",
    "\n",
    "> 関数のデプロイメントに基づいて、関数アプリ名を切り替えることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "openapi: 3.1.0\n",
    "info:\n",
    "  title: SQL Execution API\n",
    "  description: API to execute SQL statements and return results as a file.\n",
    "  version: 1.0.0\n",
    "servers:\n",
    "  - url: {your_function_url}/Prod\n",
    "    description: Production server\n",
    "paths:\n",
    "  /sql_statement:\n",
    "    post:\n",
    "      operationId: executeSqlStatement\n",
    "      summary: Executes a SQL statement and returns the result as a file.\n",
    "      requestBody:\n",
    "        required: true\n",
    "        content:\n",
    "          application/json:\n",
    "            schema:\n",
    "              type: object\n",
    "              properties:\n",
    "                sql_statement:\n",
    "                  type: string\n",
    "                  description: The SQL statement to execute.\n",
    "                  example: SELECT * FROM customers LIMIT 10\n",
    "              required:\n",
    "                - sql_statement\n",
    "      responses:\n",
    "        '200':\n",
    "          description: The SQL query result as a JSON file.\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                type: object\n",
    "                properties:\n",
    "                  openaiFileResponse:\n",
    "                    type: array\n",
    "                    items:\n",
    "                      type: object\n",
    "                      properties:\n",
    "                        name:\n",
    "                          type: string\n",
    "                          description: The name of the file.\n",
    "                          example: query_result.json\n",
    "                        mime_type:\n",
    "                          type: string\n",
    "                          description: The MIME type of the file.\n",
    "                          example: application/json\n",
    "                        content:\n",
    "                          type: string\n",
    "                          description: The base64 encoded content of the file.\n",
    "                          format: byte\n",
    "                          example: eyJrZXkiOiJ2YWx1ZSJ9\n",
    "        '500':\n",
    "          description: Error response\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                type: object\n",
    "                properties:\n",
    "                  error:\n",
    "                    type: string\n",
    "                    description: Error message.\n",
    "                    example: Database query failed error details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "これで、認証機能付きでAWSのミドルウェアを使用し、Redshiftに接続できるGPTをデプロイしました。アクセス権限を持つユーザー（Cognitoに登録されているユーザー）は、データベースにクエリを実行してデータ分析タスクを実行できるようになりました：\n",
    "\n",
    "![../../../images/redshift_gpt.png](../../../images/redshift_gpt.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
