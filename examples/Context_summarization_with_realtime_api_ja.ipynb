{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime APIã‚’ä½¿ç”¨ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„\n",
    "## 1. æ¦‚è¦\n",
    "ãƒã‚¤ã‚¯ã®éŸ³å£°ã‚’èãå–ã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¿œç­”ã—ã€**é•·ã„ä¼šè©±ã‚’è¦ç´„**ã—ã¦å“è³ªã‚’ç¶­æŒã™ã‚‹ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®**éŸ³å£°ãƒœãƒƒãƒˆ**ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "\n",
    "### å­¦ç¿’å†…å®¹\n",
    "1. **ãƒ©ã‚¤ãƒ–ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°** â†’ OpenAI *Realtime*ï¼ˆéŸ³å£°å¯¾éŸ³å£°ï¼‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\n",
    "2. å„ã‚¿ãƒ¼ãƒ³ã§ã®**å³åº§ã®è»¢å†™ã¨éŸ³å£°å†ç”Ÿ**\n",
    "3. **ã™ã¹ã¦ã®**ãƒ¦ãƒ¼ã‚¶ãƒ¼/ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã™ã‚‹**ä¼šè©±çŠ¶æ…‹ã‚³ãƒ³ãƒ†ãƒŠ**\n",
    "4. **è‡ªå‹•ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒªãƒ ã€** â€“ ãƒˆãƒ¼ã‚¯ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒéå¸¸ã«å¤§ãããªã£ãŸå ´åˆï¼ˆè¨­å®šå¯èƒ½ï¼‰ã€å¤ã„ã‚¿ãƒ¼ãƒ³ã‚’è¦ç´„ã«åœ§ç¸®\n",
    "5. ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆã€ã‚­ã‚ªã‚¹ã‚¯ã€å¤šè¨€èªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«é©å¿œå¯èƒ½ãª**æ‹¡å¼µå¯èƒ½ãªè¨­è¨ˆ**\n",
    "\n",
    "### å‰ææ¡ä»¶\n",
    "\n",
    "| è¦ä»¶ | è©³ç´° |\n",
    "|-------------|---------|\n",
    "| **Python â‰¥ 3.10** | å•é¡ŒãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ä¿è¨¼ã—ã¾ã™ |\n",
    "| **OpenAI APIã‚­ãƒ¼** | ã‚·ã‚§ãƒ«ã§`OPENAI_API_KEY`ã‚’è¨­å®šã™ã‚‹ã‹ã€ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã§è²¼ã‚Šä»˜ã‘ï¼ˆ*æœ¬ç•ªç’°å¢ƒã«ã¯ç†æƒ³çš„ã§ã¯ãªã„*ï¼‰ |\n",
    "| ãƒã‚¤ã‚¯ + ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰OSæ¨©é™ã‚’è¨±å¯ |\n",
    "\n",
    "**ã‚­ãƒ¼ã®è¨­å®šã§ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ã‹ï¼Ÿ**  \n",
    "> [å…¬å¼ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰](https://platform.openai.com/docs/quickstart#step-2-set-your-api-key)ã«å¾“ã£ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "*æ³¨æ„äº‹é …:*\n",
    "> 1. gpt-realtimeã¯32kãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ãŒã€ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ã‚ˆã‚Šå¤šãã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è©°ã‚è¾¼ã‚€ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "> 2. ãƒˆãƒ¼ã‚¯ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ = ãƒ¢ãƒ‡ãƒ«ãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã«ãƒ¡ãƒ¢ãƒªã«ä¿æŒã™ã‚‹ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå˜èªã¨éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰\n",
    "\n",
    "### ãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ–°ã—ã„ã‚»ãƒ«ã§å®Ÿè¡Œï¼‰\n",
    "\n",
    "*æ–°ã—ã„APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:*\n",
    "> 1. Realtime API GAã§ã¯æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿[`truncation`](https://platform.openai.com/docs/api-reference/realtime-client-events/session/update#realtime-client-events/session/update-session-realtime-session-configuration-truncation)ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€é–¢é€£æƒ…å ±ã‚’ä¿æŒã—ãªãŒã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã‚’æœ€å¤§åŒ–ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åˆ‡ã‚Šè©°ã‚ã‚’è‡ªå‹•çš„ã«æœ€é©åŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â RunÂ onceÂ toÂ installÂ orÂ upgradeÂ dependencies (comment out if already installed)\n",
    "# !pip install --upgrade openai websockets sounddevice simpleaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import pathlib\n",
    "import wave\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Literal\n",
    "\n",
    "# Third-party imports\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import sounddevice as sd         # microphone capture\n",
    "import simpleaudio               # speaker playback\n",
    "import websockets                # WebSocket client\n",
    "import openai                    # OpenAI Python SDK >= 1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â SetÂ yourÂ APIÂ keyÂ safely\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found â€“ please set env var or edit this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ â€“ ãƒ†ã‚­ã‚¹ãƒˆ vs éŸ³å£°\n",
    "\n",
    "å¤§ããªãƒˆãƒ¼ã‚¯ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯è²´é‡ã§ã‚ã‚Šã€ä½¿ç”¨ã™ã‚‹è¿½åŠ ãƒˆãƒ¼ã‚¯ãƒ³ã¯ã™ã¹ã¦ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚³ã‚¹ãƒˆã‚’å¢—åŠ ã•ã›ã¾ã™ã€‚  \n",
    "**éŸ³å£°**ã®å ´åˆã€æŒ¯å¹…ã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã€ãã®ä»–ã®éŸ³éŸ¿çš„è©³ç´°ã‚’è¡¨ç¾ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é€Ÿãå¢—åŠ ã—ã¾ã™ã€‚\n",
    "\n",
    "å®Ÿéš›ã«ã¯ã€åŒã˜æ–‡ç« ã§ã‚‚éŸ³å£°ã®å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã¨æ¯”è¼ƒã—ã¦**ç´„10å€**ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¿…è¦ã«ãªã‚‹ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "\n",
    "* gpt-realtimeã¯æœ€å¤§**32kãƒˆãƒ¼ã‚¯ãƒ³**ã¾ã§å—ã‘å…¥ã‚Œã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚µã‚¤ã‚ºãŒå¢—åŠ ã™ã‚‹ã¨æŒ‡ç¤ºã¸ã®æº–æ‹ ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "* ãƒ¦ãƒ¼ã‚¶ãƒ¼/ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã‚¿ãƒ¼ãƒ³ã”ã¨ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã™ã‚‹ãŸã‚ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯**å¢—åŠ ã—ç¶šã‘ã¾ã™**ã€‚\n",
    "* **æˆ¦ç•¥**: å¤ã„ã‚¿ãƒ¼ãƒ³ã‚’å˜ä¸€ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¦ç´„ã—ã€æœ€å¾Œã®æ•°ã‚¿ãƒ¼ãƒ³ã‚’ãã®ã¾ã¾ä¿æŒã—ã¦ç¶šè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "<img src=\"../images/text-vs-audio-tokens.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "ä»¥ä¸‹ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã«ã‚ˆã‚Šã€å®Œå…¨ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ä¼šè©±çŠ¶æ…‹\n",
    "HTTPãƒ™ãƒ¼ã‚¹ã®Chat Completionsã¨ã¯ç•°ãªã‚Šã€Realtime APIã¯2ã¤ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ãª**ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«**ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã—ã¾ã™ï¼š\n",
    "\n",
    "| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | ç›®çš„ |\n",
    "|----------------|---------|\n",
    "| **Session**     | ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚’åˆ¶å¾¡ â€” ãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°ã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã€VADç­‰ |\n",
    "| **Conversation** | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆé–“ã®ã‚¿ãƒ¼ãƒ³ã”ã¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ â€” éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ |\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ã“ã‚Œã‚‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å˜ç´”ãª`ConversationState`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã«ãƒ©ãƒƒãƒ—ã—ã¦ã€ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ•´ç†ã—ã€å±¥æ­´ã‚’è¿½è·¡ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒæº€æ¯ã«ãªã£ãŸéš›ã®è¦ç´„ã‚’ç®¡ç†ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Turn:\n",
    "    \"\"\"One utterance in the dialogue (user **or** assistant).\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\"]\n",
    "    item_id: str                    # Serverâ€‘assigned identifier\n",
    "    text: str | None = None         # Filled once transcript is ready\n",
    "\n",
    "@dataclass\n",
    "class ConversationState:\n",
    "    \"\"\"All mutable data the session needs â€” nothing more, nothing less.\"\"\"\n",
    "    history: List[Turn] = field(default_factory=list)         # Ordered log\n",
    "    waiting: dict[str, asyncio.Future] = field(default_factory=dict)  # Pending transcript fetches\n",
    "    summary_count: int = 0\n",
    "\n",
    "    latest_tokens: int = 0          # Window size after last reply\n",
    "    summarising: bool = False       # Guard so we donâ€™t run two summaries at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç¢ºèªã™ã‚‹ãŸã‚ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_history(state) -> None:\n",
    "    \"\"\"Pretty-print the running transcript so far.\"\"\"\n",
    "    print(\"â€”â€” Conversation so far â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")\n",
    "    for turn in state.history:\n",
    "        text_preview = (turn.text or \"\").strip().replace(\"\\n\", \" \")\n",
    "        print(f\"[{turn.role:<9}] {text_preview}  ({turn.item_id})\")\n",
    "    print(\"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Â· ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°\n",
    "ç”Ÿã®PCM-16ãƒã‚¤ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥Realtime APIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "\n",
    "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯: mic â”€â–º async.Queue â”€â–º WebSocket â”€â–º Realtime API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 ãƒã‚¤ã‚¯å…¥åŠ›ã®ã‚­ãƒ£ãƒ—ãƒãƒ£\n",
    "ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã†ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‹ã‚‰å§‹ã‚ã¾ã™ï¼š\n",
    "\n",
    "* ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒã‚¤ã‚¯ã‚’**24 kHzã€ãƒ¢ãƒãƒ©ãƒ«ã€PCMâ€‘16**ã§é–‹ãï¼ˆRealtimeãŒå—ã‘å…¥ã‚Œã‚‹[ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ](https://platform.openai.com/docs/api-reference/realtime-sessions/create#realtime-sessions-create-input_audio_format)ã®ä¸€ã¤ï¼‰ã€‚  \n",
    "* ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’**ç´„40ms**ã®ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ã™ã‚‹ã€‚  \n",
    "* å„ãƒ–ãƒ­ãƒƒã‚¯ã‚’`asyncio.Queue`ã«æŠ•å…¥ã—ã€åˆ¥ã®ã‚¿ã‚¹ã‚¯ï¼ˆæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ãŒOpenAIã«è»¢é€ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mic_to_queue(pcm_queue: asyncio.Queue[bytes]) -> None:\n",
    "    \"\"\"\n",
    "    Capture raw PCMâ€‘16 microphone audio and push ~CHUNK_DURATION_MS chunks\n",
    "    to *pcm_queue* until the surrounding task is cancelled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pcm_queue : asyncio.Queue[bytes]\n",
    "        Destination queue for PCMâ€‘16 frames (littleâ€‘endian int16).\n",
    "    \"\"\"\n",
    "    blocksize = int(SAMPLE_RATE_HZ * CHUNK_DURATION_MS / 1000)\n",
    "\n",
    "    def _callback(indata, _frames, _time, status):\n",
    "        if status:                               # XRuns, device changes, etc.\n",
    "            print(\"âš ï¸\", status, file=sys.stderr)\n",
    "        try:\n",
    "            pcm_queue.put_nowait(bytes(indata))  # 1â€‘shot enqueue\n",
    "        except asyncio.QueueFull:\n",
    "            # Drop frame if upstream (WebSocket) canâ€™t keep up.\n",
    "            pass\n",
    "\n",
    "    # RawInputStream is synchronous; wrap in context manager to autoâ€‘close.\n",
    "    with sd.RawInputStream(\n",
    "        samplerate=SAMPLE_RATE_HZ,\n",
    "        blocksize=blocksize,\n",
    "        dtype=\"int16\",\n",
    "        channels=1,\n",
    "        callback=_callback,\n",
    "    ):\n",
    "        try:\n",
    "            # Keep coroutine alive until cancelled by caller.\n",
    "            await asyncio.Event().wait()\n",
    "        finally:\n",
    "            print(\"â¹ï¸  Mic stream closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ£ãƒ³ã‚¯ã‚’APIã«é€ä¿¡ã™ã‚‹\n",
    "\n",
    "ãƒã‚¤ã‚¯ã‚¿ã‚¹ã‚¯ã¯ç¾åœ¨ã€ç”Ÿã®PCM-16ãƒ–ãƒ­ãƒƒã‚¯ã§`asyncio.Queue`ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚  \n",
    "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼šãã®ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’å–ã‚Šå‡ºã—ã€**base-64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰**ã‚’è¡Œã„ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯JSONå®‰å…¨ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¦æ±‚ã—ã¾ã™ï¼‰ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã‚’`input_audio_buffer.append`ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦Realtime WebSocketã«é€ä¿¡ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to encode audio chunks in base64\n",
    "b64 = lambda blob: base64.b64encode(blob).decode()\n",
    "\n",
    "async def queue_to_websocket(pcm_queue: asyncio.Queue[bytes], ws):\n",
    "    \"\"\"Read audio chunks from queue and send as JSON events.\"\"\"\n",
    "    try:\n",
    "        while (chunk := await pcm_queue.get()) is not None:\n",
    "            await ws.send(json.dumps({\n",
    "                \"type\": \"input_audio_buffer.append\",\n",
    "                \"audio\": b64(chunk),\n",
    "            }))\n",
    "    except websockets.ConnectionClosed:\n",
    "        print(\"WebSocket closed â€“ stopping uploader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†\n",
    "éŸ³å£°ãŒã‚µãƒ¼ãƒãƒ¼ã«åˆ°é”ã™ã‚‹ã¨ã€Realtime APIã¯**åŒã˜**WebSocketä¸Šã§JSONã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ—ãƒƒã‚·ãƒ¥ãƒãƒƒã‚¯ã—ã¾ã™ã€‚  \n",
    "ã“ã‚Œã‚‰ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ä»¥ä¸‹ã®ç‚¹ã§é‡è¦ã§ã™ï¼š\n",
    "\n",
    "* ãƒ©ã‚¤ãƒ–è»¢å†™ã®è¡¨ç¤º  \n",
    "* ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å¢—åˆ†éŸ³å£°ã®å†ç”Ÿ  \n",
    "* æ­£ç¢ºãª[`Conversation State`](https://platform.openai.com/docs/api-reference/realtime-server-events/conversation/created)ã®ç¶­æŒï¼ˆå¾Œã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒªãƒŸãƒ³ã‚°ãŒæ©Ÿèƒ½ã™ã‚‹ãŸã‚ï¼‰  \n",
    "\n",
    "\n",
    "| ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ— | åˆ°ç€ã‚¿ã‚¤ãƒŸãƒ³ã‚° | é‡è¦æ€§ | å…¸å‹çš„ãªãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ­ã‚¸ãƒƒã‚¯ |\n",
    "|------------|-----------------|---------------|-----------------------|\n",
    "| **`session.created`** | WebSocketãƒãƒ³ãƒ‰ã‚·ã‚§ã‚¤ã‚¯ç›´å¾Œ | ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒé–‹ã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€`session.id`ã‚’æä¾›ã™ã‚‹ã€‚ | ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã®ãŸã‚ã«IDã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã—ã€æ¥ç¶šã‚’ç¢ºèªã™ã‚‹ã€‚ |\n",
    "| **`session.updated`** | `session.update`å‘¼ã³å‡ºã—ã‚’é€ä¿¡ã—ãŸå¾Œ | ã‚µãƒ¼ãƒãƒ¼ãŒæ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é©ç”¨ã—ãŸã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚ | ã‚¨ã‚³ãƒ¼ã•ã‚ŒãŸè¨­å®šã‚’æ¤œæŸ»ã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã™ã‚‹ã€‚ |\n",
    "| **`conversation.item.created`** (user) | ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—çµ‚ãˆã¦ã‹ã‚‰æ•°mså¾Œï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆVADãŒç™ºç«ï¼‰ | ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚¹ãƒ­ãƒƒãƒˆã‚’äºˆç´„ã™ã‚‹ï¼›è»¢å†™ã¯ã¾ã **`null`**ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ | `state.history`ã«ã€Œè»¢å†™å¾…ã¡ã€ã¨ãƒãƒ¼ã‚¯ã•ã‚ŒãŸ*ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼*ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ãƒ¼ãƒ³ã‚’æŒ¿å…¥ã™ã‚‹ã€‚ |\n",
    "| **`conversation.item.retrieved`** | ç´„100-300mså¾Œã€éŸ³å£°è»¢å†™ãŒå®Œäº†ã—ãŸæ™‚ç‚¹ | æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼è»¢å†™ï¼ˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ä»˜ãï¼‰ã‚’æä¾›ã™ã‚‹ã€‚ | ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è»¢å†™ã§ç½®ãæ›ãˆã€å¿…è¦ã«å¿œã˜ã¦è¡¨ç¤ºã™ã‚‹ã€‚ |\n",
    "| **`response.audio.delta`** | ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒè©±ã—ã¦ã„ã‚‹é–“ã€20-60msæ¯ | PCM-16éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ï¼ˆãŠã‚ˆã³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å¢—åˆ†ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã™ã‚‹ã€‚ | å„ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã—ã¦å†ç”Ÿã™ã‚‹ï¼›ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«éƒ¨åˆ†ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã€‚ |\n",
    "| **`response.done`** | ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®æœ€å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å¾Œ | éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ãŒå®Œäº†ã—ãŸã“ã¨ã‚’é€šçŸ¥ï¼›ä½¿ç”¨çµ±è¨ˆã‚’å«ã‚€ã€‚ | ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚¿ãƒ¼ãƒ³ã‚’ç¢ºå®šã—ã€`state.latest_tokens`ã‚’æ›´æ–°ã—ã€ä½¿ç”¨é‡ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ã€‚ |\n",
    "| **`conversation.item.deleted`** | `conversation.item.delete`ã§ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹éš› | ã‚¿ãƒ¼ãƒ³ãŒå‰Šé™¤ã•ã‚Œã€ã‚µãƒ¼ãƒãƒ¼ä¸Šã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒè§£æ”¾ã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚ | ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒã‚µãƒ¼ãƒãƒ¼ã¨ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚‚å‰Šé™¤ã‚’ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 è¦ç´„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ¤œå‡ºã™ã‚‹\n",
    "Realtimeãƒ¢ãƒ‡ãƒ«ã¯**å¤§ããª32kãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦**ã‚’ä¿æŒã—ã¾ã™ãŒã€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šå¤šãã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è©°ã‚è¾¼ã‚€ã¨ã€ãã®åˆ¶é™ã«é”ã™ã‚‹ãšã£ã¨å‰ã«å“è³ªãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "æˆ‘ã€…ã®ç›®æ¨™ï¼šå®Ÿè¡Œä¸­ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒå®‰å…¨ãªé–¾å€¤ï¼ˆãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯**2,000ãƒˆãƒ¼ã‚¯ãƒ³**ï¼‰ã«è¿‘ã¥ã„ãŸã‚‰**è‡ªå‹•è¦ç´„**ã‚’è¡Œã„ã€ãã®å¾Œã€ç½®ãæ›ãˆã‚‰ã‚ŒãŸã‚¿ãƒ¼ãƒ³ã‚’ãƒ­ãƒ¼ã‚«ãƒ«*ãŠã‚ˆã³*ã‚µãƒ¼ãƒãƒ¼å´ã®ä¸¡æ–¹ã§å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã™ã€‚\n",
    "\n",
    "`response.done`ã§è¿”ã•ã‚Œã‚‹`latest_tokens`ã‚’ç›£è¦–ã—ã¾ã™ã€‚ã“ã‚ŒãŒ`SUMMARY_TRIGGER`ã‚’è¶…ãˆã€`KEEP_LAST_TURNS`ã‚ˆã‚Šå¤šãã®ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹å ´åˆã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§è¦ç´„ã‚³ãƒ«ãƒ¼ãƒãƒ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚\n",
    "\n",
    "æœ€å¾Œã®2ã‚¿ãƒ¼ãƒ³ã‚’é™¤ãã™ã¹ã¦ã‚’å˜ä¸€ã®ãƒ•ãƒ©ãƒ³ã‚¹èªæ®µè½ã«åœ§ç¸®ã—ã€ãã®å¾Œï¼š\n",
    "\n",
    "1. ãã®æ®µè½ã‚’ä¼šè©±ã®å…ˆé ­ã«æ–°ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦æŒ¿å…¥ã—ã¾ã™ã€‚\n",
    "\n",
    "2. è¦ç´„ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤ã—ã¾ã™ã€‚\n",
    "\n",
    "å¾Œã§éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è¦ç´„ã®è¨€èªã‚’å°‹ã­ã¦ã€Realtime APIä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¸ã®è¦ç´„æŒ¿å…¥ãŒæˆåŠŸã—ãŸã‹ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_summary_llm(text: str) -> str:\n",
    "    \"\"\"Call a lightweight model to summarise `text`.\"\"\"\n",
    "    resp = await asyncio.to_thread(lambda: openai.chat.completions.create(\n",
    "        model=SUMMARY_MODEL,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Summarise in French the following conversation \"\n",
    "                            \"in one concise paragraph so it can be used as \"\n",
    "                            \"context for future dialogue.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "    ))\n",
    "    return resp.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é‡è¦ãªå®Ÿè£…ã®è©³ç´°ï¼š\n",
    "- è¦ç´„ã¯ASSISTANTãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã¯ãªãã€SYSTEMãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¿½åŠ ã•ã‚Œã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã®çµæœã€é•·æ™‚é–“ã®ä¼šè©±ä¸­ã«è¦ç´„ã«ASSISTANTãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒéŸ³å£°å¿œç­”ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã«èª¤ã£ã¦åˆ‡ã‚Šæ›¿ã‚ã£ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚è¦ç´„ã«SYSTEMãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ï¼ˆè¿½åŠ ã®ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã‚‚å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼‰ã€ã“ã‚Œã‚‰ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šã®æŒ‡ç¤ºã§ã‚ã‚‹ã“ã¨ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ˜ç¢ºã«ä¼ãˆã€é€²è¡Œä¸­ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆé–“ã®ã‚„ã‚Šå–ã‚Šã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’èª¤ã£ã¦æ¡ç”¨ã™ã‚‹ã“ã¨ã‚’é˜²ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def summarise_and_prune(ws, state):\n",
    "    \"\"\"Summarise old turns, delete them serverâ€‘side, and prepend a single summary\n",
    "    turn locally + remotely.\"\"\"\n",
    "    state.summarising = True\n",
    "    print(\n",
    "        f\"âš ï¸  Token window â‰ˆ{state.latest_tokens} â‰¥ {SUMMARY_TRIGGER}. Summarisingâ€¦\",\n",
    "    )\n",
    "    old_turns, recent_turns = state.history[:-KEEP_LAST_TURNS], state.history[-KEEP_LAST_TURNS:]\n",
    "    convo_text = \"\\n\".join(f\"{t.role}: {t.text}\" for t in old_turns if t.text)\n",
    "    \n",
    "    if not convo_text:\n",
    "        print(\"Nothing to summarise (transcripts still pending).\")\n",
    "        state.summarising = False\n",
    "\n",
    "    summary_text = await run_summary_llm(convo_text) if convo_text else \"\"\n",
    "    state.summary_count += 1\n",
    "    summary_id = f\"sum_{state.summary_count:03d}\"\n",
    "    state.history[:] = [Turn(\"assistant\", summary_id, summary_text)] + recent_turns\n",
    "    \n",
    "    print_history(state)    \n",
    "\n",
    "    #Â Create summary on server\n",
    "    await ws.send(json.dumps({\n",
    "        \"type\": \"conversation.item.create\",\n",
    "        \"previous_item_id\": \"root\",\n",
    "        \"item\": {\n",
    "            \"id\": summary_id,\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"input_text\", \"text\": summary_text}],\n",
    "        },\n",
    "    }))\n",
    "\n",
    "    #Â Delete old items\n",
    "    for turn in old_turns:\n",
    "        await ws.send(json.dumps({\n",
    "            \"type\": \"conversation.item.delete\",\n",
    "            \"item_id\": turn.item_id,\n",
    "        }))\n",
    "\n",
    "    print(f\"âœ… Summary inserted ({summary_id})\")\n",
    "    \n",
    "    state.summarising = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹ã®é–¢æ•°ã¯ã€æ™‚é–“ã‚’ã‹ã‘ã¦è»¢å†™çµæœã‚’ãƒãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°ãŒã™ãã«è»¢å†™ã•ã‚Œãªã„å ´åˆã«æœ‰ç”¨ã§ã€å¾Œã§æœ€çµ‚çµæœã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_full_item(\n",
    "    ws, item_id: str, state: ConversationState, attempts: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Ask the server for a full conversation item; retry up to 5Ã— if the\n",
    "    transcript field is still null.  Resolve the waiting future when done.\n",
    "    \"\"\"\n",
    "    # If there is already a pending fetch, just await it\n",
    "    if item_id in state.waiting:\n",
    "        return await state.waiting[item_id]\n",
    "\n",
    "    fut = asyncio.get_running_loop().create_future()\n",
    "    state.waiting[item_id] = fut\n",
    "\n",
    "    await ws.send(json.dumps({\n",
    "        \"type\": \"conversation.item.retrieve\",\n",
    "        \"item_id\": item_id,\n",
    "    }))\n",
    "    item = await fut\n",
    "\n",
    "    # If transcript still missing retry (max 5Ã—)\n",
    "    if attempts < 5 and not item.get(\"content\", [{}])[0].get(\"transcript\"):\n",
    "        await asyncio.sleep(0.4 * attempts)\n",
    "        return await fetch_full_item(ws, item_id, state, attempts + 1)\n",
    "\n",
    "    # Done â€“ remove the marker\n",
    "    state.waiting.pop(item_id, None)\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "\n",
    "ä»¥ä¸‹ã®2ã¤ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ã‚»ãƒ«ã‚’ä¸­æ–­ã™ã‚‹ã¨è¨˜éŒ²ãŒåœæ­¢ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "> **æ³¨æ„:**  \n",
    "> ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€è¦ç´„ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç´ æ—©ãè¡Œã†ãŸã‚ã« `SUMMARY_TRIGGER = 2000` ã¨ `KEEP_LAST_TURNS = 2` ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚  \n",
    "> æœ¬ç•ªç’°å¢ƒã§ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‹ãƒ¼ã‚ºã«åŸºã¥ã„ã¦ã“ã‚Œã‚‰ã®å€¤ã‚’èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚  \n",
    "> - ä¸€èˆ¬çš„ãª `SUMMARY_TRIGGER` ã¯ **20,000ï½32,000ãƒˆãƒ¼ã‚¯ãƒ³** ã®ç¯„å›²ã§è¨­å®šã•ã‚Œã€ä½¿ç”¨ã‚±ãƒ¼ã‚¹ã«ãŠã„ã¦ã‚ˆã‚Šå¤§ããªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã©ã®ç¨‹åº¦ä½ä¸‹ã™ã‚‹ã‹ã«ã‚ˆã£ã¦æ±ºã¾ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Audio/configÂ knobs\n",
    "SAMPLE_RATE_HZ    = 24_000   #Â Required by pcm16\n",
    "CHUNK_DURATION_MS = 40       #Â chunk size for audio capture\n",
    "BYTES_PER_SAMPLE  = 2        #Â pcm16 = 2Â bytes/sample\n",
    "SUMMARY_TRIGGER   = 2_000    #Â Summarise when contextÂ â‰¥Â this\n",
    "KEEP_LAST_TURNS   = 2       #Â Keep these turns verbatim\n",
    "SUMMARY_MODEL     = \"gpt-4o-mini\"  #Â Cheaper, fast summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------- #\n",
    "# Realtime session                                                          #\n",
    "# --------------------------------------------------------------------------- #\n",
    "async def realtime_session(model=\"gpt-realtime\", voice=\"shimmer\", enable_playback=True):\n",
    "    \"\"\"\n",
    "    Main coroutine: connects to the Realtime endpoint, spawns helper tasks,\n",
    "    and processes incoming events in a big asyncâ€‘for loop.\n",
    "    \"\"\"\n",
    "    state = ConversationState()  # Reset state for each run\n",
    "\n",
    "    pcm_queue: asyncio.Queue[bytes] = asyncio.Queue()\n",
    "    assistant_audio: List[bytes] = []\n",
    "\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    # Open the WebSocket connection to the Realtime API                       #\n",
    "    # ----------------------------------------------------------------------- #\n",
    "    url = f\"wss://api.openai.com/v1/realtime?model={model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {openai.api_key}\"}\n",
    "\n",
    "    async with websockets.connect(url, extra_headers=headers, max_size=1 << 24) as ws:\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # Wait until server sends session.created                             #\n",
    "        # ------------------------------------------------------------------- #\n",
    "        while json.loads(await ws.recv())[\"type\"] != \"session.created\":\n",
    "            pass\n",
    "        print(\"session.created âœ…\")\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # Configure session: voice, modalities, audio formats, transcription  #\n",
    "        # ------------------------------------------------------------------- #\n",
    "        await ws.send(json.dumps({\n",
    "            \"type\": \"session.update\",\n",
    "            \"session\": {\n",
    "                \"type\": \"realtime\",\n",
    "                model: \"gpt-realtime\",\n",
    "                \"voice\": voice,\n",
    "                \"modalities\": [\"audio\", \"text\"],\n",
    "                \"input_audio_format\": \"pcm16\",\n",
    "                \"output_audio_format\": \"pcm16\",\n",
    "                \"input_audio_transcription\": {\"model\": \"gpt-4o-transcribe\"},\n",
    "            },\n",
    "        }))\n",
    "\n",
    "        # ------------------------------------------------------------------- #\n",
    "        # Launch background tasks: mic capture â†’ queue â†’ websocket            #\n",
    "        # ------------------------------------------------------------------- #\n",
    "        mic_task = asyncio.create_task(mic_to_queue(pcm_queue))\n",
    "        upl_task = asyncio.create_task(queue_to_websocket(pcm_queue, ws))\n",
    "\n",
    "        print(\"ğŸ™ï¸Â Speak nowÂ (Ctrlâ€‘C to quit)â€¦\")\n",
    "\n",
    "        try:\n",
    "            # ------------------------------------------------------------------- #\n",
    "            # Main event loop: process incoming events from the websocket         #\n",
    "            # ------------------------------------------------------------------- #\n",
    "            async for event_raw in ws:\n",
    "                event = json.loads(event_raw)\n",
    "                etype = event[\"type\"]\n",
    "\n",
    "                # --------------------------------------------------------------- #\n",
    "                # User just spoke â‡¢ conversation.item.created (role = user)        #\n",
    "                # --------------------------------------------------------------- #\n",
    "                if etype == \"conversation.item.created\" and event[\"item\"][\"role\"] == \"user\":\n",
    "                    item = event[\"item\"]\n",
    "                    text = None\n",
    "                    if item[\"content\"]:\n",
    "                        text = item[\"content\"][0].get(\"transcript\")\n",
    "                    \n",
    "                    state.history.append(Turn(\"user\", event[\"item\"][\"id\"], text))\n",
    "                    \n",
    "                    # If transcript not yet available, fetch it later\n",
    "                    if text is None:\n",
    "                        asyncio.create_task(fetch_full_item(ws, item[\"id\"], state))\n",
    "\n",
    "                # --------------------------------------------------------------- #\n",
    "                # Transcript fetched â‡¢ conversation.item.retrieved                 #\n",
    "                # --------------------------------------------------------------- #\n",
    "                elif etype == \"conversation.item.retrieved\":\n",
    "                    content = event[\"item\"][\"content\"][0]\n",
    "                    # Fill missing transcript in history\n",
    "                    for t in state.history:\n",
    "                        if t.item_id == event[\"item\"][\"id\"]:\n",
    "                            t.text = content.get(\"transcript\")\n",
    "                            break\n",
    "\n",
    "                # --------------------------------------------------------------- #\n",
    "                # Assistant audio arrives in deltas                               #\n",
    "                # --------------------------------------------------------------- #\n",
    "                elif etype == \"response.audio.delta\":\n",
    "                    assistant_audio.append(base64.b64decode(event[\"delta\"]))\n",
    "\n",
    "                # --------------------------------------------------------------- #\n",
    "                # Assistant reply finished â‡¢ response.done                        #\n",
    "                # --------------------------------------------------------------- #\n",
    "                elif etype == \"response.done\":\n",
    "                    for item in event[\"response\"][\"output\"]:\n",
    "                        if item[\"role\"] == \"assistant\":\n",
    "                            txt = item[\"content\"][0][\"transcript\"]\n",
    "                            state.history.append(Turn(\"assistant\", item[\"id\"], txt))\n",
    "                            # print(f\"\\nğŸ¤– {txt}\\n\")\n",
    "                    state.latest_tokens = event[\"response\"][\"usage\"][\"total_tokens\"]\n",
    "                    print(f\"â€”â€” response.done  (window â‰ˆ{state.latest_tokens} tokens) â€”â€”\")\n",
    "                    print_history(state)\n",
    "                    \n",
    "                    # Fetch any stillâ€‘missing user transcripts\n",
    "                    for turn in state.history:\n",
    "                        if (turn.role == \"user\"\n",
    "                            and turn.text is None\n",
    "                            and turn.item_id not in state.waiting):\n",
    "                            asyncio.create_task(\n",
    "                                fetch_full_item(ws, turn.item_id, state)\n",
    "                            )\n",
    "\n",
    "                    # Playback collected audio once reply completes\n",
    "                    if enable_playback and assistant_audio:\n",
    "                        simpleaudio.play_buffer(b\"\".join(assistant_audio), 1, BYTES_PER_SAMPLE, SAMPLE_RATE_HZ)\n",
    "                        assistant_audio.clear()\n",
    "\n",
    "                    # Summarise if context too large â€“ fire in background so we don't block dialogue\n",
    "                    if state.latest_tokens >= SUMMARY_TRIGGER and len(state.history) > KEEP_LAST_TURNS and not state.summarising:\n",
    "                        asyncio.create_task(summarise_and_prune(ws, state))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStoppingâ€¦\")\n",
    "        finally:\n",
    "            mic_task.cancel()\n",
    "            await pcm_queue.put(None)\n",
    "            await upl_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â RunÂ the realtimeÂ session (this cell blocks until you stop it)\n",
    "await realtime_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```raw\n",
    "session.created âœ…\n",
    "ğŸ™ï¸ ä»Šè©±ã—ã¦ãã ã•ã„ï¼ˆCtrlâ€‘Cã§çµ‚äº†ï¼‰â€¦\n",
    "â€”â€” response.done  (window â‰ˆ979 tokens) â€”â€”\n",
    "â€”â€” ã“ã‚Œã¾ã§ã®ä¼šè©± â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "[user     ] ç°¡å˜ãªè©±ã‚’ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ  (item_BTuMOcpUqp8qknKhLzlkA)\n",
    "[assistant] æ˜”ã€…ã€å±…å¿ƒåœ°ã®è‰¯ã„å°ã•ãªæ‘ã«ã€ã„ã¤ã‚‚ãƒˆãƒ©ãƒ–ãƒ«ã«å·»ãè¾¼ã¾ã‚Œã‚‹Whiskersã¨ã„ã†åå‰ã®çŒ«ãŒã„ã¾ã—ãŸã€‚ã‚ã‚‹æ™´ã‚ŒãŸæ—¥ã€Whiskersã¯åº­ã§ç¥ç§˜çš„ã«å…‰ã‚‹çŸ³ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚å¥½å¥‡å¿ƒæ—ºç››ãªå½¼ã¯å‰è¶³ã§ãã‚Œã‚’è§¦ã‚‹ã¨ã€ãƒãƒ³ï¼ãã®çŸ³ã¯å½¼ã«é³¥ã¨è©±ã™èƒ½åŠ›ã‚’ä¸ãˆã¾ã—ãŸã€‚Whiskersã¨æ–°ã—ã„é³¥ã®å‹é”ãŸã¡ã¯å£®å¤§ãªå†’é™ºã‚’ã—ã€è¬ã‚’è§£ãã€æ‘ã‚’æ¢æ¤œã—ã¾ã—ãŸã€‚ãã—ã¦ãã®æ—¥ã‹ã‚‰ã€Whiskersã¯æ‘ã§æœ€ã‚‚å†’é™ºå¥½ããªçŒ«ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ãŠã—ã¾ã„ã€‚  (item_BTuMPRWxqpv0ph6QM46DK)\n",
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "â€”â€” response.done  (window â‰ˆ2755 tokens) â€”â€”\n",
    "â€”â€” ã“ã‚Œã¾ã§ã®ä¼šè©± â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "[user     ] ç°¡å˜ãªè©±ã‚’ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ  (item_BTuMOcpUqp8qknKhLzlkA)\n",
    "[assistant] æ˜”ã€…ã€å±…å¿ƒåœ°ã®è‰¯ã„å°ã•ãªæ‘ã«ã€ã„ã¤ã‚‚ãƒˆãƒ©ãƒ–ãƒ«ã«å·»ãè¾¼ã¾ã‚Œã‚‹Whiskersã¨ã„ã†åå‰ã®çŒ«ãŒã„ã¾ã—ãŸã€‚ã‚ã‚‹æ™´ã‚ŒãŸæ—¥ã€Whiskersã¯åº­ã§ç¥ç§˜çš„ã«å…‰ã‚‹çŸ³ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚å¥½å¥‡å¿ƒæ—ºç››ãªå½¼ã¯å‰è¶³ã§ãã‚Œã‚’è§¦ã‚‹ã¨ã€ãƒãƒ³ï¼ãã®çŸ³ã¯å½¼ã«é³¥ã¨è©±ã™èƒ½åŠ›ã‚’ä¸ãˆã¾ã—ãŸã€‚Whiskersã¨æ–°ã—ã„é³¥ã®å‹é”ãŸã¡ã¯å£®å¤§ãªå†’é™ºã‚’ã—ã€è¬ã‚’è§£ãã€æ‘ã‚’æ¢æ¤œã—ã¾ã—ãŸã€‚ãã—ã¦ãã®æ—¥ã‹ã‚‰ã€Whiskersã¯æ‘ã§æœ€ã‚‚å†’é™ºå¥½ããªçŒ«ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ãŠã—ã¾ã„ã€‚  (item_BTuMPRWxqpv0ph6QM46DK)\n",
    "[user     ] ã¨ã¦ã‚‚é¢ç™½ã„è©±ã‚’3ã¤æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ  (item_BTuNN64LdULM21OyC4vzN)\n",
    "[assistant] ã‚‚ã¡ã‚ã‚“ã€ç¬‘ãˆã‚‹ãŠè©±ã«é£›ã³è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼š  **è©±ãã®1ï¼š** Bennyã¨ã„ã†å¿˜ã‚Œã£ã½ã„ãƒ‘ãƒ³å±‹ãŒã„ã¦ã€å¤§ããªçµå©šå¼ã®ãŸã‚ã«100å€‹ã®ã‚±ãƒ¼ã‚­ã‚’ç„¼ãã¾ã—ãŸã€‚ã—ã‹ã—å½“æ—¥ã€å½¼ã¯ãã‚Œã‚‰ã‚’ã©ã“ã«ç½®ã„ãŸã‹å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸï¼ç”ºå…¨ä½“ãŒè¡Œæ–¹ä¸æ˜ã®ã‚±ãƒ¼ã‚­ã‚’æ¢ã™ã®ã«å‚åŠ ã—ã€BennyãŒè‡ªåˆ†ã®ãƒ‘ãƒ³ãƒˆãƒªãƒ¼ã ã¨æ€ã£ã¦éš£äººã®ã‚¬ãƒ¬ãƒ¼ã‚¸ã«ä¿ç®¡ã—ã¦ã„ãŸã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚çµå©šå¼ã¯ç”ºå…¨ä½“ã®ã‚±ãƒ¼ã‚­ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®2ï¼š** Sparkyã¨ã„ã†ã„ãŸãšã‚‰å¥½ããªçŠ¬ãŒã„ã¦ã€ã„ãŸãšã‚‰ã‚’ã™ã‚‹ã®ãŒå¤§å¥½ãã§ã—ãŸã€‚ã‚ã‚‹æ—¥ã€å½¼ã¯é£¼ã„ä¸»ã®é›»è©±ã‚’ãã—ã‚€ãŠã‚‚ã¡ã‚ƒã¨äº¤æ›ã—ã€å ãˆå£°ã€ãã—ã¿éŸ³ã€æ··ä¹±ã—ãŸé€šè©±ã®é™½æ°—ãªæ··ä¹±ã‚’å¼•ãèµ·ã“ã—ã¾ã—ãŸã€‚Sparkyã®é£¼ã„ä¸»ã¯çµå±€ã€éƒµä¾¿é…é”å“¡ã¨å…¨ã¦ãã—ã¿éŸ³ã§å®Œå…¨ãªä¼šè©±ã‚’ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®3ï¼š** å°ã•ãªç”ºã§ã€Pollyã¨ã„ã†ã‚ªã‚¦ãƒ ãŒæ—©å£è¨€è‘‰ã‚’æš—å”±ã™ã‚‹ã“ã¨ã§åœ°å…ƒã®æœ‰åäººã«ãªã‚Šã¾ã—ãŸã€‚ã‚ã‚‹æ—¥ã€Pollyã¯å¸‚é•·ã«æ—©å£è¨€è‘‰æ±ºé—˜ã‚’æŒ‘ã¿ã¾ã—ãŸã€‚èˆŒãŒã‚‚ã¤ã‚Œã¦ç¬‘ã£ã¦ã„ã‚‹å¸‚é•·ã¯ã€Pollyã‚’å…¬å¼ã®ç”ºã®é“åŒ–å¸«ã«ä»»å‘½ã—ã¾ã—ãŸã€‚Pollyã¯èª‡ã‚‰ã—ã’ã«é³´ãã€ç”ºã¯ä½•æ—¥ã‚‚ç¬‘ã„å£°ã§éŸ¿ãã¾ã—ãŸã€‚  (item_BTuNNpNxki5ynSQ5c3Xsa)\n",
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "âš ï¸  Token window â‰ˆ2755 â‰¥ 2000. è¦ç´„ä¸­â€¦\n",
    "â€”â€” ã“ã‚Œã¾ã§ã®ä¼šè©± â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "[assistant] L'utilisateur a demandÃ© une histoire rapide, et l'assistant a racontÃ© celle d'un chat nommÃ© Whiskers qui, aprÃ¨s avoir trouvÃ© une pierre mystÃ©rieuse dans son jardin, a obtenu le pouvoir de parler aux oiseaux. Avec ses nouveaux amis oiseaux, Whiskers a vÃ©cu de grandes aventures, rÃ©solvant des mystÃ¨res et explorant le village, devenant ainsi le chat le plus aventurier du village.  (sum_001)\n",
    "[user     ] ã¨ã¦ã‚‚é¢ç™½ã„è©±ã‚’3ã¤æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ  (item_BTuNN64LdULM21OyC4vzN)\n",
    "[assistant] ã‚‚ã¡ã‚ã‚“ã€ç¬‘ãˆã‚‹ãŠè©±ã«é£›ã³è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼š  **è©±ãã®1ï¼š** Bennyã¨ã„ã†å¿˜ã‚Œã£ã½ã„ãƒ‘ãƒ³å±‹ãŒã„ã¦ã€å¤§ããªçµå©šå¼ã®ãŸã‚ã«100å€‹ã®ã‚±ãƒ¼ã‚­ã‚’ç„¼ãã¾ã—ãŸã€‚ã—ã‹ã—å½“æ—¥ã€å½¼ã¯ãã‚Œã‚‰ã‚’ã©ã“ã«ç½®ã„ãŸã‹å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸï¼ç”ºå…¨ä½“ãŒè¡Œæ–¹ä¸æ˜ã®ã‚±ãƒ¼ã‚­ã‚’æ¢ã™ã®ã«å‚åŠ ã—ã€BennyãŒè‡ªåˆ†ã®ãƒ‘ãƒ³ãƒˆãƒªãƒ¼ã ã¨æ€ã£ã¦éš£äººã®ã‚¬ãƒ¬ãƒ¼ã‚¸ã«ä¿ç®¡ã—ã¦ã„ãŸã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚çµå©šå¼ã¯ç”ºå…¨ä½“ã®ã‚±ãƒ¼ã‚­ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®2ï¼š** Sparkyã¨ã„ã†ã„ãŸãšã‚‰å¥½ããªçŠ¬ãŒã„ã¦ã€ã„ãŸãšã‚‰ã‚’ã™ã‚‹ã®ãŒå¤§å¥½ãã§ã—ãŸã€‚ã‚ã‚‹æ—¥ã€å½¼ã¯é£¼ã„ä¸»ã®é›»è©±ã‚’ãã—ã‚€ãŠã‚‚ã¡ã‚ƒã¨äº¤æ›ã—ã€å ãˆå£°ã€ãã—ã¿éŸ³ã€æ··ä¹±ã—ãŸé€šè©±ã®é™½æ°—ãªæ··ä¹±ã‚’å¼•ãèµ·ã“ã—ã¾ã—ãŸã€‚Sparkyã®é£¼ã„ä¸»ã¯çµå±€ã€éƒµä¾¿é…é”å“¡ã¨å…¨ã¦ãã—ã¿éŸ³ã§å®Œå…¨ãªä¼šè©±ã‚’ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®3ï¼š** å°ã•ãªç”ºã§ã€Pollyã¨ã„ã†ã‚ªã‚¦ãƒ ãŒæ—©å£è¨€è‘‰ã‚’æš—å”±ã™ã‚‹ã“ã¨ã§åœ°å…ƒã®æœ‰åäººã«ãªã‚Šã¾ã—ãŸã€‚ã‚ã‚‹æ—¥ã€Pollyã¯å¸‚é•·ã«æ—©å£è¨€è‘‰æ±ºé—˜ã‚’æŒ‘ã¿ã¾ã—ãŸã€‚èˆŒãŒã‚‚ã¤ã‚Œã¦ç¬‘ã£ã¦ã„ã‚‹å¸‚é•·ã¯ã€Pollyã‚’å…¬å¼ã®ç”ºã®é“åŒ–å¸«ã«ä»»å‘½ã—ã¾ã—ãŸã€‚Pollyã¯èª‡ã‚‰ã—ã’ã«é³´ãã€ç”ºã¯ä½•æ—¥ã‚‚ç¬‘ã„å£°ã§éŸ¿ãã¾ã—ãŸã€‚  (item_BTuNNpNxki5ynSQ5c3Xsa)\n",
    "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "âœ… è¦ç´„ãŒæŒ¿å…¥ã•ã‚Œã¾ã—ãŸ (sum_001)\n",
    "â€”â€” response.done  (window â‰ˆ2147 tokens) â€”â€”\n",
    "â€”â€” ã“ã‚Œã¾ã§ã®ä¼šè©± â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "[assistant] L'utilisateur a demandÃ© une histoire rapide, et l'assistant a racontÃ© celle d'un chat nommÃ© Whiskers qui, aprÃ¨s avoir trouvÃ© une pierre mystÃ©rieuse dans son jardin, a obtenu le pouvoir de parler aux oiseaux. Avec ses nouveaux amis oiseaux, Whiskers a vÃ©cu de grandes aventures, rÃ©solvant des mystÃ¨res et explorant le village, devenant ainsi le chat le plus aventurier du village.  (sum_001)\n",
    "[user     ] ã¨ã¦ã‚‚é¢ç™½ã„è©±ã‚’3ã¤æ•™ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã‹ï¼Ÿ  (item_BTuNN64LdULM21OyC4vzN)\n",
    "[assistant] ã‚‚ã¡ã‚ã‚“ã€ç¬‘ãˆã‚‹ãŠè©±ã«é£›ã³è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼š  **è©±ãã®1ï¼š** Bennyã¨ã„ã†å¿˜ã‚Œã£ã½ã„ãƒ‘ãƒ³å±‹ãŒã„ã¦ã€å¤§ããªçµå©šå¼ã®ãŸã‚ã«100å€‹ã®ã‚±ãƒ¼ã‚­ã‚’ç„¼ãã¾ã—ãŸã€‚ã—ã‹ã—å½“æ—¥ã€å½¼ã¯ãã‚Œã‚‰ã‚’ã©ã“ã«ç½®ã„ãŸã‹å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸï¼ç”ºå…¨ä½“ãŒè¡Œæ–¹ä¸æ˜ã®ã‚±ãƒ¼ã‚­ã‚’æ¢ã™ã®ã«å‚åŠ ã—ã€BennyãŒè‡ªåˆ†ã®ãƒ‘ãƒ³ãƒˆãƒªãƒ¼ã ã¨æ€ã£ã¦éš£äººã®ã‚¬ãƒ¬ãƒ¼ã‚¸ã«ä¿ç®¡ã—ã¦ã„ãŸã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚çµå©šå¼ã¯ç”ºå…¨ä½“ã®ã‚±ãƒ¼ã‚­ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®2ï¼š** Sparkyã¨ã„ã†ã„ãŸãšã‚‰å¥½ããªçŠ¬ãŒã„ã¦ã€ã„ãŸãšã‚‰ã‚’ã™ã‚‹ã®ãŒå¤§å¥½ãã§ã—ãŸã€‚ã‚ã‚‹æ—¥ã€å½¼ã¯é£¼ã„ä¸»ã®é›»è©±ã‚’ãã—ã‚€ãŠã‚‚ã¡ã‚ƒã¨äº¤æ›ã—ã€å ãˆå£°ã€ãã—ã¿éŸ³ã€æ··ä¹±ã—ãŸé€šè©±ã®é™½æ°—ãªæ··ä¹±ã‚’å¼•ãèµ·ã“ã—ã¾ã—ãŸã€‚Sparkyã®é£¼ã„ä¸»ã¯çµå±€ã€éƒµä¾¿é…é”å“¡ã¨å…¨ã¦ãã—ã¿éŸ³ã§å®Œå…¨ãªä¼šè©±ã‚’ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼  **è©±ãã®3ï¼š** å°ã•ãªç”ºã§ã€Pollyã¨ã„ã†ã‚ªã‚¦ãƒ ãŒæ—©å£è¨€è‘‰ã‚’æš—å”±ã™ã‚‹ã“ã¨ã§åœ°å…ƒã®æœ‰åäººã«ãªã‚Šã¾ã—ãŸã€‚ã‚ã‚‹æ—¥ã€Pollyã¯å¸‚é•·ã«æ—©å£è¨€è‘‰æ±ºé—˜ã‚’æŒ‘ã¿ã¾ã—ãŸã€‚èˆŒãŒã‚‚ã¤ã‚Œã¦ç¬‘ã£ã¦ã„ã‚‹å¸‚é•·ã¯ã€Pollyã‚’å…¬å¼ã®ç”ºã®é“åŒ–å¸«ã«ä»»å‘½ã—ã¾ã—ãŸã€‚Pollyã¯èª‡ã‚‰ã—ã’ã«é³´ãã€ç”ºã¯ä½•æ—¥ã‚‚ç¬‘ã„å£°ã§éŸ¿ãã¾ã—ãŸã€‚  (item_BTuNNpNxki5ynSQ5c3Xsa)\n",
    "[user     ]   (item_BTuPLaCv8ATdIwAQ2rLgO)\n",
    "[assistant] ã‚‚ã¡ã‚ã‚“ã§ã™ï¼ç§ãŸã¡ã®é–“ã§æœ€åˆã«æä¾›ã—ãŸè¦ç´„ã¯ãƒ•ãƒ©ãƒ³ã‚¹èªã§ã—ãŸã€‚  (item_BTuPLa7BaSQToGCVOmfBK)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ç§ãŸã¡ã¯Voice AIã¨ä¼šè©±ã‚’ã—ã¾ã—ãŸã€‚æ•°å›ã®ã‚„ã‚Šå–ã‚Šã®å¾Œã€ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒSUMMARY_MAXã«é”ã—ã€ä¼šè©±è¦ç´„ã‚¹ãƒ†ãƒƒãƒ—ãŒãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¦ç´„ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n",
    "\n",
    "ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ãŒN = 4ã ã£ãŸãŸã‚ã€æœ€åˆã®N - 2 = 2å€‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦ç´„ã—ã¾ã—ãŸï¼š\n",
    "```txt\n",
    "â€”â€” Conversation so far â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "[user     ] Can you tell me a quick story?  (item_BTuMOcpUqp8qknKhLzlkA)\n",
    "[assistant] Once upon a time, in a cozy little village, there was a cat named Whiskers who was always getting into trouble. One sunny day, Whiskers found a mysterious glowing stone in the garden. Curious, he pawed at it, and poof! The stone granted him the ability to talk to birds. Whiskers and his new bird friends had grand adventures, solving mysteries and exploring the village. And from that day on, Whiskers was known as the most adventurous cat in the village. The end.  (item_BTuMPRWxqpv0ph6QM46DK)\n",
    "```\n",
    "\n",
    "ãã®å¾Œã€ãƒ•ãƒ©ãƒ³ã‚¹èªã§è¦ç´„ã‚’ä½œæˆã—ã€`root: true`ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã—ã¦ä¼šè©±å±¥æ­´ã«æŒ¿å…¥ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¦ç´„ãŒä¼šè©±ã®æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¾ã—ãŸã€‚ãã®å¾Œã€`\"type\": \"conversation.item.delete\"`ã‚’ä½¿ç”¨ã—ã¦ã€è¦ç´„ã•ã‚ŒãŸå…ƒã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "è¦ç´„ã®æŒ¿å…¥ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã€Voice AIã«è¦ç´„ãŒã©ã®è¨€èªã§æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‹ã‚’å°‹ã­ã¾ã—ãŸã€‚æ­£ã—ãå¿œç­”ã—ã¾ã—ãŸï¼š\n",
    "\n",
    "```txt\n",
    "[assistant] Sure! The first summary I provided between us was in French.  (item_BTuPLa7BaSQToGCVOmfBK)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Â· å®Ÿä¸–ç•Œã§ã®å¿œç”¨\n",
    "\n",
    "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¯**é•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã‚‹éŸ³å£°ä½“é¨“**ã«æœ‰ç”¨ã§ã™ã€‚  \n",
    "ä»¥ä¸‹ã«ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç¤ºã—ã¾ã™ï¼š\n",
    "\n",
    "| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | ä»˜åŠ ä¾¡å€¤ | æœ‰ç”¨æ€§ |\n",
    "|----------|-------------|------------|\n",
    "| **ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆéŸ³å£°ãƒœãƒƒãƒˆ** | 24æ™‚é–“365æ—¥ã®è‡ªç„¶ãªé›»è©±å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ï¼›ãƒã‚±ãƒƒãƒˆè¦ç´„ã®è‡ªå‹•ç”Ÿæˆ | é•·æ™‚é–“ã®é¡§å®¢é€šè©±ã‚’è¦ç´„ã—ã¦åŠ¹ç‡çš„ãªå¼•ãç¶™ãã¨è¨˜éŒ²ç®¡ç†ã‚’å®Ÿç¾ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæ¥­è² è·ã‚’è»½æ¸›ã—ã¦å¿œç­”å“è³ªã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚ |\n",
    "| **èªå­¦ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼** | ä¿®æ­£ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä»˜ãã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¼šè©±ç·´ç¿’ | å­¦ç¿’è€…ã®é€²æ­©ã‚’è¿½è·¡ã—ã€ç¹°ã‚Šè¿”ã•ã‚Œã‚‹é–“é•ã„ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ã“ã¨ã§ã€å€‹äººã«åˆã‚ã›ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã‚ˆã‚ŠåŠ¹æœçš„ãªè¨€èªç¿’å¾—ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ |\n",
    "| **AIã‚»ãƒ©ãƒ”ã‚¹ãƒˆ / ã‚³ãƒ¼ãƒ** | ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨˜æ†¶ã™ã‚‹å®‰å…¨ã§å¸¸ã«åˆ©ç”¨å¯èƒ½ãªèãæ‰‹ | é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã¨æ„Ÿæƒ…çš„ãªãƒˆãƒ¼ãƒ³ã‚’è¨˜æ†¶ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã®ç¶™ç¶šæ€§ã‚’ç¶­æŒã—ã€ã‚ˆã‚Šå…±æ„Ÿçš„ã§åŠ¹æœçš„ãªä½“é¨“ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚ |\n",
    "| **ä¼šè­°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** | ãƒ©ã‚¤ãƒ–è»¢å†™ + Slackã§ã®ç°¡æ½”ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ è¦ç´„ | é•·æ™‚é–“ã®ä¼šè­°ã‚’å®Ÿè¡Œå¯èƒ½ãªè¦ç´„ã«å‡ç¸®ã—ã€ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã®æ™‚é–“ã‚’ç¯€ç´„ã—ã¦é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’è¦‹é€ƒã•ãªã„ã‚ˆã†ã«ã—ã¾ã™ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Â· æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨å‚è€ƒè³‡æ–™\n",
    "ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’è©¦ã—ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚’ã‚ãªãŸã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆã—ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "è©¦ã™ã“ã¨ãŒã§ãã‚‹ã„ãã¤ã‹ã®é …ç›®ï¼š\n",
    "| è©¦ã—ã¦ã¿ã‚‹ã“ã¨â€¦ | å­¦ã¹ã‚‹ã“ã¨ |\n",
    "|-----------|------------------|\n",
    "| **è¦ç´„ã®A/Bãƒ†ã‚¹ãƒˆ**<br/>è¦ç´„ã‚’*ã‚ªãƒ³*ã¨*ã‚ªãƒ•*ã«ã—ã¦è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚ | ãƒˆãƒªãƒŸãƒ³ã‚°ãŒå®Ÿéš›ã«ã‚ãªãŸã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã‹ã©ã†ã‹ã€ãã—ã¦ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚³ã‚¹ãƒˆã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã€‚ |\n",
    "| **è¦ç´„ã‚¹ã‚¿ã‚¤ãƒ«ã®å¤‰æ›´**<br/>ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç®‡æ¡æ›¸ãã€JSONã€è‹±èªå¯¾ãƒ•ãƒ©ãƒ³ã‚¹èªãªã©ã«å¤‰æ›´ã™ã‚‹ã€‚ | ä¸‹æµã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒã©ã®å½¢å¼ã‚’æœ€ã‚‚ã‚ˆãå¸åã™ã‚‹ã‹ã€è¨€èªé¸æŠãŒå¾Œç¶šã®å›ç­”ã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã€‚ |\n",
    "| **é–¾å€¤ã®èª¿æ•´**<br/>`SUMMARY_TRIGGER_TOKENS`ï¼ˆ2k â†’ 8kï¼‰ã§èª¿æ•´ã™ã‚‹ã€‚ | ãƒ¢ãƒ‡ãƒ«ãƒ‰ãƒªãƒ•ãƒˆã¨è¦ç´„ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã®é–“ã®æœ€é©ãªãƒãƒ©ãƒ³ã‚¹ã€‚ |\n",
    "| **ã‚³ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°**<br/>è¦ç´„å‰å¾Œã®`usage.total_tokens`ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ã€‚ | å…·ä½“çš„ãªROIï¼šä¼šè©±1æ™‚é–“ã‚ãŸã‚Šã®ãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„é‡ã€‚ |\n",
    "\n",
    "\n",
    "### ãƒªã‚½ãƒ¼ã‚¹ï¼š\n",
    "- [OpenAI Realtime Guide](https://platform.openai.com/docs/guides/realtime)\n",
    "- [OpenAI Realtime Conversations](https://platform.openai.com/docs/guides/realtime-conversations)\n",
    "- [OpenAI Realtime API Reference](https://platform.openai.com/docs/api-reference/realtime)\n",
    "- [Voice AI and Voice Agents](https://voiceaiandvoiceagents.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
