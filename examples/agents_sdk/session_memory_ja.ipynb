{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bcfc573",
   "metadata": {},
   "source": [
    "# コンテキストエンジニアリング - OpenAI Agents SDKのセッションを使用した短期記憶管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab798a",
   "metadata": {},
   "source": [
    "AIエージェントは多くの場合、**長時間にわたる複数ターンのやり取り**で動作し、適切な**コンテキスト**のバランスを保つことが重要です。引き継ぐ情報が多すぎると、モデルは注意散漫、非効率、または完全な失敗のリスクを負います。保持する情報が少なすぎると、エージェントは一貫性を失います。\n",
    "\n",
    "ここで、コンテキストとは、モデルが一度に注意を向けることができるトークンの総ウィンドウ（入力 + 出力）を指します。[GPT-5](https://platform.openai.com/docs/models/gpt-5)の場合、この容量は最大272kの入力トークンと128kの出力トークンですが、このような大きなウィンドウでも、整理されていない履歴、冗長なツール結果、またはノイズの多い検索結果によって圧迫される可能性があります。これにより、コンテキスト管理は最適化だけでなく、必要不可欠なものとなります。\n",
    "\n",
    "このクックブックでは、**[OpenAI Agents SDK](https://github.com/openai/openai-agents-python)の`Session`オブジェクトを使用してコンテキストを効果的に管理する方法**を探求し、エージェントを高速、信頼性が高く、コスト効率的に保つための2つの実証済みのコンテキスト管理技術—**トリミング**と**圧縮**—に焦点を当てます。\n",
    "\n",
    "#### コンテキスト管理が重要な理由\n",
    "\n",
    "* **長いスレッド全体での持続的な一貫性** – 古い詳細を引きずることなく、エージェントを最新のユーザー目標に固定し続けます。セッションレベルのトリミングと要約により、「昨日の計画」が今日の要求を上書きすることを防ぎます。\n",
    "* **より高いツール呼び出し精度** – 焦点を絞ったコンテキストにより、関数の選択と引数の入力が改善され、マルチツール実行中の再試行、タイムアウト、連鎖的な失敗が減少します。\n",
    "* **低レイテンシ & コスト削減** – より小さく、より鋭いプロンプトにより、ターンあたりのトークンと注意負荷が削減されます。\n",
    "* **エラー & 幻覚の封じ込め** – 要約は以前の間違いを修正または省略する「クリーンルーム」として機能し、トリミングにより悪い事実（「コンテキスト汚染」）をターンごとに増幅することを回避します。\n",
    "* **より簡単なデバッグ & 可観測性** – 安定した要約と境界のある履歴により、ログが比較可能になります：要約を差分比較し、回帰を特定し、失敗を確実に再現できます。\n",
    "* **マルチ問題とハンドオフの耐性** – マルチ問題チャットでは、問題ごとのミニ要約により、エージェントは一貫性を保ちながら一時停止/再開、人間へのエスカレーション、または他のエージェントへのハンドオフが可能になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e1913",
   "metadata": {},
   "source": [
    "![AI エージェントにおけるメモリ比較](../../images/memory_comparison.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8fdc3",
   "metadata": {},
   "source": [
    "[OpenAI Responses API](https://platform.openai.com/docs/api-reference/responses/create#responses-create-previous_response_id)は、組み込みの状態と`previous_response_id`によるメッセージチェーンを通じて**基本的なメモリサポート**を提供しています。\n",
    "\n",
    "前回のレスポンスの`id`を`previous_response_id`として渡すことで会話を継続できます。または、出力をリストに収集し、次のレスポンスの`input`として再送信することで、手動でコンテキストを管理することもできます。\n",
    "\n",
    "しかし、**自動メモリ管理**は提供されません。そこで**Agents SDK**の出番です。このSDKはResponsesの上に[セッションメモリ](https://openai.github.io/openai-agents-python/sessions/)を提供するため、手動で`response.output`を追加したり、IDを自分で追跡したりする必要がなくなります。セッションが**メモリオブジェクト**となり、単純に`session.run(\"...\")`を繰り返し呼び出すだけで、SDKがコンテキスト長、履歴、継続性を処理してくれます。これにより、一貫性のあるマルチターンエージェントの構築がはるかに簡単になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068564c",
   "metadata": {},
   "source": [
    "#### 実際のシナリオ\n",
    "\n",
    "これらの技術を実践的な例で説明します。長時間実行されるタスクの一般的な例として、以下のようなものがあります：\n",
    "\n",
    "* **マルチターンカスタマーサービス会話**\n",
    "ハードウェアとソフトウェアの両方を含む技術製品に関する長時間の会話では、顧客は時間の経過とともに複数の問題を提起することがよくあります。エージェントは、過去のすべての詳細を引きずるのではなく、必要最小限の情報のみを保持しながら、一貫性を保ち、目標に集中し続ける必要があります。\n",
    "\n",
    "#### 取り上げる技術\n",
    "\n",
    "これらの課題に対処するため、OpenAI Agents SDKを使用した2つの具体的なアプローチを紹介します：\n",
    "\n",
    "- **コンテキストトリミング** – 古いターンを削除し、最新のNターンのみを保持する。\n",
    "  - **メリット**\n",
    "\n",
    "    * **決定論的でシンプル：** 要約器の変動がなく、状態の推論や実行の再現が容易。\n",
    "    * **レイテンシの追加なし：** 履歴を圧縮するための追加のモデル呼び出しが不要。\n",
    "    * **最近の作業の忠実性：** 最新のツール結果、パラメータ、エッジケースが逐語的に保持される—デバッグに最適。\n",
    "    * **「要約ドリフト」のリスクが低い：** 事実を再解釈や圧縮することがない。\n",
    "\n",
    "    **デメリット**\n",
    "\n",
    "    * **長期コンテキストの急激な忘却：** 重要な初期の制約、ID、決定がNを超えてスクロールすると消失する可能性。\n",
    "    * **ユーザーエクスペリエンスの「健忘症」：** エージェントが長いセッションの途中で約束や以前の設定を「忘れた」ように見える。\n",
    "    * **シグナルの無駄：** 古いターンには再利用可能な知識（要件、制約）が含まれている可能性があるが、それが削除される。\n",
    "    * **トークンスパイクの可能性：** 最近のターンに巨大なツールペイロードが含まれている場合、最新Nターンでもコンテキストが爆発する可能性。\n",
    "\n",
    "  - **最適な使用場面**\n",
    "\n",
    "    - 会話内のタスクが互いに独立しており、重複しないコンテキストで、以前の詳細を引き継ぐ必要がない場合。\n",
    "    - 予測可能性、簡単な評価、低レイテンシが必要な場合（運用自動化、CRM/APIアクション）。\n",
    "    - 会話の有用なコンテキストがローカルな場合（最近のステップが遠い履歴よりもはるかに重要）。\n",
    "\n",
    "- **コンテキスト要約** – 以前のメッセージ（アシスタント、ユーザー、ツールなど）を構造化された短い要約に圧縮し、会話履歴に注入する。\n",
    "\n",
    "  - **メリット**\n",
    "\n",
    "    * **長期記憶をコンパクトに保持：** 過去の要件、決定、根拠がNを超えて持続。\n",
    "    * **よりスムーズなUX：** エージェントが長いセッション全体で約束や制約を「記憶」。\n",
    "    * **コスト制御されたスケール：** 1つの簡潔な要約で数百のターンを置き換え可能。\n",
    "    * **検索可能なアンカー：** 単一の合成アシスタントメッセージが安定した「これまでの世界の状態」となる。\n",
    "\n",
    "    **デメリット**\n",
    "\n",
    "    * **要約の損失とバイアス：** 詳細が削除されたり、重み付けが間違ったりする可能性；微妙な制約が消失する可能性。\n",
    "    * **レイテンシとコストのスパイク：** 各更新でモデル作業（および潜在的にツールトリムロジック）が追加。\n",
    "    * **エラーの複合：** 悪い事実が要約に入ると、将来の動作を**汚染**する可能性（「コンテキスト汚染」）。\n",
    "    * **観測可能性の複雑さ：** 監査可能性と評価のために要約プロンプト/出力をログに記録する必要。\n",
    "\n",
    "  - **最適な使用場面**\n",
    "\n",
    "    - 計画/コーチング、RAG重要分析、ポリシーQ&Aなど、フロー全体で収集されたコンテキストが必要なユースケースがある場合。\n",
    "    - 長期間にわたる継続性が必要で、関連タスクを解決するために重要な詳細を引き継ぐ必要がある場合。\n",
    "    - セッションがNターンを超えるが、決定、ID、制約を確実に保持する必要がある場合。\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765f2b8",
   "metadata": {},
   "source": [
    "**簡単な比較**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e5bf7",
   "metadata": {},
   "source": [
    "| 次元         | **トリミング（最新N回の会話）**         | **要約（古い会話 → 生成された要約）** |\n",
    "| ----------------- | ------------------------------- | ------------------------------------ |\n",
    "| レイテンシ / コスト    | 最低（追加の呼び出しなし）     | 要約更新時により高い |\n",
    "| 長期記憶    | 弱い（ハードカットオフ）         | 強い（コンパクトな引き継ぎ）   |\n",
    "| リスクタイプ         | コンテキストの損失                | コンテキストの歪み/汚染     |\n",
    "| 可観測性     | シンプルなログ                 | 要約プロンプト/出力のログが必要 |\n",
    "| 評価の安定性    | 高い                        | 堅牢な要約評価が必要       |\n",
    "| 最適な用途          | ツール重視の操作、短いワークフロー | アナリスト/コンシェルジュ、長いスレッド      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc613968",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "このクックブックを実行する前に、以下のアカウントを設定し、いくつかのセットアップ作業を完了する必要があります。これらの前提条件は、このプロジェクトで使用されるAPIと連携するために必要不可欠です。\n",
    "\n",
    "#### ステップ0: OpenAIアカウントと`OPENAI_API_KEY`\n",
    "\n",
    "- **目的:**  \n",
    "  このクックブックで紹介されている言語モデルにアクセスし、Agents SDKを使用するためにOpenAIアカウントが必要です。\n",
    "\n",
    "- **手順:**  \n",
    "  まだアカウントをお持ちでない場合は、[OpenAIアカウントにサインアップ](https://openai.com)してください。アカウントを取得したら、[OpenAI API Keysページ](https://platform.openai.com/api-keys)にアクセスしてAPIキーを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094205e7",
   "metadata": {},
   "source": [
    "**ワークフローを実行する前に、環境変数を設定してください：**\n",
    "\n",
    "```\n",
    "# Your openai key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "```\n",
    "\n",
    "または、agentsライブラリをインポートして`set_default_openai_key`関数を使用することで、エージェントが使用するOpenAI APIキーを設定することもできます。\n",
    "\n",
    "```\n",
    "from agents import set_default_openai_key\n",
    "set_default_openai_key(\"YOUR_API_KEY\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9a109",
   "metadata": {},
   "source": [
    "#### ステップ1: 必要なライブラリのインストール\n",
    "\n",
    "以下では、`openai-agents`ライブラリ（[OpenAI Agents SDK](https://github.com/openai/openai-agents-python)）をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87818100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai-agents nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6348e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b39f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import set_tracing_disabled\n",
    "set_tracing_disabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b7952",
   "metadata": {},
   "source": [
    "インストールしたライブラリをテストするために、エージェントを定義して実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating AI agents ensures reliability, safety, ethical alignment, performance accuracy, and helps avoid biases, improving overall trust and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"Reply very concisely.\",\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"Tell me why it is important to evaluate AI agents.\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39dab9d",
   "metadata": {},
   "source": [
    "### エージェントの定義\n",
    "\n",
    "Agents SDK ライブラリから必要なコンポーネントを定義することから始めることができます。エージェント作成時にユースケースに基づいて指示が追加されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2725d9d",
   "metadata": {},
   "source": [
    "#### カスタマーサービス担当者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4451ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_agent = Agent(\n",
    "    name=\"Customer Support Assistant\",\n",
    "    model=\"gpt-5\",\n",
    "    instructions=(\n",
    "        \"You are a patient, step-by-step IT support assistant. \"\n",
    "        \"Your role is to help customers troubleshoot and resolve issues with devices and software. \"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"- Be concise and use numbered steps where possible.\\n\"\n",
    "        \"- Ask only one focused, clarifying question at a time before suggesting next actions.\\n\"\n",
    "        \"- Track and remember multiple issues across the conversation; update your understanding as new problems emerge.\\n\"\n",
    "        \"- When a problem is resolved, briefly confirm closure before moving to the next.\\n\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8074e05",
   "metadata": {},
   "source": [
    "## コンテキストトリミング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8cf80",
   "metadata": {},
   "source": [
    "#### カスタムセッションオブジェクトの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993098b",
   "metadata": {},
   "source": [
    "[OpenAI Agents Python SDK](https://openai.github.io/openai-agents-python/)の[Session](https://openai.github.io/openai-agents-python/sessions/)オブジェクトを使用しています。以下は**最後のN回のターンのみを保持する**`TrimmingSession`の実装です（「ターン」とは、1つのユーザーメッセージと次のユーザーメッセージまでのすべて—アシスタントの返答やツール呼び出し/結果を含む）。これはインメモリで動作し、書き込みと読み込みのたびに自動的にトリミングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "95ed36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "from collections import deque\n",
    "from typing import Any, Deque, Dict, List, cast\n",
    "\n",
    "from agents.memory.session import SessionABC\n",
    "from agents.items import TResponseInputItem  # dict-like item\n",
    "\n",
    "ROLE_USER = \"user\"\n",
    "\n",
    "\n",
    "def _is_user_msg(item: TResponseInputItem) -> bool:\n",
    "    \"\"\"Return True if the item represents a user message.\"\"\"\n",
    "    # Common dict-shaped messages\n",
    "    if isinstance(item, dict):\n",
    "        role = item.get(\"role\")\n",
    "        if role is not None:\n",
    "            return role == ROLE_USER\n",
    "        # Some SDKs: {\"type\": \"message\", \"role\": \"...\"}\n",
    "        if item.get(\"type\") == \"message\":\n",
    "            return item.get(\"role\") == ROLE_USER\n",
    "    # Fallback: objects with a .role attr\n",
    "    return getattr(item, \"role\", None) == ROLE_USER\n",
    "\n",
    "\n",
    "class TrimmingSession(SessionABC):\n",
    "    \"\"\"\n",
    "    Keep only the last N *user turns* in memory.\n",
    "\n",
    "    A turn = a user message and all subsequent items (assistant/tool calls/results)\n",
    "    up to (but not including) the next user message.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, session_id: str, max_turns: int = 8):\n",
    "        self.session_id = session_id\n",
    "        self.max_turns = max(1, int(max_turns))\n",
    "        self._items: Deque[TResponseInputItem] = deque()  # chronological log\n",
    "        self._lock = asyncio.Lock()\n",
    "\n",
    "    # ---- SessionABC API ----\n",
    "\n",
    "    async def get_items(self, limit: int | None = None) -> List[TResponseInputItem]:\n",
    "        \"\"\"Return history trimmed to the last N user turns (optionally limited to most-recent `limit` items).\"\"\"\n",
    "        async with self._lock:\n",
    "            trimmed = self._trim_to_last_turns(list(self._items))\n",
    "            return trimmed[-limit:] if (limit is not None and limit >= 0) else trimmed\n",
    "\n",
    "    async def add_items(self, items: List[TResponseInputItem]) -> None:\n",
    "        \"\"\"Append new items, then trim to last N user turns.\"\"\"\n",
    "        if not items:\n",
    "            return\n",
    "        async with self._lock:\n",
    "            self._items.extend(items)\n",
    "            trimmed = self._trim_to_last_turns(list(self._items))\n",
    "            self._items.clear()\n",
    "            self._items.extend(trimmed)\n",
    "\n",
    "    async def pop_item(self) -> TResponseInputItem | None:\n",
    "        \"\"\"Remove and return the most recent item (post-trim).\"\"\"\n",
    "        async with self._lock:\n",
    "            return self._items.pop() if self._items else None\n",
    "\n",
    "    async def clear_session(self) -> None:\n",
    "        \"\"\"Remove all items for this session.\"\"\"\n",
    "        async with self._lock:\n",
    "            self._items.clear()\n",
    "\n",
    "    # ---- Helpers ----\n",
    "\n",
    "    def _trim_to_last_turns(self, items: List[TResponseInputItem]) -> List[TResponseInputItem]:\n",
    "        \"\"\"\n",
    "        Keep only the suffix containing the last `max_turns` user messages and everything after\n",
    "        the earliest of those user messages.\n",
    "\n",
    "        If there are fewer than `max_turns` user messages (or none), keep all items.\n",
    "        \"\"\"\n",
    "        if not items:\n",
    "            return items\n",
    "\n",
    "        count = 0\n",
    "        start_idx = 0  # default: keep all if we never reach max_turns\n",
    "\n",
    "        # Walk backward; when we hit the Nth user message, mark its index.\n",
    "        for i in range(len(items) - 1, -1, -1):\n",
    "            if _is_user_msg(items[i]):\n",
    "                count += 1\n",
    "                if count == self.max_turns:\n",
    "                    start_idx = i\n",
    "                    break\n",
    "\n",
    "        return items[start_idx:]\n",
    "\n",
    "    # ---- Optional convenience API ----\n",
    "\n",
    "    async def set_max_turns(self, max_turns: int) -> None:\n",
    "        async with self._lock:\n",
    "            self.max_turns = max(1, int(max_turns))\n",
    "            trimmed = self._trim_to_last_turns(list(self._items))\n",
    "            self._items.clear()\n",
    "            self._items.extend(trimmed)\n",
    "\n",
    "    async def raw_items(self) -> List[TResponseInputItem]:\n",
    "        \"\"\"Return the untrimmed in-memory log (for debugging).\"\"\"\n",
    "        async with self._lock:\n",
    "            return list(self._items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd5b28",
   "metadata": {},
   "source": [
    "以下のように、`max_turns=3`で実装したカスタムセッションオブジェクトを定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "951ad6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the last 8 turns (user + assistant/tool interactions)\n",
    "session = TrimmingSession(\"my_session\", max_turns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab99cd",
   "metadata": {},
   "source": [
    "**適切な`max_turns`の選び方**\n",
    "\n",
    "このパラメータを決定するには、通常、会話履歴を使った実験が必要です。一つのアプローチは、会話全体のターン数の合計を抽出し、その分布を分析することです。もう一つの選択肢は、LLMを使って会話を評価することです。各会話に含まれるタスクや問題の数を特定し、問題あたりに必要なターン数の平均を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c59d40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"There is a red light blinking on my laptop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "03b15552",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(\n",
    "    support_agent,\n",
    "    message,\n",
    "    session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c94beb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = await session.get_items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "626a6e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'There is a red light blinking on my laptop.', 'role': 'user'},\n",
       " {'id': 'rs_68be66229c008190aa4b3c5501f397080fdfa41323fb39cb',\n",
       "  'summary': [],\n",
       "  'type': 'reasoning',\n",
       "  'content': []},\n",
       " {'id': 'msg_68be662f704c8190969bdf539701a3e90fdfa41323fb39cb',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': 'A blinking red light usually indicates a power/battery or hardware fault, but the meaning varies by brand.\\n\\nWhat is the exact make and model of your laptop?\\n\\nWhile you check that, please try these quick checks:\\n1) Note exactly where the red LED is (charging port, power button, keyboard edge) and the blink pattern (e.g., constant blink, 2 short/1 long).\\n2) Plug the charger directly into a known‑good wall outlet (no power strip), ensure the charger tip is fully seated, and look for damage to the cable/port. See if the LED behavior changes.\\n3) Leave it on charge for 30 minutes in case the battery is critically low.\\n4) Power reset: unplug the charger; if the battery is removable, remove it. Hold the power button for 20–30 seconds. Reconnect power (and battery) and try turning it on.\\n5) Tell me the LED location, blink pattern, and what changed after these steps.',\n",
       "    'type': 'output_text',\n",
       "    'logprobs': []}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "51f60675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example flow\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"I am using a macbook pro and it has some overheating issues too.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"I see. Let's check your firmware version.\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Firmware v1.0.3; still failing.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Could you please try a factory reset?\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Reset done; error 42 now.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Leave it on charge for 30 minutes in case the battery is critically low. Is there any other error message?\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Yes, I see error 404 now.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Do you see it on the browser while accessing a website?\"}])\n",
    "# At this point, with max_turns=3, everything *before* the earliest of the last 3 user\n",
    "# messages is summarized into a synthetic pair, and the last 3 turns remain verbatim.\n",
    "\n",
    "history = await session.get_items()\n",
    "# Pass `history` into your agent runner / responses call as the conversation context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6dc29a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "07430b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Firmware v1.0.3; still failing.'},\n",
       " {'role': 'assistant', 'content': 'Could you please try a factory reset?'},\n",
       " {'role': 'user', 'content': 'Reset done; error 42 now.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Leave it on charge for 30 minutes in case the battery is critically low. Is there any other error message?'},\n",
       " {'role': 'user', 'content': 'Yes, I see error 404 now.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Do you see it on the browser while accessing a website?'}]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8de9a",
   "metadata": {},
   "source": [
    "以下では、`max_turns=3`でのトリミングセッションの動作を確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42471c87",
   "metadata": {},
   "source": [
    "![セッションでのコンテキストトリミング](../../images/trimingSession.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dd9c5",
   "metadata": {},
   "source": [
    "**「ターン」とは何か**\n",
    "\n",
    "* **ターン** = 1つの**ユーザー**メッセージ**とそれに続くすべて**（アシスタントの返信、推論、ツール呼び出し、ツール結果）が**次のユーザーメッセージまで**続く単位。\n",
    "\n",
    "**トリミングが発生するタイミング**\n",
    "\n",
    "* **書き込み時**: `add_items(...)`が新しいアイテムを追加し、その後すぐに保存された履歴をトリミングします。\n",
    "* **読み込み時**: `get_items(...)`は**トリミングされた**ビューを返します（書き込みをバイパスしても、読み込み時に古いターンが漏れることはありません）。\n",
    "\n",
    "**保持するものを決定する方法**\n",
    "\n",
    "1. `role == \"user\"`を持つアイテムを**ユーザーメッセージ**として扱います（`_is_user_msg`経由）。\n",
    "2. 履歴を**後ろから**スキャンし、最後の**N**個のユーザーメッセージ（`max_turns`）のインデックスを収集します。\n",
    "3. それらN個のユーザーメッセージの中で**最も早い**インデックスを見つけます。\n",
    "4. **そのインデックスから最後まですべてを保持**し、それより前のものはすべて削除します。\n",
    "\n",
    "これにより、各完全なターン境界が保持されます：保持される最も早いユーザーメッセージがインデックス`k`にある場合、`k`の後に来たすべてのアシスタント/ツールアイテムも保持されます。\n",
    "\n",
    "**簡単な例**\n",
    "\n",
    "履歴（古い → 新しい）：\n",
    "\n",
    "```\n",
    "0: user(\"Hi\")\n",
    "1: assistant(\"Hello!\")\n",
    "2: tool_call(\"lookup\")\n",
    "3: tool_result(\"…\")\n",
    "4: user(\"It didn't work\")\n",
    "5: assistant(\"Try rebooting\")\n",
    "6: user(\"Rebooted, now error 42\")\n",
    "7: assistant(\"On it\")\n",
    "```\n",
    "\n",
    "`max_turns = 2`の場合、最後の2つのユーザーメッセージはインデックス**4**と**6**にあります。\n",
    "それらの中で最も早いのは**4** → アイテム**4..7**を保持し、**0..3**を削除します。\n",
    "\n",
    "**これがうまく機能する理由**\n",
    "\n",
    "* 常に**完全な**ターンを保持するため、アシスタントは必要な直近のコンテキスト（ユーザーの最後の質問とその間のアシスタント/ツールステップの両方）を保持できます。\n",
    "* 単なるメッセージではなく、古いターンを丸ごと破棄することで、コンテキストの肥大化を防ぎます。\n",
    "\n",
    "**カスタマイズのオプション**\n",
    "\n",
    "* 初期化時に`max_turns`を変更。\n",
    "* アイテムスキーマが異なる場合は`_is_user_msg(...)`を調整。\n",
    "* **メッセージ数**や**トークン数**で制限したい場合は、`_trim_to_last_turns(...)`を置き換えるか、トークンを測定する2番目のパスを追加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa349f",
   "metadata": {},
   "source": [
    "## コンテキスト要約"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c453e",
   "metadata": {},
   "source": [
    "履歴が`max_turns`を超えると、最新のNユーザーターンをそのまま保持し、**それより古いものをすべて2つの合成メッセージに要約します**：\n",
    "\n",
    "* `user`: *\"これまでの会話を要約してください。\"*\n",
    "* `assistant`: *{生成された要約}*\n",
    "\n",
    "ユーザーからの要約リクエストのシャドウプロンプトは、ユーザーとアシスタント間のチャットフローを混乱させることなく、会話の自然な流れを保つために追加されます。生成された要約の最終版は、アシスタントメッセージに注入されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b8d8c",
   "metadata": {},
   "source": [
    "**要約プロンプト**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380492d",
   "metadata": {},
   "source": [
    "適切に作成された要約プロンプトは、会話のコンテキストを保持するために不可欠であり、常に特定のユースケースに合わせて調整する必要があります。これは**カスタマーサポート担当者が次の担当者にケースを引き継ぐ**ような状況と考えてください。スムーズに継続するために、どのような簡潔でありながら重要な詳細情報が必要でしょうか？プロンプトは適切なバランスを取る必要があります：不要な情報で過負荷にならず、かつ重要なコンテキストが失われるほど簡素でもない状態です。このバランスを実現するには、詳細レベルを微調整するための慎重な設計と継続的な実験が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7be8b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_PROMPT = \"\"\"\n",
    "You are a senior customer-support assistant for tech devices, setup, and software issues.\n",
    "Compress the earlier conversation into a precise, reusable snapshot for future turns.\n",
    "\n",
    "Before you write (do this silently):\n",
    "- Contradiction check: compare user claims with system instructions and tool definitions/logs; note any conflicts or reversals.\n",
    "- Temporal ordering: sort key events by time; the most recent update wins. If timestamps exist, keep them.\n",
    "- Hallucination control: if any fact is uncertain/not stated, mark it as UNVERIFIED rather than guessing.\n",
    "\n",
    "Write a structured, factual summary ≤ 200 words using the sections below (use the exact headings):\n",
    "\n",
    "• Product & Environment:\n",
    "  - Device/model, OS/app versions, network/context if mentioned.\n",
    "\n",
    "• Reported Issue:\n",
    "  - Single-sentence problem statement (latest state).\n",
    "\n",
    "• Steps Tried & Results:\n",
    "  - Chronological bullets (include tool calls + outcomes, errors, codes).\n",
    "\n",
    "• Identifiers:\n",
    "  - Ticket #, device serial/model, account/email (only if provided).\n",
    "\n",
    "• Timeline Milestones:\n",
    "  - Key events with timestamps or relative order (e.g., 10:32 install → 10:41 error).\n",
    "\n",
    "• Tool Performance Insights:\n",
    "  - What tool calls worked/failed and why (if evident).\n",
    "\n",
    "• Current Status & Blockers:\n",
    "  - What’s resolved vs pending; explicit blockers preventing progress.\n",
    "\n",
    "• Next Recommended Step:\n",
    "  - One concrete action (or two alternatives) aligned with policies/tools.\n",
    "\n",
    "Rules:\n",
    "- Be concise, no fluff; use short bullets, verbs first.\n",
    "- Do not invent new facts; quote error strings/codes exactly when available.\n",
    "- If previous info was superseded, note “Superseded:” and omit details unless critical.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f7b15",
   "metadata": {},
   "source": [
    "**メモリ要約プロンプト設計の主要原則**\n",
    "\n",
    "* **マイルストーン:** 会話における重要なイベントを強調する—例えば、問題が解決された時、価値のある情報が発見された時、または必要な詳細がすべて収集された時など。\n",
    "\n",
    "* **ユースケース特化:** 圧縮プロンプトを特定のユースケースに合わせて調整する。同じタスクを解決する際に、人間がワーキングメモリで情報をどのように追跡し思い出すかを考える。\n",
    "\n",
    "* **矛盾チェック:** 要約が自己矛盾せず、システム指示やツール定義と競合しないことを確認する。これは推論モデルにとって特に重要で、コンテキストにおける競合が起こりやすい。\n",
    "\n",
    "* **タイムスタンプと時間的流れ:** 要約にイベントのタイミングを組み込む。これにより、モデルが順序立てて更新について推論でき、タイムライン上で最新のメモリを忘れたり思い出したりする際の混乱を減らす。\n",
    "\n",
    "* **チャンク化:** 詳細を長い段落ではなく、カテゴリやセクションに整理する。構造化されたグループ化により、LLMが情報の断片間の関係を理解する能力が向上する。\n",
    "\n",
    "* **ツールパフォーマンスの洞察:** マルチターンでツールを活用したインタラクションから得られた教訓を捉える—例えば、特定のクエリに対してどのツールが効果的に機能したか、そしてその理由を記録する。これらの洞察は将来のステップを導く上で価値がある。\n",
    "\n",
    "* **ガイダンスと例:** 明確なガイダンスで要約を導く。可能な場合は、会話履歴から具体的な例を抽出して、将来のターンをより根拠に基づいた、コンテキストに富んだものにする。\n",
    "\n",
    "* **幻覚制御:** 含める内容について正確性を保つ。要約における軽微な幻覚でさえ、前方に伝播し、将来のコンテキストを不正確性で汚染する可能性がある。\n",
    "\n",
    "* **モデル選択:** ユースケース要件、要約の長さ、レイテンシとコストのトレードオフに基づいて要約モデルを選択する。場合によっては、AIエージェント自体と同じモデルを使用することが有利になることもある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6c2265ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMSummarizer:\n",
    "    def __init__(self, client, model=\"gpt-4o\", max_tokens=400, tool_trim_limit=600):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.max_tokens = max_tokens\n",
    "        self.tool_trim_limit = tool_trim_limit\n",
    "\n",
    "    async def summarize(self, messages: List[Item]) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Create a compact summary from `messages`.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, str]: The shadow user line to keep dialog natural,\n",
    "            and the model-generated summary text.\n",
    "        \"\"\"\n",
    "        user_shadow = \"Summarize the conversation we had so far.\"\n",
    "        TOOL_ROLES = {\"tool\", \"tool_result\"}\n",
    "\n",
    "        def to_snippet(m: Item) -> str | None:\n",
    "            role = (m.get(\"role\") or \"assistant\").lower()\n",
    "            content = (m.get(\"content\") or \"\").strip()\n",
    "            if not content:\n",
    "                return None\n",
    "            # Trim verbose tool outputs to keep prompt compact    \n",
    "            if role in TOOL_ROLES and len(content) > self.tool_trim_limit:\n",
    "                content = content[: self.tool_trim_limit] + \" …\"\n",
    "            return f\"{role.upper()}: {content}\"\n",
    "\n",
    "        # Build compact, trimmed history\n",
    "        history_snippets = [s for m in messages if (s := to_snippet(m))]\n",
    "\n",
    "        prompt_messages = [\n",
    "            {\"role\": \"system\", \"content\": SUMMARY_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": \"\\n\".join(history_snippets)},\n",
    "        ]\n",
    "\n",
    "        resp = await asyncio.to_thread(\n",
    "            self.client.responses.create,\n",
    "            model=self.model,\n",
    "            input=prompt_messages,\n",
    "            max_output_tokens=self.max_tokens,\n",
    "        )\n",
    "\n",
    "        summary = resp.output_text\n",
    "        await asyncio.sleep(0)  # yield control\n",
    "        return user_shadow, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "30ca3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections import deque\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "\n",
    "Record = Dict[str, Dict[str, Any]]  # {\"msg\": {...}, \"meta\": {...}}\n",
    "\n",
    "class SummarizingSession:\n",
    "    \"\"\"\n",
    "    Session that keeps only the last N *user turns* verbatim and summarizes the rest.\n",
    "\n",
    "    - A *turn* starts at a real user message and includes everything until the next real user message.\n",
    "    - When the number of real user turns exceeds `context_limit`, everything before the earliest\n",
    "      of the last `keep_last_n_turns` user-turn starts is summarized into a synthetic user→assistant pair.\n",
    "    - Stores full records (message + metadata). Exposes:\n",
    "        • get_items():           model-safe messages only (no metadata)\n",
    "        • get_full_history():    [{\"message\": msg, \"metadata\": meta}, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # Only these keys are ever sent to the model; the rest live in metadata.\n",
    "    _ALLOWED_MSG_KEYS = {\"role\", \"content\", \"name\"}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keep_last_n_turns: int = 3,\n",
    "        context_limit: int = 3,\n",
    "        summarizer: Optional[\"Summarizer\"] = None,\n",
    "        session_id: Optional[str] = None,\n",
    "    ):\n",
    "        assert context_limit >= 1\n",
    "        assert keep_last_n_turns >= 0\n",
    "        assert keep_last_n_turns <= context_limit, \"keep_last_n_turns should not be greater than context_limit\"\n",
    "\n",
    "        self.keep_last_n_turns = keep_last_n_turns\n",
    "        self.context_limit = context_limit\n",
    "        self.summarizer = summarizer\n",
    "        self.session_id = session_id or \"default\"\n",
    "\n",
    "        self._records: deque[Record] = deque()\n",
    "        self._lock = asyncio.Lock()\n",
    "\n",
    "    # --------- public API used by your runner ---------\n",
    "    async def get_items(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Return model-safe messages only (no metadata).\"\"\"\n",
    "        async with self._lock:\n",
    "            data = list(self._records)\n",
    "        msgs = [self._sanitize_for_model(rec[\"msg\"]) for rec in data]\n",
    "        return msgs[-limit:] if limit else msgs\n",
    "\n",
    "    async def add_items(self, items: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Append new items and, if needed, summarize older turns.\"\"\"\n",
    "        # 1) Ingest items\n",
    "        async with self._lock:\n",
    "            for it in items:\n",
    "                msg, meta = self._split_msg_and_meta(it)\n",
    "                self._records.append({\"msg\": msg, \"meta\": meta})\n",
    "\n",
    "            need_summary, boundary = self._summarize_decision_locked()\n",
    "\n",
    "        # 2) No summarization needed → just normalize flags and exit\n",
    "        if not need_summary:\n",
    "            async with self._lock:\n",
    "                self._normalize_synthetic_flags_locked()\n",
    "            return\n",
    "\n",
    "        # 3) Prepare summary prefix (model-safe copy) outside the lock\n",
    "        async with self._lock:\n",
    "            snapshot = list(self._records)\n",
    "            prefix_msgs = [r[\"msg\"] for r in snapshot[:boundary]]\n",
    "\n",
    "        user_shadow, assistant_summary = await self._summarize(prefix_msgs)\n",
    "\n",
    "        # 4) Re-check and apply summary atomically\n",
    "        async with self._lock:\n",
    "            still_need, new_boundary = self._summarize_decision_locked()\n",
    "            if not still_need:\n",
    "                self._normalize_synthetic_flags_locked()\n",
    "                return\n",
    "\n",
    "            snapshot = list(self._records)\n",
    "            suffix = snapshot[new_boundary:]  # keep-last-N turns live here\n",
    "\n",
    "            # Replace with: synthetic pair + suffix\n",
    "            self._records.clear()\n",
    "            self._records.extend([\n",
    "                {\n",
    "                    \"msg\": {\"role\": \"user\", \"content\": user_shadow},\n",
    "                    \"meta\": {\n",
    "                        \"synthetic\": True,\n",
    "                        \"kind\": \"history_summary_prompt\",\n",
    "                        \"summary_for_turns\": f\"< all before idx {new_boundary} >\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"msg\": {\"role\": \"assistant\", \"content\": assistant_summary},\n",
    "                    \"meta\": {\n",
    "                        \"synthetic\": True,\n",
    "                        \"kind\": \"history_summary\",\n",
    "                        \"summary_for_turns\": f\"< all before idx {new_boundary} >\",\n",
    "                    },\n",
    "                },\n",
    "            ])\n",
    "            self._records.extend(suffix)\n",
    "\n",
    "            # Ensure all real user/assistant messages explicitly have synthetic=False\n",
    "            self._normalize_synthetic_flags_locked()\n",
    "\n",
    "    async def pop_item(self) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Pop the latest message (model-safe), if any.\"\"\"\n",
    "        async with self._lock:\n",
    "            if not self._records:\n",
    "                return None\n",
    "            rec = self._records.pop()\n",
    "            return dict(rec[\"msg\"])\n",
    "\n",
    "    async def clear_session(self) -> None:\n",
    "        \"\"\"Remove all records.\"\"\"\n",
    "        async with self._lock:\n",
    "            self._records.clear()\n",
    "\n",
    "    def set_max_turns(self, n: int) -> None:\n",
    "        \"\"\"\n",
    "        Back-compat shim for old callers: update `context_limit`\n",
    "        and clamp `keep_last_n_turns` if needed.\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.context_limit = n\n",
    "        if self.keep_last_n_turns > self.context_limit:\n",
    "            self.keep_last_n_turns = self.context_limit\n",
    "\n",
    "    # Full history (debugging/analytics/observability)\n",
    "\n",
    "    async def get_full_history(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Return combined history entries in the shape:\n",
    "          {\"message\": {role, content[, name]}, \"metadata\": {...}}\n",
    "        This is NOT sent to the model; for logs/UI/debugging only.\n",
    "        \"\"\"\n",
    "        async with self._lock:\n",
    "            data = list(self._records)\n",
    "        out = [{\"message\": dict(rec[\"msg\"]), \"metadata\": dict(rec[\"meta\"])} for rec in data]\n",
    "        return out[-limit:] if limit else out\n",
    "\n",
    "    # Back-compat alias\n",
    "    async def get_items_with_metadata(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:\n",
    "        return await self.get_full_history(limit)\n",
    "\n",
    "    # Internals\n",
    "\n",
    "    def _split_msg_and_meta(self, it: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Split input into (msg, meta):\n",
    "          - msg keeps only _ALLOWED_MSG_KEYS; if role/content missing, default them.\n",
    "          - everything else goes under meta (including nested \"metadata\" if provided).\n",
    "          - default synthetic=False for real user/assistant unless explicitly set.\n",
    "        \"\"\"\n",
    "        msg = {k: v for k, v in it.items() if k in self._ALLOWED_MSG_KEYS}\n",
    "        extra = {k: v for k, v in it.items() if k not in self._ALLOWED_MSG_KEYS}\n",
    "        meta = dict(extra.pop(\"metadata\", {}))\n",
    "        meta.update(extra)\n",
    "\n",
    "        msg.setdefault(\"role\", \"user\")\n",
    "        msg.setdefault(\"content\", str(it))\n",
    "\n",
    "        role = msg.get(\"role\")\n",
    "        if role in (\"user\", \"assistant\") and \"synthetic\" not in meta:\n",
    "            meta[\"synthetic\"] = False\n",
    "        return msg, meta\n",
    "\n",
    "    @staticmethod\n",
    "    def _sanitize_for_model(msg: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Drop anything not allowed in model calls.\"\"\"\n",
    "        return {k: v for k, v in msg.items() if k in SummarizingSession._ALLOWED_MSG_KEYS}\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_real_user_turn_start(rec: Record) -> bool:\n",
    "        \"\"\"True if record starts a *real* user turn (role=='user' and not synthetic).\"\"\"\n",
    "        return (\n",
    "            rec[\"msg\"].get(\"role\") == \"user\"\n",
    "            and not rec[\"meta\"].get(\"synthetic\", False)\n",
    "        )\n",
    "\n",
    "    def _summarize_decision_locked(self) -> Tuple[bool, int]:\n",
    "        \"\"\"\n",
    "        Decide whether to summarize and compute the boundary index.\n",
    "\n",
    "        Returns:\n",
    "            (need_summary, boundary_idx)\n",
    "\n",
    "        If need_summary:\n",
    "          • boundary_idx is the earliest index among the last `keep_last_n_turns`\n",
    "            *real* user-turn starts.\n",
    "          • Everything before boundary_idx becomes the summary prefix.\n",
    "        \"\"\"\n",
    "        user_starts: List[int] = [\n",
    "            i for i, rec in enumerate(self._records) if self._is_real_user_turn_start(rec)\n",
    "        ]\n",
    "        real_turns = len(user_starts)\n",
    "\n",
    "        # Not over the limit → nothing to do\n",
    "        if real_turns <= self.context_limit:\n",
    "            return False, -1\n",
    "\n",
    "        # Keep zero turns verbatim → summarize everything\n",
    "        if self.keep_last_n_turns == 0:\n",
    "            return True, len(self._records)\n",
    "\n",
    "        # Otherwise, keep the last N turns; summarize everything before the earliest of those\n",
    "        if len(user_starts) < self.keep_last_n_turns:\n",
    "            return False, -1  # defensive (shouldn't happen given the earlier check)\n",
    "\n",
    "        boundary = user_starts[-self.keep_last_n_turns]\n",
    "\n",
    "        # If there is nothing before boundary, there is nothing to summarize\n",
    "        if boundary <= 0:\n",
    "            return False, -1\n",
    "\n",
    "        return True, boundary\n",
    "\n",
    "    def _normalize_synthetic_flags_locked(self) -> None:\n",
    "        \"\"\"Ensure all real user/assistant records explicitly carry synthetic=False.\"\"\"\n",
    "        for rec in self._records:\n",
    "            role = rec[\"msg\"].get(\"role\")\n",
    "            if role in (\"user\", \"assistant\") and \"synthetic\" not in rec[\"meta\"]:\n",
    "                rec[\"meta\"][\"synthetic\"] = False\n",
    "\n",
    "    async def _summarize(self, prefix_msgs: List[Dict[str, Any]]) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Ask the configured summarizer to compress the given prefix.\n",
    "        Uses model-safe messages only. If no summarizer is configured,\n",
    "        returns a graceful fallback.\n",
    "        \"\"\"\n",
    "        if not self.summarizer:\n",
    "            return (\"Summarize the conversation we had so far.\", \"Summary unavailable.\")\n",
    "        clean_prefix = [self._sanitize_for_model(m) for m in prefix_msgs]\n",
    "        return await self.summarizer.summarize(clean_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214228c8",
   "metadata": {},
   "source": [
    "![セッション内のコンテキストトリミング](../../images/summarizingSession.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b12761",
   "metadata": {},
   "source": [
    "**高レベルのアイデア**\n",
    "\n",
    "* **1ターン** = 1つの**実際のユーザー**メッセージ**とそれに続くすべて**（アシスタントの返答、ツール呼び出し/結果など）**次の実際のユーザーメッセージまで**。\n",
    "* 2つのパラメータを設定します：\n",
    "\n",
    "  * **`context_limit`**: 要約を行う前に生履歴で許可される**実際のユーザーターン**の最大数。\n",
    "  * **`keep_last_n_turns`**: 要約を行う際に、最新の**ターン**のうち何個をそのまま保持するか。\n",
    "\n",
    "    * 不変条件: `keep_last_n_turns <= context_limit`。\n",
    "* **実際の**ユーザーターン数が`context_limit`を超えると、セッションは：\n",
    "\n",
    "  1. 最後の`keep_last_n_turns`ターンの最も早いターンが開始される**前**のすべてを**要約**し、\n",
    "  2. 保持される領域の先頭に**合成されたユーザー→アシスタントのペア**を挿入します：\n",
    "\n",
    "     * `user`: `\"Summarize the conversation we had so far.\"`（シャドウプロンプト）\n",
    "     * `assistant`: `{生成された要約}`\n",
    "  3. 最後の`keep_last_n_turns`ターンを**そのまま****保持**します。\n",
    "\n",
    "これにより、最後の`keep_last_n_turns`ターンが発生した通りに正確に保持されることが保証され、それより前のすべてのコンテンツは2つの合成メッセージに圧縮されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "6d867c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SummarizingSession(\n",
    "    keep_last_n_turns=2,\n",
    "    context_limit=4,\n",
    "    summarizer=LLMSummarizer(client)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a8d22531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example flow\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Hi, my router won't connect. by the way, I am using Windows 10. I tried troubleshooting via your FAQs but I didn't get anywhere. This is my third tiem calling you. I am based in the US and one of Premium customers.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Let's check your firmware version.\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Firmware v1.0.3; still failing.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Try a factory reset.\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"Reset done; error 42 now.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Try to install a new firmware.\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"I tried but I got another error now.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Can you please provide me with the error code?\"}])\n",
    "await session.add_items([{\"role\": \"user\", \"content\": \"It says 404 not found when I try to access the page.\"}])\n",
    "await session.add_items([{\"role\": \"assistant\", \"content\": \"Are you connected to the internet?\"}])\n",
    "# At this point, with context_limit=4, everything *before* the earliest of the last 4 turns\n",
    "# is summarized into a synthetic pair, and the last 2 turns remain verbatim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e2e1b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = await session.get_items()\n",
    "# Pass `history` into your agent runner / responses call as the conversation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9f229de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Summarize the conversation we had so far.'},\n",
       " {'role': 'assistant',\n",
       "  'content': '• Product & Environment:\\n  - Router with Firmware v1.0.3, Windows 10, based in the US.\\n\\n• Reported Issue:\\n  - Router fails to connect.\\n\\n• Steps Tried & Results:\\n  - Checked FAQs: No resolution.\\n  - Checked firmware version: v1.0.3, problem persists.\\n  - Factory reset: Resulted in error 42.\\n\\n• Identifiers:\\n  - Premium customer (no specific identifier provided).\\n\\n• Timeline Milestones:\\n  - Initial troubleshooting via FAQs.\\n  - Firmware check (before factory reset).\\n  - Factory reset → Error 42.\\n\\n• Tool Performance Insights:\\n  - Firmware version check successful.\\n  - Factory reset resulted in new error (42).\\n\\n• Current Status & Blockers:\\n  - Connection issue unresolved; error 42 is the immediate blocker.\\n\\n• Next Recommended Step:\\n  - Install a new firmware update.'},\n",
       " {'role': 'user', 'content': 'I tried but I got another error now.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Can you please provide me with the error code?'},\n",
       " {'role': 'user',\n",
       "  'content': 'It says 404 not found when I try to access the page.'},\n",
       " {'role': 'assistant', 'content': 'Are you connected to the internet?'}]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7bb3457c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Product & Environment:\n",
      "  - Router with Firmware v1.0.3, Windows 10, based in the US.\n",
      "\n",
      "• Reported Issue:\n",
      "  - Router fails to connect.\n",
      "\n",
      "• Steps Tried & Results:\n",
      "  - Checked FAQs: No resolution.\n",
      "  - Checked firmware version: v1.0.3, problem persists.\n",
      "  - Factory reset: Resulted in error 42.\n",
      "\n",
      "• Identifiers:\n",
      "  - Premium customer (no specific identifier provided).\n",
      "\n",
      "• Timeline Milestones:\n",
      "  - Initial troubleshooting via FAQs.\n",
      "  - Firmware check (before factory reset).\n",
      "  - Factory reset → Error 42.\n",
      "\n",
      "• Tool Performance Insights:\n",
      "  - Firmware version check successful.\n",
      "  - Factory reset resulted in new error (42).\n",
      "\n",
      "• Current Status & Blockers:\n",
      "  - Connection issue unresolved; error 42 is the immediate blocker.\n",
      "\n",
      "• Next Recommended Step:\n",
      "  - Install a new firmware update.\n"
     ]
    }
   ],
   "source": [
    "print(history[1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6004db",
   "metadata": {},
   "source": [
    "`get_items_with_metadata`メソッドを使用して、デバッグや分析目的でメタデータを含むセッションの完全な履歴を取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5448ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_history = await session.get_items_with_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ddec0fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'message': {'role': 'user',\n",
       "   'content': 'Summarize the conversation we had so far.'},\n",
       "  'metadata': {'synthetic': True,\n",
       "   'kind': 'history_summary_prompt',\n",
       "   'summary_for_turns': '< all before idx 6 >'}},\n",
       " {'message': {'role': 'assistant',\n",
       "   'content': '**Product & Environment:**\\n- Device: Router\\n- OS: Windows 10\\n- Firmware: v1.0.3\\n\\n**Reported Issue:**\\n- Router fails to connect to the internet, now showing error 42.\\n\\n**Steps Tried & Results:**\\n- Checked FAQs: No resolution.\\n- Firmware version checked: v1.0.3.\\n- Factory reset performed: Resulted in error 42.\\n\\n**Identifiers:**\\n- UNVERIFIED\\n\\n**Timeline Milestones:**\\n- User attempted FAQ troubleshooting.\\n- Firmware checked after initial advice.\\n- Factory reset led to error 42.\\n\\n**Tool Performance Insights:**\\n- FAQs and basic reset process did not resolve the issue.\\n\\n**Current Status & Blockers:**\\n- Error 42 unresolved; firmware update needed.\\n\\n**Next Recommended Step:**\\n- Install the latest firmware update and check for resolution.'},\n",
       "  'metadata': {'synthetic': True,\n",
       "   'kind': 'history_summary',\n",
       "   'summary_for_turns': '< all before idx 6 >'}},\n",
       " {'message': {'role': 'user',\n",
       "   'content': 'I tried but I got another error now.'},\n",
       "  'metadata': {'synthetic': False}},\n",
       " {'message': {'content': 'I still have a problem with my router.',\n",
       "   'role': 'user'},\n",
       "  'metadata': {'synthetic': False}},\n",
       " {'message': {'content': [], 'role': 'user'},\n",
       "  'metadata': {'id': 'rs_68ba192de700819dbed28ad768a9c48205277fe33200f1e3',\n",
       "   'summary': [],\n",
       "   'type': 'reasoning',\n",
       "   'synthetic': False}},\n",
       " {'message': {'content': [{'annotations': [],\n",
       "     'text': 'Sorry you’re still stuck. What is the exact error code/message you see now during the firmware update, and does it appear in the router’s web UI or elsewhere?\\n\\nWhile you check that, try these quick, safe steps:\\n1) Verify the firmware file exactly matches your router’s model and hardware revision (check the label on the router) and region.\\n2) Re‑download the firmware from the vendor site and verify its checksum (MD5/SHA256) if provided.\\n3) Use a wired Ethernet connection to a LAN port, disable Wi‑Fi on the PC, and try a different browser with extensions disabled.\\n4) Ensure you’re uploading the correct file type (e.g., .bin/.img), not a ZIP; don’t rename the file.\\n5) Reboot the router and your PC, then retry the upload; after starting the update, wait at least 10 minutes and don’t power off.\\n\\nNote: “Error 42” meanings vary by brand; once you share the exact current error text and where it appears, I’ll give brand‑specific steps (including recovery options if needed).',\n",
       "     'type': 'output_text',\n",
       "     'logprobs': []}],\n",
       "   'role': 'assistant'},\n",
       "  'metadata': {'id': 'msg_68ba19400060819db38bcb891e9aec7605277fe33200f1e3',\n",
       "   'status': 'completed',\n",
       "   'type': 'message',\n",
       "   'synthetic': False}}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "64d555ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product & Environment:**\n",
      "- Device: Router\n",
      "- OS: Windows 10\n",
      "- Firmware: v1.0.3\n",
      "\n",
      "**Reported Issue:**\n",
      "- Router fails to connect to the internet, now showing error 42.\n",
      "\n",
      "**Steps Tried & Results:**\n",
      "- Checked FAQs: No resolution.\n",
      "- Firmware version checked: v1.0.3.\n",
      "- Factory reset performed: Resulted in error 42.\n",
      "\n",
      "**Identifiers:**\n",
      "- UNVERIFIED\n",
      "\n",
      "**Timeline Milestones:**\n",
      "- User attempted FAQ troubleshooting.\n",
      "- Firmware checked after initial advice.\n",
      "- Factory reset led to error 42.\n",
      "\n",
      "**Tool Performance Insights:**\n",
      "- FAQs and basic reset process did not resolve the issue.\n",
      "\n",
      "**Current Status & Blockers:**\n",
      "- Error 42 unresolved; firmware update needed.\n",
      "\n",
      "**Next Recommended Step:**\n",
      "- Install the latest firmware update and check for resolution.\n"
     ]
    }
   ],
   "source": [
    "print(history[1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744c6d8",
   "metadata": {},
   "source": [
    "### 注意事項と設計上の選択\n",
    "\n",
    "* **「新しい」側でターン境界を保持**: **`keep_last_n_turns`のユーザーターン**はそのまま保持され、それより古いものは圧縮されます。\n",
    "* **2メッセージの要約ブロック**: 下流のツールが検出や表示を行いやすくなります（`metadata.synthetic == True`）。\n",
    "* **非同期 + ロック規律**: （潜在的に遅い）要約処理の実行中は**ロックを解放**し、要約を適用する前に条件を再チェックして競合状態でのマージを回避します。\n",
    "* **冪等な動作**: 要約処理中により多くのメッセージが到着した場合、await後の再チェックにより古い書き換えを防ぎます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730afac9",
   "metadata": {},
   "source": [
    "## Evals\n",
    "\n",
    "最終的に、コンテキストエンジニアリングにおいても**evalsがすべて**です。重要な問いは次のとおりです：*モデルが「コンテキストを失っている」または「コンテキストを混同している」ことをどのように知ることができるでしょうか？*\n",
    "\n",
    "メモリに関する完全なクックブックは将来的に独立したものになる可能性がありますが、まずは以下のような軽量な評価ハーネスのアイデアから始めることができます：\n",
    "\n",
    "* **ベースライン & デルタ：** コアとなるevalセットを継続的に実行し、実験の前後を比較してメモリの改善を測定します。\n",
    "* **LLM-as-Judge：** 慎重に設計された採点プロンプトを持つモデルを使用して、要約の品質を評価します。正しい形式で最も重要な詳細を捉えているかどうかに焦点を当てます。\n",
    "* **トランスクリプト再生：** 長い会話を再実行し、コンテキストトリミングありとなしで次のターンの精度を測定します。メトリクスには、エンティティ/IDの完全一致や推論品質のルーブリックベースのスコアリングが含まれます。\n",
    "* **エラー回帰追跡：** 一般的な失敗モード（未回答の質問、制約の脱落、不要/重複したツール呼び出し）を監視します。\n",
    "* **トークン圧迫チェック：** トークン制限により保護されたコンテキストの削除が強制される場合にフラグを立てます。重要な詳細が削除されているタイミングを検出するために、前後のトークン数をログに記録します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2843701",
   "metadata": {},
   "source": [
    "申し訳ございませんが、翻訳すべきテキストが提供されていないようです。「---」の後に翻訳したい英語のテキストを貼り付けていただけますでしょうか？\n",
    "\n",
    "技術文書の翻訳を行う準備はできておりますので、翻訳したい内容をお送りください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
