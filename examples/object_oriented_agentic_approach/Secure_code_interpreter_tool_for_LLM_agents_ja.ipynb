{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fde7616369c1e1e",
   "metadata": {},
   "source": [
    "## 独自のコードインタープリターを構築する - o3-miniによる動的ツール生成と実行\n",
    "\n",
    "LLMエージェントが外部世界や他のエージェントと相互作用する機能の中核となるのは「ツール（または関数）呼び出し」です。これは、LLMが引数を持つ関数（コードブロック）を呼び出すことができる機能です。通常、これらの関数は開発者によって事前に定義され、期待される入力と出力も決められています。しかし、このクックブックでは、より柔軟なパラダイムを探求します。LLMモデル（この場合は**o3-mini**）を使用して**動的にツールを生成**し、コードインタープリターを使ってそのツールを実行する能力について説明します。\n",
    "\n",
    "### コードインタープリターによる動的生成ツール呼び出し\n",
    "動的生成ツールとは、ユーザーのプロンプトに基づいてLLM自体が実行時に作成する関数またはコードブロックです。これは、コードベースで考えられるすべてのシナリオを事前に定義する必要がないことを意味し、はるかにオープンエンドで創造的、かつ適応的な問題解決を可能にします。\n",
    "\n",
    "動的生成ツール呼び出しは、LLMにツールを生成し、コードブロックをその場で実行する能力を与えることで、さらに一歩進んだアプローチです。この動的アプローチは、以下のようなタスクに特に有用です：\n",
    "\n",
    "- データ分析と可視化\n",
    "- データ操作と変換\n",
    "- 機械学習ワークフローの生成と実行\n",
    "- プロセス自動化とスクリプト作成\n",
    "- その他、実験を通じて新たな可能性が生まれる多くの分野\n",
    "\n",
    "### 動的ツール生成におけるo3-miniの使用\n",
    "\n",
    "2025年1月31日にリリースされたo3-miniモデルは、科学、数学、コーディングに特に優れた例外的なSTEM能力を持ちながら、小型モデルの低コストと短いレイテンシを維持しています。このクックブックでは、データを解釈し洞察を導き出すPythonコードを生成するo3-miniの能力を実証します。\n",
    "\n",
    "推論モデルは、明示的な思考の連鎖プロンプトを必要とせず、自分自身で推論できるため、データを分析する動的ツールの生成に特に優れています。実際、明示的な思考の連鎖指示を提供すると、モデルの内部推論に干渉し、最適でない結果につながる可能性があります。o3-miniについて詳しくは[こちら](https://openai.com/index/openai-o3-mini/)をご覧ください。\n",
    "\n",
    "### 独自のコードインタープリターを構築する理由\n",
    "\n",
    "OpenAIのAssistants APIなど、多くのAPIプロバイダーは組み込みのコードインタープリター機能を提供しています。これらの組み込みコードインタープリターは非常に強力ですが、開発者が独自のカスタムコードインタープリターを作成する必要がある状況があります。例えば：\n",
    "\n",
    "1. **言語やライブラリのサポート**: 組み込みインタープリターが、タスクに必要な特定のプログラミング言語（C++、Javaなど）やライブラリをサポートしていない場合。\n",
    "2. **タスクの互換性**: ユースケースがプロバイダーの組み込みソリューションと互換性がない場合。\n",
    "3. **モデルの制約**: プロバイダーのインタープリターでサポートされていない言語モデルが必要な場合。\n",
    "4. **コストの考慮**: コード実行やモデル使用のコスト構造が予算や制約に合わない場合。\n",
    "5. **ファイルサイズ**: 入力データのファイルサイズが大きすぎる、またはプロバイダーのインタープリターでサポートされていない場合。\n",
    "6. **内部システムとの統合**: プロバイダーのインタープリターが内部システムと統合できない場合。\n",
    "\n",
    "### 学習内容\n",
    "このクックブックに従うことで、以下のことを学習できます：\n",
    "\n",
    "- Dockerを使用した分離されたPythonコード実行環境のセットアップ\n",
    "- LLMエージェント用の独自コードインタープリターツールの設定\n",
    "- セキュリティと安全性のための「エージェント的」関心事の明確な分離の確立\n",
    "- データ分析用のコードを動的に生成するための**o3-mini**モデルの使用\n",
    "- 与えられたタスクを効率的に達成するためのエージェントのオーケストレーション\n",
    "- コードを動的に生成・実行できるエージェントアプリケーションの設計\n",
    "\n",
    "ゼロからカスタムコードインタープリターツールを構築し、LLMの力を活用して洗練されたコードを生成し、そのコードを分離された環境で安全に実行する方法を学びます。これらすべては、AI駆動アプリケーションをより柔軟で強力、かつコスト効率的にすることを目的としています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd93887",
   "metadata": {},
   "source": [
    "### サンプルシナリオ\n",
    "\n",
    "[Key Factors Traffic Accidents](https://www.kaggle.com/datasets/willianoliveiragibin/key-factors-traffic-accidents)で提供されているサンプルデータを使用して、一連の質問に答えます。これらの質問は事前に定義する必要はなく、LLMにそのような質問に答えるためのコードを生成する能力を与えます。\n",
    "\n",
    "サンプル質問は以下のようなものです：\n",
    "- 事故頻度に最も寄与する要因は何か？（特徴量重要度分析）\n",
    "- 事故のリスクが最も高い地域はどこか？（分類/クラスタリング）\n",
    "- 交通違反金額は事故件数にどのような影響を与えるか？（回帰/因果推論）\n",
    "- 事故率を減らすための最適な罰金額を決定できるか？（最適化モデル）\n",
    "- より高い罰金は平均速度の低下や事故の減少と相関があるか？（相関/回帰）\n",
    "- その他...\n",
    "\n",
    "従来の**事前定義ツール呼び出し**アプローチを使用する場合、開発者はこれらの質問それぞれに対して関数を事前に定義する必要があります。これにより、事前定義された関数セットで定義されていない他の質問に答えるLLMの能力が制限されます。私たちは、LLMがコードを生成し、Code Interpretterツールを使用してコードを実行する**動的ツール呼び出し**アプローチを使用することで、この制限を克服します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301abe8",
   "metadata": {},
   "source": [
    "## 概要\n",
    "動的に生成されるツール呼び出し機能を持つエージェントアプリケーションを構築する手順について詳しく見ていきましょう。このアプリケーションには3つのコンポーネントがあります："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2269f",
   "metadata": {},
   "source": [
    "#### ステップ1: 分離されたコード実行コンテナ環境のセットアップ\n",
    "\n",
    "LLMが生成した関数呼び出しを実行できる安全な環境が必要です。LLMが生成したコードをホストマシン上で直接実行することを避けたいので、リソースアクセスが制限された（例：ネットワークアクセスなし）Dockerコンテナ環境を作成します。デフォルトでは、Dockerコンテナはホストマシンのファイルシステムにアクセスできないため、LLMが生成したコードが確実に隔離された状態を保つことができます。\n",
    "\n",
    "##### ⚠️ 注意事項: LLMが生成するコードに対する強力なガードレールの実装\n",
    "LLMは意図しない結果を招く有害なコードを生成する可能性があります。ベストプラクティスとして、タスクに必要なリソースへのアクセスのみを許可し、コード実行環境を分離してください。LLMが生成したコードをホストマシンやラップトップ上で実行することは避けてください。\n",
    "\n",
    "#### ステップ2: エージェントの定義とテスト\n",
    "\n",
    "「**エージェントとは何か？**」このCookbookの文脈において、エージェントとは以下のものです：\n",
    "1. LLMが従うべき指示のセット、つまり開発者プロンプト\n",
    "2. LLMモデル、およびAPI経由でモデルを呼び出す機能\n",
    "3. 関数へのツール呼び出しアクセス、および関数を実行する機能\n",
    "\n",
    "2つのエージェントを定義します：\n",
    "1. FileAccessAgent: このエージェントはファイルを読み取り、PythonCodeExecAgentにコンテキストを提供します。\n",
    "2. PythonCodeExecAgent: このエージェントはユーザーの質問に答えるPythonコードを生成し、Dockerコンテナ内でコードを実行します。\n",
    "\n",
    "#### ステップ3: アプリケーションを実行するためのエージェント オーケストレーションのセットアップ\n",
    "アプリケーションの要件に基づいて、エージェントをオーケストレーションする様々な方法があります。この例では、ユーザーがタスクを提供し、エージェントが順次呼び出されてタスクを達成するシンプルなオーケストレーションを使用します。\n",
    "\n",
    "全体的なオーケストレーションを以下に示します：\n",
    "\n",
    "![](../../images/oo_aa_image_1_code_interpreter_agents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a651f8d",
   "metadata": {},
   "source": [
    "## 始めましょう\n",
    "\n",
    "\n",
    "### 前提条件\n",
    "開始する前に、ホストマシンに以下がインストールされ、設定されていることを確認してください：\n",
    "\n",
    "1. Docker: ローカルマシンにインストールされ、実行されていること。Dockerについて詳しく学び、[こちらからインストール](https://www.docker.com/)できます。\n",
    "2. Python: ローカルマシンにインストールされていること。Pythonについて詳しく学び、[こちらからインストール](https://www.python.org/downloads/)できます。\n",
    "3. OpenAI API key: ローカルマシンで環境変数として、またはルートディレクトリの.envファイルに設定されていること。OpenAI API keyについて詳しく学び、[こちらから設定](https://platform.openai.com/docs/api-reference/introduction)できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea3005fbd91c61",
   "metadata": {},
   "source": [
    "### ステップ1: 分離されたコード実行環境のセットアップ\n",
    "\n",
    "コードを実行するために使用するDockerizedコンテナ環境を定義しましょう。`resources/docker`ディレクトリの下に**[dockerfile](https://github.com/openai/openai-cookbook/blob/main/examples/object_oriented_agentic_approach/resources/docker/dockerfile)**を定義しており、以下の仕様でコンテナ環境を作成するために使用されます：\n",
    "- ベースとしてPython 3.10を使用\n",
    "- 非rootユーザー\n",
    "- requirements.txtのパッケージを事前インストール\n",
    "\n",
    "dockerイメージ作成プロセスに含まれるrequirements.txtには、LLMが生成するコードがタスクを実行するために必要となる可能性のあるすべてのパッケージが含まれています。コンテナからのネットワークアクセスを制限するため、タスクに必要なパッケージを事前にインストールする必要があります。セキュリティ上の理由から、LLMは追加のパッケージをインストールすることは許可されません。\n",
    "\n",
    "言語要件（Python 3.10など）を満たし、タスクに必要なパッケージを事前インストールした独自のdockerイメージを作成することも、特定の言語（Java、C++など）とタスクに必要なパッケージを含むカスタムdockerイメージを作成することも可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2af004",
   "metadata": {},
   "source": [
    "以下のコマンドでDockerイメージをビルドしましょう。簡潔にするため、出力を成功メッセージをgrepするようにリダイレクトし、ビルドが失敗した場合にメッセージを出力するようにしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe136739b0bd164a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T00:13:35.949224Z",
     "start_time": "2025-01-27T00:13:33.524485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/kl8fo02q7rgbindi9b42pn1zr\r\n"
     ]
    }
   ],
   "source": [
    "!docker build -t python_sandbox:latest ./resources/docker 2>&1 | grep -E \"View build details|ERROR\" || echo \"Build failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0e9024894d45d",
   "metadata": {},
   "source": [
    "制限モードでコンテナを実行してみましょう。コンテナはバックグラウンドで実行されます。これは、コンテナのセキュリティポリシーを定義する機会です。タスクに必要な最小限の機能のみをコンテナに許可することが良い慣行です。デフォルトでは、コンテナはコンテナ内からホストファイルシステムにアクセスできません。また、インターネットやその他のネットワークリソースにアクセスできないように、ネットワークへのアクセスも制限しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfaa0418f90fde09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T00:13:43.561453Z",
     "start_time": "2025-01-27T00:13:43.213479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8446d1e9a7972f2e00a5d1799451c1979d34a2962aa6b4c35a9868af8d321b0e\r\n"
     ]
    }
   ],
   "source": [
    "# Run the container in restricted mode. The container will run in the background.\n",
    "!docker run -d --name sandbox --network none --cap-drop all --pids-limit 64 --tmpfs /tmp:rw,size=64M   python_sandbox:latest sleep infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21cafbcfdc09e2c",
   "metadata": {},
   "source": [
    "`docker ps`を使用してコンテナが実行されていることを確認しましょう。これにより、私たちのコンテナが一覧表示されるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4df845011b77a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T00:13:45.473413Z",
     "start_time": "2025-01-27T00:13:45.316092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                   COMMAND            CREATED         STATUS         PORTS     NAMES\r\n",
      "8446d1e9a797   python_sandbox:latest   \"sleep infinity\"   2 seconds ago   Up 2 seconds             sandbox\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a2c8f40710c2",
   "metadata": {},
   "source": [
    "### ステップ2: エージェントの定義とテスト\n",
    "\n",
    "我々の目的のために、2つのエージェントを定義します。\n",
    "\n",
    "1.\t**エージェント1: ファイルアクセスエージェント（事前定義されたツール呼び出し）**\n",
    "- エージェント2にコンテキストとして提供するファイルの内容を理解する指示。\n",
    "- ホストマシンのファイルシステムにアクセス可能。\n",
    "- ホストからファイルを読み取り、Dockerコンテナにコピー可能。\n",
    "- コードインタープリターツールにはアクセス不可。\n",
    "- gpt-4oモデルを使用。\n",
    "\n",
    "2.\t**エージェント2: Pythonコード生成・実行エージェント（動的に生成されたツール呼び出しとコード実行）**\n",
    "- エージェント1からファイルコンテンツのコンテキストを受信。\n",
    "- ユーザーの質問に答えるPythonスクリプトを生成する指示。\n",
    "- Dockerコンテナ内のコードインタープリターにアクセス可能で、Pythonコードの実行に使用。\n",
    "- Dockerコンテナ内のファイルシステムのみにアクセス可能（ホストではない）。\n",
    "- ホストマシンのファイルシステムやネットワークにはアクセス不可。\n",
    "- コード生成に優れた最新の**o3-mini**モデルを使用。\n",
    "\n",
    "ファイルアクセス（エージェント1）とコード生成・実行（エージェント2）の関心事の分離は、LLMがホストマシンに直接アクセスしたり変更したりすることを防ぐために重要です。\n",
    "\n",
    "**エージェント1はホストファイルシステムにアクセスできるため、静的ツール呼び出しに制限します。**\n",
    "\n",
    "| エージェント | ツール呼び出しの種類 | ホストファイルシステムへのアクセス | Dockerコンテナファイルシステムへのアクセス | コードインタープリターへのアクセス |\n",
    "|-------|-------------------|----------------------------|----------------------------------------|----------------------------|\n",
    "| エージェント1: ファイルアクセス | 事前定義されたツール | あり | あり | なし |\n",
    "| エージェント2: Pythonコード生成・実行 | 動的に生成されたツール | なし | あり | あり |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d4d2ba5d47226",
   "metadata": {},
   "source": [
    "エージェントとツールを整理するために、オブジェクト指向プログラミングの原則を使用して一貫性を保ちながら2つのエージェントを作成するための**コアクラス**のセットを定義しました。\n",
    "\n",
    "- **BaseAgent**: `task()`などの共通メソッドシグネチャを強制する抽象基底クラスから始めます。基底クラスはデバッグ用のロガー、言語モデルインターフェース、およびエージェントにコンテキストを追加する`add_context()`などの他の共通機能も提供します。\n",
    "- **ChatMessages**: ChatCompletions APIがステートレスであることを考慮して、会話履歴を保存するクラスです。\n",
    "- **ToolManager**: エージェントが呼び出すことができるツールを管理するクラスです。\n",
    "- **ToolInterface**: エージェントが呼び出すことができる任意の「ツール」のための抽象クラスで、ツールが一貫したインターフェースを持つようにします。\n",
    "\n",
    "これらのクラスは[object_oriented_agents/core_classes](./resources/object_oriented_agents/core_classes)ディレクトリに定義されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90cda38",
   "metadata": {},
   "source": [
    "#### コアクラスのUMLクラス図\n",
    "以下のクラス図は、コアクラス間の関係を示しています。このUML（統一モデリング言語）は[Mermaid](https://mermaid)を使用して生成されています。\n",
    "\n",
    "![](../../images/oo_aa_image_2_uml_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb923b",
   "metadata": {},
   "source": [
    "**エージェント1の定義：FileAccessToolを持つFileAccessAgent**\n",
    "\n",
    "まず、ToolInterfaceクラスを継承するFileAccessToolの定義から始めましょう。**FileAccessTool**ツールは、`resources/registry/tools`ディレクトリの[file_access_tool.py](https://github.com/openai/openai-cookbook/blob/main/examples/object_oriented_agentic_approach/resources/registry/tools/file_access_tool.py)ファイルで定義されています。\n",
    "\n",
    "- FileAccessToolはToolInterfaceクラスを実装しており、これによりツールが一貫したインターフェースを持つことが保証されます。\n",
    "- `get_definition`メソッドでOpenAI Function Calling APIのツール定義をバインドし、ツールの`run`メソッドと組み合わせることで、保守性、拡張性、再利用性が確保されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f349e",
   "metadata": {},
   "source": [
    "それでは、BaseAgentクラスを継承し、**FileAccessTool**をエージェントにバインドする**FileAccessAgent**を定義しましょう。FileAccessAgentは、`resources/registry/agents`ディレクトリの[file_acess_agent.py](https://github.com/openai/openai-cookbook/blob/main/examples/object_oriented_agentic_approach/resources/registry/agents/file_access_agent.py)ファイルで定義されています。FileAccessAgentは以下の特徴を持ちます：\n",
    "\n",
    "- BaseAgentクラスの具象実装です。\n",
    "- 開発者プロンプト、モデル名、ロガー、言語モデルインターフェースで初期化されます。これらの値は必要に応じて開発者がオーバーライドできます。\n",
    "- FileAccessToolをツールマネージャーに登録する`setup_tools`メソッドを持ちます。\n",
    "- ファイルを読み取り、PythonCodeExecAgentにコンテキストを提供するためにFileAccessToolを呼び出す`task`メソッドを持ちます。\n",
    "- タスクに十分な推論とツール呼び出し能力を提供する`model_name='gpt-4o'`を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cd2e5447b4ff9",
   "metadata": {},
   "source": [
    "**エージェント2の定義: PythonExecToolを使用したPythonExecAgent**\n",
    "\n",
    "同様に、PythonExecToolはToolInterfaceクラスを継承し、get_definitionメソッドとrunメソッドを実装しています。get_definitionメソッドは、OpenAI Function Calling APIが期待する形式でツール定義を返します。runメソッドは、DockerコンテナでPythonコードを実行し、出力を返します。このツールは、`resources/registry/tools`ディレクトリの[python_code_interpreter_tool.py](https://github.com/openai/openai-cookbook/blob/main/examples/object_oriented_agentic_approach/resources/registry/tools/python_code_interpreter_tool.py)ファイルで定義されています。\n",
    "\n",
    "同様に、PythonExecAgentはBaseAgentクラスの具体的な実装です。これは、`resources/registry/agents`ディレクトリの[python_code_exec_agent.py](https://github.com/openai/openai-cookbook/blob/main/examples/object_oriented_agentic_approach/resources/registry/agents/python_code_exec_agent.py)ファイルで定義されています。PythonExecAgentは以下の特徴があります：\n",
    "\n",
    "- BaseAgentクラスの具体的な実装\n",
    "- 開発者プロンプト、モデル名、ロガー、言語モデルインターフェースで初期化される。これらの値は必要に応じて開発者が上書きできる\n",
    "- PythonExecToolをツールマネージャーに登録するsetup_toolsメソッドを持つ\n",
    "- ユーザーのタスクを実行するためにOpenAI APIを呼び出す`task`メソッドを持つ。この場合、ユーザーの質問に答えるPythonスクリプトを生成し、Code Interpreterツールで実行する\n",
    "- コード生成などのSTEMタスクに優れた`model_name='o3-mini'`\n",
    "- タスクの複雑さに応じてより完全な推論を可能にする`reasoning_effort='high'`。ただし、より多くのトークンが生成され、応答が遅くなるコストがある。デフォルト値はmediumで、速度と推論精度のバランスを取っている\n",
    "\n",
    "`reasoning_effort`パラメータについて詳しくは[こちら](https://platform.openai.com/docs/guides/reasoning)をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93488f",
   "metadata": {},
   "source": [
    "### ステップ3: アプリケーションを実行するためのエージェント・オーケストレーションを設定する\n",
    "\n",
    "エージェントが定義されたので、次にアプリケーションを実行するオーケストレーション・ループを定義できます。このループはユーザーに質問やタスクを入力するよう促し、その後FileAccessAgentを呼び出してファイルを読み取り、PythonExecAgentにコンテキストを提供します。PythonExecAgentはユーザーの質問に答えるためのPythonコードを生成し、Dockerコンテナ内でコードを実行します。コード実行の出力がユーザーに表示されます。\n",
    "\n",
    "ユーザーは'exit'と入力してアプリケーションを停止できます。私たちの質問は：**事故頻度に最も寄与する要因は何ですか？** この質問に答える関数を事前に定義していないことに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866b7eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T21:05:18.680311Z",
     "start_time": "2025-02-03T21:03:52.169439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup: \n",
      "Use the file traffic_accidents.csv for your analysis. The column names are:\n",
      "Variable\tDescription\n",
      "accidents\tNumber of recorded accidents, as a positive integer.\n",
      "traffic_fine_amount\tTraffic fine amount, expressed in thousands of USD.\n",
      "traffic_density\tTraffic density index, scale from 0 (low) to 10 (high).\n",
      "traffic_lights\tProportion of traffic lights in the area (0 to 1).\n",
      "pavement_quality\tPavement quality, scale from 0 (very poor) to 5 (excellent).\n",
      "urban_area\tUrban area (1) or rural area (0), as an integer.\n",
      "average_speed\tAverage speed of vehicles in km/h.\n",
      "rain_intensity\tRain intensity, scale from 0 (no rain) to 3 (heavy rain).\n",
      "vehicle_count\tEstimated number of vehicles, in thousands, as an integer.\n",
      "time_of_day\tTime of day in 24-hour format (0 to 24).\n",
      "accidents\ttraffic_fine_amount\n",
      "\n",
      "Setting up the agents... \n",
      "Understanding the contents of the file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 13:03:54,066 - MyApp - INFO - Handling tool call: safe_file_access\n",
      "2025-02-03 13:03:54,067 - MyApp - INFO - Tool arguments: {'filename': './resources/data/traffic_accidents.csv'}\n",
      "2025-02-03 13:03:54,562 - MyApp - INFO - Tool 'safe_file_access' response: Copied ./resources/data/traffic_accidents.csv into sandbox:/home/sandboxuser/.\n",
      "The file content for the first 15 rows is:\n",
      "    accidents  traffic_fine_amount  traffic_density  traffic_lights  pavement_quality  urban_area  average_speed  rain_intensity  vehicle_count  time_of_day\n",
      "0          20               4.3709           2.3049         753.000            0.7700           1        321.592          1.1944       290.8570     160.4320\n",
      "1          11               9.5564           3.2757           5.452            4.0540           1        478.623          6.2960       931.8120       8.9108\n",
      "2          19               7.5879           2.0989           6.697          345.0000           0        364.476          2.8584       830.0860       5.5727\n",
      "3          23               6.3879           4.9188           9.412            4.7290           0         20.920          2.1065       813.1590     131.4520\n",
      "4          23               2.4042           1.9610           7.393            1.7111           1         37.378          1.7028         1.4663       6.9610\n",
      "5          31               2.4040           6.7137           5.411            5.9050           1        404.621          1.8936       689.0410       8.1801\n",
      "6          29               1.5228           5.2316           9.326            2.3785           1         16.292          2.5213       237.9710      12.6622\n",
      "7          18               8.7956           8.9864           4.784            1.9984           0        352.566          1.9072       968.0670       8.0602\n",
      "8          15               6.4100           1.6439           5.612            3.6090           1        217.198          3.4380       535.4440       8.2904\n",
      "9          22               7.3727           8.0411           5.961            4.7650           1        409.261          2.0919       569.0560     203.5910\n",
      "10         28               1.1853           7.9196           0.410            3.7678           1        147.689          1.6946       362.9180     224.1580\n",
      "11         17               9.7292           1.2718           8.385            8.9720           0         46.888          2.8990       541.3630     198.5740\n",
      "12         14               8.4920           3.9856           1.852            4.6776           0        287.393          2.2012        75.2240       2.3728\n",
      "13         21               2.9111           1.7015           5.548            1.9607           1        176.652          1.0320       566.3010       6.9538\n",
      "14         22               2.6364           2.5472           7.222            2.3709           0        209.686          4.0620        64.4850     170.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your question related to the data in the file. Type 'exit' to exit.\n",
      "User question: What factors contribute the most to accident frequency?\n",
      "Generating dynamic tools and using code interpreter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 13:04:39,427 - MyApp - INFO - Handling tool call: execute_python_code\n",
      "2025-02-03 13:04:39,429 - MyApp - INFO - Tool arguments: {'python_code': \"import pandas as pd\\nimport numpy as np\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.preprocessing import StandardScaler\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Load the dataset\\nfile_path = '/home/sandboxuser/traffic_accidents.csv'\\ndf = pd.read_csv(file_path)\\n\\n# Show basic information\\nprint('Dataset shape:', df.shape)\\nprint('First few rows:')\\nprint(df.head(), '\\\\n')\\nprint('Columns:', df.columns.tolist(), '\\\\n')\\n\\n# Correlation matrix analysis\\ncorr_matrix = df.corr()\\nprint('Correlation matrix:')\\nprint(corr_matrix, '\\\\n')\\n\\n# Correlation of each feature with accidents\\nacc_corr = corr_matrix['accidents'].drop('accidents').sort_values(key=lambda x: abs(x), ascending=False)\\nprint('Correlation of other variables with accidents (sorted by absolute correlation):')\\nprint(acc_corr, '\\\\n')\\n\\n# Visualize the correlation matrix\\nplt.figure(figsize=(10, 8))\\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\\nplt.title('Correlation Matrix')\\nplt.tight_layout()\\nplt.savefig('correlation_matrix.png')\\nplt.close()\\n\\n# Prepare data for regression analysis\\n# Exclude target variable 'accidents'\\nfeatures = [col for col in df.columns if col != 'accidents']\\nX = df[features]\\ny = df['accidents']\\n\\n# Standardize the features to compare the regression coefficients on the same scale\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n# Fit a linear regression model\\nmodel = LinearRegression()\\nmodel.fit(X_scaled, y)\\n\\n# Gather coefficients along with feature names\\ncoef = model.coef_\\ncoef_df = pd.DataFrame({'Feature': features, 'Coefficient': coef})\\ncoef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\\ncoef_df = coef_df.sort_values(by='AbsCoefficient', ascending=False)\\nprint('Linear Regression Coefficients (using standardized features):')\\nprint(coef_df[['Feature', 'Coefficient']], '\\\\n')\\n\\n# Additionally, compute feature importances using a Random Forest regressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nrf = RandomForestRegressor(random_state=42)\\nrf.fit(X, y)\\nrf_importance = rf.feature_importances_\\nrf_df = pd.DataFrame({'Feature': features, 'Importance': rf_importance})\\nrf_df = rf_df.sort_values(by='Importance', ascending=False)\\nprint('Random Forest Feature Importances:')\\nprint(rf_df, '\\\\n')\\n\\n# The printed outputs will help in understanding which factors contribute most to accident frequency.\\n\\n# For clarity, save the coefficients and importances to CSV files (optional)\\ncoef_df.to_csv('linear_regression_coefficients.csv', index=False)\\nrf_df.to_csv('random_forest_importances.csv', index=False)\\n\\n# End of analysis\\n\"}\n",
      "2025-02-03 13:04:43,123 - MyApp - INFO - Tool 'execute_python_code' response: Dataset shape: (8756, 10)\n",
      "First few rows:\n",
      "   accidents  traffic_fine_amount  ...  vehicle_count  time_of_day\n",
      "0         20               4.3709  ...       290.8570     160.4320\n",
      "1         11               9.5564  ...       931.8120       8.9108\n",
      "2         19               7.5879  ...       830.0860       5.5727\n",
      "3         23               6.3879  ...       813.1590     131.4520\n",
      "4         23               2.4042  ...         1.4663       6.9610\n",
      "\n",
      "[5 rows x 10 columns] \n",
      "\n",
      "Columns: ['accidents', 'traffic_fine_amount', 'traffic_density', 'traffic_lights', 'pavement_quality', 'urban_area', 'average_speed', 'rain_intensity', 'vehicle_count', 'time_of_day'] \n",
      "\n",
      "Correlation matrix:\n",
      "                     accidents  traffic_fine_amount  ...  vehicle_count  time_of_day\n",
      "accidents             1.000000            -0.745161  ...       0.068399     0.101995\n",
      "traffic_fine_amount  -0.745161             1.000000  ...      -0.016610    -0.006236\n",
      "traffic_density      -0.059265            -0.004365  ...      -0.014244     0.002806\n",
      "traffic_lights       -0.026642             0.009056  ...       0.001373    -0.001971\n",
      "pavement_quality      0.064694            -0.021229  ...       0.007840     0.000055\n",
      "urban_area            0.145092            -0.005136  ...      -0.006053    -0.006320\n",
      "average_speed         0.093923             0.009151  ...       0.000777    -0.005338\n",
      "rain_intensity       -0.091673            -0.015302  ...      -0.025933    -0.013446\n",
      "vehicle_count         0.068399            -0.016610  ...       1.000000    -0.009303\n",
      "time_of_day           0.101995            -0.006236  ...      -0.009303     1.000000\n",
      "\n",
      "[10 rows x 10 columns] \n",
      "\n",
      "Correlation of other variables with accidents (sorted by absolute correlation):\n",
      "traffic_fine_amount   -0.745161\n",
      "urban_area             0.145092\n",
      "time_of_day            0.101995\n",
      "average_speed          0.093923\n",
      "rain_intensity        -0.091673\n",
      "vehicle_count          0.068399\n",
      "pavement_quality       0.064694\n",
      "traffic_density       -0.059265\n",
      "traffic_lights        -0.026642\n",
      "Name: accidents, dtype: float64 \n",
      "\n",
      "Linear Regression Coefficients (using standardized features):\n",
      "               Feature  Coefficient\n",
      "0  traffic_fine_amount    -3.891935\n",
      "4           urban_area     0.739618\n",
      "5        average_speed     0.533698\n",
      "6       rain_intensity    -0.532251\n",
      "8          time_of_day     0.512661\n",
      "1      traffic_density    -0.331997\n",
      "7        vehicle_count     0.281283\n",
      "3     pavement_quality     0.264987\n",
      "2       traffic_lights    -0.092800 \n",
      "\n",
      "Random Forest Feature Importances:\n",
      "               Feature  Importance\n",
      "0  traffic_fine_amount    0.580838\n",
      "1      traffic_density    0.165201\n",
      "6       rain_intensity    0.095124\n",
      "8          time_of_day    0.035814\n",
      "5        average_speed    0.035590\n",
      "3     pavement_quality    0.032177\n",
      "2       traffic_lights    0.022613\n",
      "7        vehicle_count    0.021006\n",
      "4           urban_area    0.011637 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output...\n",
      "The analysis shows that one variable stands out by far:\n",
      "\n",
      "• Both the simple correlation analysis and regression results indicate that traffic_fine_amount is the dominant factor—its correlation with accidents is strong (about –0.75), and in the standardized linear regression its coefficient is the largest in magnitude (around –3.89). The negative sign suggests that, in this data, higher fine amounts are associated with fewer accidents (which might reflect more stringent enforcement or deterrence).\n",
      "\n",
      "Other findings include:\n",
      "\n",
      "• The Random Forest model also ranks traffic_fine_amount as most important (importance ≈ 0.58), with the next most influential factor being traffic_density (importance ≈ 0.17). Although its simple correlation with accidents is lower, traffic_density may contribute non‐linearly.\n",
      "\n",
      "• Additional factors like urban_area, average_speed, rain_intensity, and time_of_day have moderate associations (with linear model coefficients ranging between about ±0.5 to +0.74). These suggest that accidents tend to be somewhat higher in urban areas and vary with time of day and weather conditions, but their overall impact is much less than that of traffic fine amounts.\n",
      "\n",
      "In summary, the data analysis indicates that traffic_fine_amount contributes the most to accident frequency—with higher fines linked to fewer recorded accidents—while factors such as traffic density, urban area status, vehicle speed, rain intensity, and time of day also play secondary roles.\n",
      "Type your question related to the data in the file. Type 'exit' to exit.\n",
      "Exiting the application.\n"
     ]
    }
   ],
   "source": [
    "# Import the agents from registry/agents\n",
    "\n",
    "from resources.registry.agents.file_access_agent import FileAccessAgent\n",
    "from resources.registry.agents.python_code_exec_agent import PythonExecAgent\n",
    "\n",
    "\n",
    "prompt = \"\"\"Use the file traffic_accidents.csv for your analysis. The column names are:\n",
    "Variable\tDescription\n",
    "accidents\tNumber of recorded accidents, as a positive integer.\n",
    "traffic_fine_amount\tTraffic fine amount, expressed in thousands of USD.\n",
    "traffic_density\tTraffic density index, scale from 0 (low) to 10 (high).\n",
    "traffic_lights\tProportion of traffic lights in the area (0 to 1).\n",
    "pavement_quality\tPavement quality, scale from 0 (very poor) to 5 (excellent).\n",
    "urban_area\tUrban area (1) or rural area (0), as an integer.\n",
    "average_speed\tAverage speed of vehicles in km/h.\n",
    "rain_intensity\tRain intensity, scale from 0 (no rain) to 3 (heavy rain).\n",
    "vehicle_count\tEstimated number of vehicles, in thousands, as an integer.\n",
    "time_of_day\tTime of day in 24-hour format (0 to 24).\n",
    "accidents\ttraffic_fine_amount\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"Setup: \")\n",
    "print(prompt)\n",
    "\n",
    "print(\"Setting up the agents... \")\n",
    "\n",
    "# Instantiate the agents with the default constructor defined values\n",
    "# Developer may override the default values - prompt, model, logger, and language model interface if needed\n",
    "\n",
    "# This agent use gpt-4o by default\n",
    "file_ingestion_agent = FileAccessAgent()\n",
    "\n",
    "# Let's make sure agent uses o3-mini model and set the reasoning_effort to high\n",
    "data_analysis_agent = PythonExecAgent(model_name='o3-mini', reasoning_effort='high')\n",
    "\n",
    "print(\"Understanding the contents of the file...\")\n",
    "# Give a task to the file ingestion agent to read the file and provide the context to the data analysis agent \n",
    "file_ingestion_agent_output = file_ingestion_agent.task(prompt)\n",
    "\n",
    "# Add the file content as context to the data analysis agent\n",
    "# The context is added to the agent's tool manager so that the tool manager can use the context to generate the code \n",
    "\n",
    "data_analysis_agent.add_context(prompt)\n",
    "data_analysis_agent.add_context(file_ingestion_agent_output)\n",
    "\n",
    "while True:\n",
    "\n",
    "    print(\"Type your question related to the data in the file. Type 'exit' to exit.\")\n",
    "    user_input = input(\"Type your question.\")\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        print(\"Exiting the application.\")\n",
    "        break\n",
    "\n",
    "    print(f\"User question: {user_input}\")\n",
    "\n",
    "    print(\"Generating dynamic tools and using code interpreter...\")\n",
    "    data_analysis_agent_output = data_analysis_agent.task(user_input)\n",
    "\n",
    "    print(\"Output...\")\n",
    "    print(data_analysis_agent_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f96b97",
   "metadata": {},
   "source": [
    "この例では、**o3-mini**がユーザーの質問に基づいてデータを分析するためのツール（Pythonスクリプト）を動的に生成しました。**o3-mini**は相関分析、線形回帰、ランダムフォレストモデルなど、複数のアプローチを使用して問題を検証したことに注目してください。このアプローチは以下の点を強調しています：\n",
    "\n",
    "**reasoning_effort**: モデルが実行する推論の深さ（例：この場合のアプローチ数）は、一般的にパラメータをlow、medium、highに増加させると向上します。異なるレベルの推論努力を試して、その違いを確認することができます。\n",
    "\n",
    "**動的に生成されるツール呼び出し**: データを分析するためのツール（Pythonスクリプト）は、開発者によって手動で書かれたり、事前に決定されたりしたものではありません。代わりに、o3-miniモデルが実行時に関連するデータ探索と相関分析のコードを作成しました。\n",
    "\n",
    "**分離されたコード実行**: セキュリティを確保し、ホストマシン上で信頼できないコードの実行を避けるため、Pythonスクリプトは`execute_python_code`ツールを使用してDockerコンテナ内で実行されました。このコンテナはリソースアクセスが制限されており（例：ネットワークなし、ファイルシステムアクセス制限）、任意のコード実行によって生じる潜在的なリスクを最小限に抑えています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ed586",
   "metadata": {},
   "source": [
    "### 結論\n",
    "\n",
    "このCookbookでは、言語の制約、コストの考慮、異なるLLMやモデルでの柔軟性の必要性など、ベンダー提供のソリューションで見られる制限に対処し、特定のアプリケーションニーズに合わせた**カスタムコードインタープリター**を開発するためのガイドを提供しています。\n",
    "\n",
    "**エージェントとツールの管理アプローチ**: また、エージェントとツールを管理するためのコアクラスのセットを定義しました。このアプローチにより、エージェントとツールが一貫したインターフェースを持ち、異なるアプリケーション間で再利用できることが保証されます。[registry](https://github.com/openai/openai-cookbook/tree/main/examples/object_oriented_agentic_approach/resources/registry)フォルダのようなエージェントとツールのリポジトリを作成して、エージェントとツールを管理することができます。\n",
    "\n",
    "**o3-miniモデル**: ユーザーの最小限のプロンプトに基づいてデータを分析するために、実行時に洗練されたコードを生成するo3-miniモデルの能力を実証しました。o3-miniモデルは、分析の結果を推論して、ユーザーに結果を説明しました。\n",
    "\n",
    "最後に、**要約すると**、動的ツール呼び出しを使用したAgenticアプリケーションを構築するための3つのステップは以下の通りです：\n",
    "1. 分離されたコード実行コンテナ環境のセットアップ\n",
    "2. エージェントの定義とテスト\n",
    "3. アプリケーションを実行するためのAgentic Orchestrationのセットアップ\n",
    "\n",
    "セキュリティを確保し、ホストマシン上で信頼できないコードの実行を避けるために、コード実行環境を分離することの重要性について議論しました。CSVファイルのユースケースを使用して、データを分析してユーザーの質問に答えるためのツール（Pythonスクリプト）を動的に生成する方法を実証しました。また、Dockerコンテナでコードを実行し、出力をユーザーに返す方法も示しました。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
