{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1537e6",
   "metadata": {},
   "source": [
    "# WeaviateでのOpenAI Q&Aモジュールを使った質問応答\n",
    "\n",
    "このノートブックは以下のシナリオ向けに準備されています：\n",
    "* データがベクトル化されていない場合\n",
    "* [OpenAI completions](https://beta.openai.com/docs/api-reference/completions)エンドポイントに基づいて、データに対してQ&A（[詳細はこちら](https://weaviate.io/developers/weaviate/modules/reader-generator-modules/qna-openai)）を実行したい場合\n",
    "* OpenAIモジュール（[text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)）を使用してWeaviateを利用し、ベクトル埋め込みを生成したい場合\n",
    "\n",
    "このノートブックでは、Weaviateインスタンスのセットアップ、接続（OpenAI APIキーを使用）、データスキーマの設定、データのインポート（データのベクトル埋め込みを自動生成）、質問応答の実行という簡単なフローを説明します。\n",
    "\n",
    "## Weaviateとは\n",
    "\n",
    "Weaviateは、データオブジェクトとそのベクトルを一緒に保存するオープンソースのベクトル検索エンジンです。これにより、ベクトル検索と構造化フィルタリングを組み合わせることができます。\n",
    "\n",
    "WeaviateはKNNアルゴリズムを使用してベクトル最適化されたインデックスを作成し、クエリを非常に高速に実行できます。詳細は[こちら](https://weaviate.io/blog/why-is-vector-search-so-fast)をご覧ください。\n",
    "\n",
    "Weaviateでは、お気に入りのMLモデルを使用でき、数十億のデータオブジェクトまでシームレスにスケールできます。\n",
    "\n",
    "### デプロイメントオプション\n",
    "\n",
    "シナリオや本番環境のセットアップに関係なく、Weaviateにはあなたに適したオプションがあります。Weaviateは以下のセットアップでデプロイできます：\n",
    "* セルフホスト – dockerを使用してローカルまたは任意のサーバーにWeaviateをデプロイできます。\n",
    "* SaaS – [Weaviate Cloud Service (WCS)](https://console.weaviate.io/)を使用してWeaviateインスタンスをホストできます。\n",
    "* Hybrid-SaaS – 独自のプライベートクラウドサービスにWeaviateをデプロイできます\n",
    "\n",
    "### プログラミング言語\n",
    "\n",
    "Weaviateは4つの[クライアントライブラリ](https://weaviate.io/developers/weaviate/client-libraries)を提供しており、アプリケーションから通信できます：\n",
    "* [Python](https://weaviate.io/developers/weaviate/client-libraries/python)\n",
    "* [JavaScript](https://weaviate.io/developers/weaviate/client-libraries/javascript)\n",
    "* [Java](https://weaviate.io/developers/weaviate/client-libraries/java)\n",
    "* [Go](https://weaviate.io/developers/weaviate/client-libraries/go)\n",
    "\n",
    "さらに、Weaviateには[RESTレイヤー](https://weaviate.io/developers/weaviate/api/rest/objects)があります。基本的に、RESTリクエストをサポートする任意の言語からWeaviateを呼び出すことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45956173",
   "metadata": {},
   "source": [
    "## デモフロー\n",
    "デモフローは以下の通りです：\n",
    "- **前提条件のセットアップ**: Weaviateインスタンスを作成し、必要なライブラリをインストール\n",
    "- **接続**: Weaviateインスタンスに接続\n",
    "- **スキーマ設定**: データのスキーマを設定\n",
    "    - *注意*: ここで使用するOpenAI Embedding Modelを定義できます\n",
    "    - *注意*: ここでインデックス化するプロパティを設定できます\n",
    "- **データインポート**: デモデータセットを読み込み、Weaviateにインポート\n",
    "    - *注意*: インポートプロセスは、スキーマの設定に基づいて自動的にデータをインデックス化します\n",
    "    - *注意*: データを明示的にベクトル化する必要はありません。WeaviateがOpenAIと通信して自動的に行います\n",
    "- **クエリ実行**: クエリを実行\n",
    "    - *注意*: クエリを明示的にベクトル化する必要はありません。WeaviateがOpenAIと通信して自動的に行います\n",
    "    - *注意*: `qna-openai`モジュールは自動的にOpenAI completionsエンドポイントと通信します\n",
    "\n",
    "このノートブックを実行し終えると、質問応答のためのベクトルデータベースの設定と使用方法について基本的な理解が得られるはずです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a145e",
   "metadata": {},
   "source": [
    "## WeaviateのOpenAIモジュール\n",
    "すべてのWeaviateインスタンスには、[text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)と[qna-openai](https://weaviate.io/developers/weaviate/modules/reader-generator-modules/qna-openai)モジュールが搭載されています。\n",
    "\n",
    "最初のモジュールは、インポート時（またはCRUD操作時）および検索クエリ実行時のベクトル化処理を担当します。2番目のモジュールは、OpenAIのcompletionsエンドポイントと通信します。\n",
    "\n",
    "### データを手動でベクトル化する必要がありません\n",
    "これはあなたにとって素晴らしいニュースです。[text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)を使用すると、Weaviateが必要に応じてOpenAIを呼び出してくれるため、データを手動でベクトル化する必要がありません。\n",
    "\n",
    "必要なことは以下だけです：\n",
    "1. OpenAI API Keyを提供する – Weaviate Clientに接続する際\n",
    "2. スキーマで使用するOpenAIベクトライザーを定義する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a618c5",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "このプロジェクトを開始する前に、以下の設定が必要です：\n",
    "\n",
    "* `Weaviate`インスタンスの作成\n",
    "* ライブラリのインストール\n",
    "    * `weaviate-client`\n",
    "    * `datasets`\n",
    "    * `apache-beam`\n",
    "* [OpenAI API key](https://beta.openai.com/account/api-keys)の取得\n",
    "\n",
    "===========================================================\n",
    "### Weaviateインスタンスの作成\n",
    "\n",
    "Weaviateインスタンスを作成するには2つのオプションがあります：\n",
    "\n",
    "1. （推奨）[Weaviate Cloud Service](https://console.weaviate.io/) – クラウドでWeaviateインスタンスをホストします。無料のサンドボックスでこのクックブックには十分です。\n",
    "2. Dockerを使用してWeaviateをローカルにインストールして実行します。\n",
    "\n",
    "#### オプション1 – WCSインストール手順\n",
    "\n",
    "[Weaviate Cloud Service](https://console.weaviate.io/)（WCS）を使用して無料のWeaviateクラスターを作成します。\n",
    "1. [WCS](https://console.weaviate.io/)で無料アカウントを作成し、ログインします\n",
    "2. 以下の設定で`Weaviate Cluster`を作成します：\n",
    "    * Sandbox: `Sandbox Free`\n",
    "    * Weaviate Version: デフォルトを使用（最新版）\n",
    "    * OIDC Authentication: `Disabled`\n",
    "3. インスタンスは1〜2分で準備完了します\n",
    "4. `Cluster Id`をメモしてください。リンクからクラスターの完全なパス（後で接続するために必要）に移動できます。`https://your-project-name.weaviate.network`のようなものになります\n",
    "\n",
    "#### オプション2 – DockerによるローカルWeaviateインスタンス\n",
    "\n",
    "Dockerを使用してWeaviateをローカルにインストールして実行します。\n",
    "1. [./docker-compose.yml](./docker-compose.yml)ファイルをダウンロードします\n",
    "2. ターミナルを開き、docker-compose.ymlファイルがある場所に移動して、`docker-compose up -d`でDockerを起動します\n",
    "3. 準備が完了すると、インスタンスは[http://localhost:8080](http://localhost:8080)で利用可能になります\n",
    "\n",
    "注意：Dockerインスタンスをシャットダウンするには`docker-compose down`を実行してください\n",
    "\n",
    "##### 詳細情報\n",
    "DockerでWeaviateを使用する詳細については、[インストールドキュメント](https://weaviate.io/developers/weaviate/installation/docker-compose)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9babafe",
   "metadata": {},
   "source": [
    "===========================================================    \n",
    "## 必要なライブラリのインストール\n",
    "\n",
    "このプロジェクトを実行する前に、以下のライブラリがインストールされていることを確認してください：\n",
    "\n",
    "### Weaviate Python client\n",
    "\n",
    "[Weaviate Python client](https://weaviate.io/developers/weaviate/client-libraries/python)を使用すると、PythonプロジェクトからWeaviateインスタンスと通信することができます。\n",
    "\n",
    "### datasets & apache-beam\n",
    "\n",
    "サンプルデータを読み込むには、`datasets`ライブラリとその依存関係である`apache-beam`が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Weaviate client for Python\n",
    "!pip install weaviate-client>3.11.0\n",
    "\n",
    "# Install datasets and apache-beam to load the sample datasets\n",
    "!pip install datasets apache-beam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe86f4",
   "metadata": {},
   "source": [
    "## OpenAI APIキーの準備\n",
    "\n",
    "`OpenAI API key`は、インポート時のデータのベクトル化とクエリに使用されます。\n",
    "\n",
    "OpenAI APIキーをお持ちでない場合は、[https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys)から取得できます。\n",
    "\n",
    "キーを取得したら、環境変数に`OPENAI_API_KEY`として追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ded4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export OpenAI API Key\n",
    "!export OPENAI_API_KEY=\"your key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that your OpenAI API key is correctly set as an environment variable\n",
    "# Note. if you run this notebook locally, you will need to reload your terminal and the notebook for the env variables to be live.\n",
    "import os\n",
    "\n",
    "# Note. alternatively you can set a temporary env variable like this:\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-goes-here'\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print (\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print (\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df4d5b",
   "metadata": {},
   "source": [
    "## Weaviateインスタンスに接続する\n",
    "\n",
    "このセクションでは、以下を行います：\n",
    "\n",
    "1. 環境変数 `OPENAI_API_KEY` をテストします – [#Prepare-your-OpenAI-API-key](#Prepare-your-OpenAI-API-key) のステップを完了していることを**確認してください**\n",
    "2. あなたの `OpenAI API Key` を使用してWeaviateに接続します\n",
    "3. クライアント接続をテストします\n",
    "\n",
    "### クライアント\n",
    "\n",
    "このステップの後、`client` オブジェクトはすべてのWeaviate関連の操作を実行するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc662c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# Connect to your Weaviate instance\n",
    "client = weaviate.Client(\n",
    "    url=\"https://your-wcs-instance-name.weaviate.network/\",\n",
    "#   url=\"http://localhost:8080/\",\n",
    "    auth_client_secret=weaviate.auth.AuthApiKey(api_key=\"<YOUR-WEAVIATE-API-KEY>\"), # comment out this line if you are not using authentication for your Weaviate instance (i.e. for locally deployed instances)\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check if your instance is live and ready\n",
    "# This should return `True`\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dac3c",
   "metadata": {},
   "source": [
    "# スキーマ\n",
    "\n",
    "このセクションでは、以下を行います：\n",
    "1. データのデータスキーマを設定する\n",
    "2. OpenAIモジュールを選択する\n",
    "\n",
    "> これは2番目で最後のステップであり、OpenAI固有の設定が必要です。\n",
    "> このステップの後、残りの手順はWeaviateのみに関するものとなります。OpenAIのタスクは自動的に処理されるためです。\n",
    "\n",
    "\n",
    "## スキーマとは\n",
    "\n",
    "Weaviateでは、検索対象となる各エンティティを捉えるために__スキーマ__を作成します。\n",
    "\n",
    "スキーマは、Weaviateに以下を伝える方法です：\n",
    "* データをベクトル化するために使用すべき埋め込みモデル\n",
    "* データの構成要素（プロパティ名と型）\n",
    "* どのプロパティをベクトル化してインデックス化すべきか\n",
    "\n",
    "このクックブックでは、`Articles`のデータセットを使用します。これには以下が含まれます：\n",
    "* `title`\n",
    "* `content`\n",
    "* `url`\n",
    "\n",
    "`title`と`content`をベクトル化したいですが、`url`はベクトル化しません。\n",
    "\n",
    "データをベクトル化してクエリするために、`text-embedding-3-small`を使用します。Q&Aには`gpt-3.5-turbo-instruct`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894b911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clear up the schema, so that we can recreate it\n",
    "client.schema.delete_all()\n",
    "client.schema.get()\n",
    "\n",
    "# Define the Schema object to use `text-embedding-3-small` on `title` and `content`, but skip it for `url`\n",
    "article_schema = {\n",
    "    \"class\": \"Article\",\n",
    "    \"description\": \"A collection of articles\",\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "          \"model\": \"ada\",\n",
    "          \"modelVersion\": \"002\",\n",
    "          \"type\": \"text\"\n",
    "        }, \n",
    "        \"qna-openai\": {\n",
    "          \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "          \"maxTokens\": 16,\n",
    "          \"temperature\": 0.0,\n",
    "          \"topP\": 1,\n",
    "          \"frequencyPenalty\": 0.0,\n",
    "          \"presencePenalty\": 0.0\n",
    "        }\n",
    "    },\n",
    "    \"properties\": [{\n",
    "        \"name\": \"title\",\n",
    "        \"description\": \"Title of the article\",\n",
    "        \"dataType\": [\"string\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"content\",\n",
    "        \"description\": \"Contents of the article\",\n",
    "        \"dataType\": [\"text\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"url\",\n",
    "        \"description\": \"URL to the article\",\n",
    "        \"dataType\": [\"string\"],\n",
    "        \"moduleConfig\": { \"text2vec-openai\": { \"skip\": True } }\n",
    "    }]\n",
    "}\n",
    "\n",
    "# add the Article schema\n",
    "client.schema.create_class(article_schema)\n",
    "\n",
    "# get the schema to make sure it worked\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9d2e1",
   "metadata": {},
   "source": [
    "## データのインポート\n",
    "\n",
    "このセクションでは以下を行います：\n",
    "1. Simple Wikipediaデータセットを読み込む\n",
    "2. Weaviate Batchインポートを設定する（インポートをより効率的にするため）\n",
    "3. データをWeaviateにインポートする\n",
    "\n",
    "> 注意: <br/>\n",
    "> 前述の通り、データを手動でベクトル化する必要はありません。<br/>\n",
    "> [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)モジュールがそれを処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3efadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 1 - load the dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "from typing import List, Iterator\n",
    "\n",
    "# We'll use the datasets library to pull the Simple Wikipedia dataset for embedding\n",
    "dataset = list(load_dataset(\"wikipedia\", \"20220301.simple\")[\"train\"])\n",
    "\n",
    "# For testing, limited to 2.5k articles for demo purposes\n",
    "dataset = dataset[:2_500]\n",
    "\n",
    "# Limited to 25k articles for larger demo purposes\n",
    "# dataset = dataset[:25_000]\n",
    "\n",
    "# for free OpenAI acounts, you can use 50 objects\n",
    "# dataset = dataset[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2 - configure Weaviate Batch, with\n",
    "# - starting batch size of 100\n",
    "# - dynamically increase/decrease based on performance\n",
    "# - add timeout retries if something goes wrong\n",
    "\n",
    "client.batch.configure(\n",
    "    batch_size=10, \n",
    "    dynamic=True,\n",
    "    timeout_retries=3,\n",
    "#   callback=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3 - import data\n",
    "\n",
    "print(\"Importing Articles\")\n",
    "\n",
    "counter=0\n",
    "\n",
    "with client.batch as batch:\n",
    "    for article in dataset:\n",
    "        if (counter %10 == 0):\n",
    "            print(f\"Import {counter} / {len(dataset)} \")\n",
    "\n",
    "        properties = {\n",
    "            \"title\": article[\"title\"],\n",
    "            \"content\": article[\"text\"],\n",
    "            \"url\": article[\"url\"]\n",
    "        }\n",
    "        \n",
    "        batch.add_data_object(properties, \"Article\")\n",
    "        counter = counter+1\n",
    "\n",
    "print(\"Importing Articles complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that all data has loaded – get object count\n",
    "result = (\n",
    "    client.query.aggregate(\"Article\")\n",
    "    .with_fields(\"meta { count }\")\n",
    "    .do()\n",
    ")\n",
    "print(\"Object count: \", result[\"data\"][\"Aggregate\"][\"Article\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d791186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one article has worked by checking one object\n",
    "test_article = (\n",
    "    client.query\n",
    "    .get(\"Article\", [\"title\", \"url\", \"content\"])\n",
    "    .with_limit(1)\n",
    "    .do()\n",
    ")[\"data\"][\"Get\"][\"Article\"][0]\n",
    "\n",
    "print(test_article['title'])\n",
    "print(test_article['url'])\n",
    "print(test_article['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46050ca9",
   "metadata": {},
   "source": [
    "### データに対する質問応答\n",
    "\n",
    "上記と同様に、新しいIndexに対していくつかのクエリを実行し、既存のベクトルとの近似度に基づいて結果を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(query, collection_name):\n",
    "    \n",
    "    properties = [\n",
    "        \"title\", \"content\", \"url\",\n",
    "        \"_additional { answer { hasAnswer property result startPosition endPosition } distance }\"\n",
    "    ]\n",
    "\n",
    "    ask = {\n",
    "        \"question\": query,\n",
    "        \"properties\": [\"content\"]\n",
    "    }\n",
    "\n",
    "    result = (\n",
    "        client.query\n",
    "        .get(collection_name, properties)\n",
    "        .with_ask(ask)\n",
    "        .with_limit(1)\n",
    "        .do()\n",
    "    )\n",
    "    \n",
    "    # Check for errors\n",
    "    if (\"errors\" in result):\n",
    "        print (\"\\033[91mYou probably have run out of OpenAI API calls for the current minute – the limit is set at 60 per minute.\")\n",
    "        raise Exception(result[\"errors\"][0]['message'])\n",
    "    \n",
    "    return result[\"data\"][\"Get\"][collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2025f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = qna(\"Did Alanis Morissette win a Grammy?\", \"Article\")\n",
    "\n",
    "for i, article in enumerate(query_result):\n",
    "    print(f\"{i+1}. { article['_additional']['answer']['result']} (Distance: {round(article['_additional']['distance'],3) })\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = qna(\"What is the capital of China?\", \"Article\")\n",
    "\n",
    "for i, article in enumerate(query_result):\n",
    "    if article['_additional']['answer']['hasAnswer'] == False:\n",
    "      print('No answer found')\n",
    "    else:\n",
    "      print(f\"{i+1}. { article['_additional']['answer']['result']} (Distance: {round(article['_additional']['distance'],3) })\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007be48",
   "metadata": {},
   "source": [
    "ここまでお疲れ様でした。これで独自のベクトルデータベースを設定し、埋め込みを使用してあらゆる種類の素晴らしいことを行う準備が整いました - お楽しみください！より複雑なユースケースについては、このリポジトリの他のクックブック例を引き続き参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
