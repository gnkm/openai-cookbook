{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46589cdf-1ab6-4028-b07c-08b75acd98e5",
   "metadata": {},
   "source": [
    "# ベクトル埋め込み、OpenAI、Astra DBを使った哲学\n",
    "\n",
    "### AstraPy バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3496d07-f473-4008-9133-1a54b818c8d3",
   "metadata": {},
   "source": [
    "このクイックスタートでは、OpenAIのベクトル埋め込みとDataStax [Astra DB](https://docs.datastax.com/en/astra/home/astra.html)をベクトルストアとして使用して、データの永続化を行う「哲学名言検索・生成器」の構築方法を学びます。\n",
    "\n",
    "このノートブックの基本的なワークフローを以下に示します。有名な哲学者の名言のベクトル埋め込みを評価・保存し、それらを使用して強力な検索エンジンを構築し、その後、新しい名言の生成器まで作成します！\n",
    "\n",
    "このノートブックは、ベクトル検索の標準的な使用パターンをいくつか例示しており、[Astra DB](https://docs.datastax.com/en/astra/home/astra.html)を使い始めることがいかに簡単かを示しています。\n",
    "\n",
    "ベクトル検索とテキスト埋め込みを使用して質問応答システムを構築することの背景については、この優れた実践的なノートブックをご確認ください：[Question answering using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)。\n",
    "\n",
    "目次：\n",
    "- セットアップ\n",
    "- ベクトルコレクションの作成\n",
    "- OpenAIへの接続\n",
    "- ベクトルストアへの名言の読み込み\n",
    "- 使用例1：**名言検索エンジン**\n",
    "- 使用例2：**名言生成器**\n",
    "- クリーンアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf17cc-eef4-4021-b72a-4d3832a9b4a7",
   "metadata": {},
   "source": [
    "### 仕組み\n",
    "\n",
    "**インデックス化**\n",
    "\n",
    "各引用文はOpenAIの`Embedding`を使用してエンベディングベクトルに変換されます。これらは後の検索で使用するためにVector Storeに保存されます。著者名やその他のいくつかの事前計算されたタグを含むメタデータも一緒に保存され、検索のカスタマイズを可能にします。\n",
    "\n",
    "![1_vector_indexing](https://user-images.githubusercontent.com/14221764/282422016-1d540607-eed4-4240-9c3d-22ee3a3bc90f.png)\n",
    "\n",
    "**検索**\n",
    "\n",
    "提供された検索引用文に類似した引用文を見つけるために、後者はその場でエンベディングベクトルに変換され、このベクトルを使用してストアから類似のベクトル、つまり以前にインデックス化された類似の引用文を検索します。検索は追加のメタデータによってオプションで制約することができます（「スピノザによる、これに類似した引用文を見つけて...」など）。\n",
    "\n",
    "![2_vector_search](https://user-images.githubusercontent.com/14221764/282422033-0a1297c4-63bb-4e04-b120-dfd98dc1a689.png)\n",
    "\n",
    "ここでの重要なポイントは、「内容が類似した引用文」がベクトル空間では、互いに距離的に近いベクトルに変換されることです。つまり、ベクトル類似性検索は効果的に意味的類似性を実装します。_これがベクトルエンベディングが非常に強力である主要な理由です。_\n",
    "\n",
    "以下のスケッチはこのアイデアを伝えようとしています。各引用文は、ベクトルに変換されると、空間内の点になります。この場合、OpenAIのエンベディングベクトルは、他の多くのベクトルと同様に_単位長_に正規化されているため、球面上の点となります。そして、この球面は実際には3次元ではなく、1536次元です！\n",
    "\n",
    "つまり、本質的に、ベクトル空間での類似性検索は、クエリベクトルに最も近いベクトルを返します：\n",
    "\n",
    "![3_vector_space](https://user-images.githubusercontent.com/14221764/262321363-c8c625c1-8be9-450e-8c68-b1ed518f990d.png)\n",
    "\n",
    "**生成**\n",
    "\n",
    "提案（トピックまたは暫定的な引用文）が与えられると、検索ステップが実行され、最初に返された結果（引用文）がLLMプロンプトに入力されます。このプロンプトは、渡された例_と_初期提案に沿って新しいテキストを発明するよう生成モデルに要求します。\n",
    "\n",
    "![4_quote_generation](https://user-images.githubusercontent.com/14221764/282422050-2e209ff5-07d6-41ac-99ac-f442e090b3bb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493f44-565d-4f23-8bfd-1a7335392c2b",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a14f95-4683-4d0c-a251-0df7b43ca975",
   "metadata": {},
   "source": [
    "必要な依存関係をインストールしてインポートします："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39afdb74-56e4-44ff-9c72-ab2669780113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet \"astrapy>=0.6.0\" \"openai>=1.0.0\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca6f5c6-30b4-4518-a816-5c732a60e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from collections import Counter\n",
    "\n",
    "from astrapy.db import AstraDB\n",
    "import openai\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb99e33-5cb7-416f-8dca-da18e0cb108d",
   "metadata": {},
   "source": [
    "### 接続パラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8edc1-4633-491b-9ed3-11163ec24e46",
   "metadata": {},
   "source": [
    "Astraダッシュボードでデータベースの認証情報を取得してください（[詳細](https://docs.datastax.com/en/astra/astra-db-vector/)）。これらの情報はすぐに必要になります。\n",
    "\n",
    "例の値：\n",
    "\n",
    "- API Endpoint: `https://01234567-89ab-cdef-0123-456789abcdef-us-east1.apps.astra.datastax.com`\n",
    "- Token: `AstraCS:6gBhNmsk135...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5a2f5d-3ff2-43d6-91c0-4a52c0ecd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your API Endpoint: https://4f835778-ec78-42b0-9ae3-29e3cf45b596-us-east1.apps.astra.datastax.com\n",
      "Please enter your Token ········\n"
     ]
    }
   ],
   "source": [
    "ASTRA_DB_API_ENDPOINT = input(\"Please enter your API Endpoint:\")\n",
    "ASTRA_DB_APPLICATION_TOKEN = getpass(\"Please enter your Token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4e5ec-2ab2-4d41-b3ec-c946469fed8b",
   "metadata": {},
   "source": [
    "### Astra DBクライアントのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b526e55-ad2c-413d-94b1-cf651afefd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_db = AstraDB(\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60829851-bd48-4461-9243-974f76304933",
   "metadata": {},
   "source": [
    "## ベクターコレクションの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd19dc-0580-42c2-8d45-1cef52050a59",
   "metadata": {},
   "source": [
    "コレクション名以外に指定する唯一のパラメータは、保存するベクトルの次元数です。その他のパラメータ、特に検索に使用する類似度メトリックは、オプションです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db837dc-cd49-41e2-8b5d-edb17ccc470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_name = \"philosophers_astra_db\"\n",
    "collection = astra_db.create_collection(coll_name, dimension=1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86f91a-88a6-4997-b0f8-9da0816f8ece",
   "metadata": {},
   "source": [
    "## OpenAIに接続する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b664b5-fd84-492e-a7bd-4dda3863b48a",
   "metadata": {},
   "source": [
    "### シークレットキーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fe7653-dd64-4494-83e1-5702ec41725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass(\"Please enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f2821-7f3f-4dcd-8e0c-49aa397e36f4",
   "metadata": {},
   "source": [
    "### 埋め込みのテストコール\n",
    "\n",
    "入力テキストのリストに対して埋め込みベクトルを取得する方法を簡単に確認してみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf89454-9a55-4202-ab6b-ea15b2048f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "embedding_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "result = client.embeddings.create(\n",
    "    input=[\n",
    "        \"This is a sentence\",\n",
    "        \"A second sentence\"\n",
    "    ],\n",
    "    model=embedding_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2841934-7b2a-4a00-b112-b0865c9ec593",
   "metadata": {},
   "source": [
    "_注意: 上記はOpenAI v1.0+の構文です。以前のバージョンを使用している場合、埋め込みを取得するコードは異なって見えます。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a8e6f0-0aa7-4ffc-94e9-702b68566815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(result.data)              = 2\n",
      "result.data[1].embedding      = [-0.0108176339417696, 0.0013546717818826437, 0.00362232...\n",
      "len(result.data[1].embedding) = 1536\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(result.data)              = {len(result.data)}\")\n",
    "print(f\"result.data[1].embedding      = {str(result.data[1].embedding)[:55]}...\")\n",
    "print(f\"len(result.data[1].embedding) = {len(result.data[1].embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f09c42-fff3-4aa2-922b-043739b4b06a",
   "metadata": {},
   "source": [
    "## ベクターストアに引用文を読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f3d58-74c2-458b-903d-3d12e61b7846",
   "metadata": {},
   "source": [
    "データセットから名言を取得します。_（このデモで使用するために、[このKaggleデータセット](https://www.kaggle.com/datasets/mertbozkurt5/quotes-by-philosophers)のデータを適応・拡張しました。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa68f038-3240-4e22-b7c6-a5f214eda381",
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b08b1-e3db-4c7c-9d7c-2ada7c8bc71d",
   "metadata": {},
   "source": [
    "簡単な検査："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b629cf-efd7-434a-9dc6-7f38f35f7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example entry:\n",
      "{'author': 'aristotle', 'quote': 'Love well, be loved and do something of value.', 'tags': 'love;ethics'}\n"
     ]
    }
   ],
   "source": [
    "print(\"An example entry:\")\n",
    "print(philo_dataset[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badaa4d-80ea-462c-bb00-1909c6435eea",
   "metadata": {},
   "source": [
    "データセットのサイズを確認してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b33ac73-f8f2-4b64-8a27-178ac76886a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 450 quotes. By author:\n",
      "    aristotle           : 50 quotes\n",
      "    schopenhauer        : 50 quotes\n",
      "    spinoza             : 50 quotes\n",
      "    hegel               : 50 quotes\n",
      "    freud               : 50 quotes\n",
      "    nietzsche           : 50 quotes\n",
      "    sartre              : 50 quotes\n",
      "    plato               : 50 quotes\n",
      "    kant                : 50 quotes\n"
     ]
    }
   ],
   "source": [
    "author_count = Counter(entry[\"author\"] for entry in philo_dataset)\n",
    "print(f\"Total: {len(philo_dataset)} quotes. By author:\")\n",
    "for author, count in author_count.most_common():\n",
    "    print(f\"    {author:<20}: {count} quotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062157d1-d262-4735-b06c-f3112575b4cc",
   "metadata": {},
   "source": [
    "### ベクターコレクションへの書き込み\n",
    "\n",
    "引用文の埋め込みを計算し、テキスト自体と後で使用するメタデータと一緒にVector Storeに保存します。\n",
    "\n",
    "速度を最適化し、呼び出し回数を削減するために、OpenAIの埋め込みサービスに対してバッチ呼び出しを実行します。\n",
    "\n",
    "引用オブジェクトを保存するには、コレクションの`insert_many`メソッドを使用します（バッチごとに1回の呼び出し）。挿入用のドキュメントを準備する際は、適切なフィールド名を選択してください。ただし、埋め込みベクターは固定の特別な`$vector`フィールドでなければならないことに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab84ccb-3363-4bdc-9484-0d68c25a58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to store entries: [20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][20][10]\n",
      "Finished storing entries.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "num_batches = ((len(philo_dataset) + BATCH_SIZE - 1) // BATCH_SIZE)\n",
    "\n",
    "quotes_list = philo_dataset[\"quote\"]\n",
    "authors_list = philo_dataset[\"author\"]\n",
    "tags_list = philo_dataset[\"tags\"]\n",
    "\n",
    "print(\"Starting to store entries: \", end=\"\")\n",
    "for batch_i in range(num_batches):\n",
    "    b_start = batch_i * BATCH_SIZE\n",
    "    b_end = (batch_i + 1) * BATCH_SIZE\n",
    "    # compute the embedding vectors for this batch\n",
    "    b_emb_results = client.embeddings.create(\n",
    "        input=quotes_list[b_start : b_end],\n",
    "        model=embedding_model_name,\n",
    "    )\n",
    "    # prepare the documents for insertion\n",
    "    b_docs = []\n",
    "    for entry_idx, emb_result in zip(range(b_start, b_end), b_emb_results.data):\n",
    "        if tags_list[entry_idx]:\n",
    "            tags = {\n",
    "                tag: True\n",
    "                for tag in tags_list[entry_idx].split(\";\")\n",
    "            }\n",
    "        else:\n",
    "            tags = {}\n",
    "        b_docs.append({\n",
    "            \"quote\": quotes_list[entry_idx],\n",
    "            \"$vector\": emb_result.embedding,\n",
    "            \"author\": authors_list[entry_idx],\n",
    "            \"tags\": tags,\n",
    "        })\n",
    "    # write to the vector collection\n",
    "    collection.insert_many(b_docs)\n",
    "    print(f\"[{len(b_docs)}]\", end=\"\")\n",
    "\n",
    "print(\"\\nFinished storing entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ee629-b6b9-4a77-8c58-c3b93403a6a6",
   "metadata": {},
   "source": [
    "## ユースケース1: **引用検索エンジン**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b12b3-2557-4826-af5a-16e6cd9a4531",
   "metadata": {},
   "source": [
    "引用検索機能については、まず入力された引用をベクトルに変換し、それを使用してストアにクエリを実行する必要があります（検索呼び出しにオプションのメタデータを処理することに加えて）。\n",
    "\n",
    "再利用しやすくするために、検索エンジン機能を関数にカプセル化します。その核心となるのは、コレクションの`vector_find`メソッドです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6fcf182-3ab7-4d28-9472-dce35cc38182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quote_and_author(query_quote, n, author=None, tags=None):\n",
    "    query_vector = client.embeddings.create(\n",
    "        input=[query_quote],\n",
    "        model=embedding_model_name,\n",
    "    ).data[0].embedding\n",
    "    filter_clause = {}\n",
    "    if author:\n",
    "        filter_clause[\"author\"] = author\n",
    "    if tags:\n",
    "        filter_clause[\"tags\"] = {}\n",
    "        for tag in tags:\n",
    "            filter_clause[\"tags\"][tag] = True\n",
    "    #\n",
    "    results = collection.vector_find(\n",
    "        query_vector,\n",
    "        limit=n,\n",
    "        filter=filter_clause,\n",
    "        fields=[\"quote\", \"author\"]\n",
    "    )\n",
    "    return [\n",
    "        (result[\"quote\"], result[\"author\"])\n",
    "        for result in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539262d-100b-4e8d-864d-e9c612a73e91",
   "metadata": {},
   "source": [
    "### 検索機能をテストする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634165c-0882-4281-bc60-ab96261a500d",
   "metadata": {},
   "source": [
    "引用符のみを渡す場合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6722c2c0-3e54-4738-80ce-4d1149e95414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life to the great majority is only a constant struggle for mere existence, with the certainty of losing it at last.',\n",
       "  'schopenhauer'),\n",
       " ('We give up leisure in order that we may have leisure, just as we go to war in order that we may have peace.',\n",
       "  'aristotle'),\n",
       " ('Perhaps the gods are kind to us, by making life more disagreeable as we grow older. In the end death seems less intolerable than the manifold burdens we carry',\n",
       "  'freud')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50828e4c-9bb5-4489-9fe9-87da5fbe1f18",
   "metadata": {},
   "source": [
    "作成者に制限された検索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da9c705f-5c12-42b3-a038-202f89a3c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To live is to suffer, to survive is to find some meaning in the suffering.',\n",
       "  'nietzsche'),\n",
       " ('What makes us heroic?--Confronting simultaneously our supreme suffering and our supreme hope.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, author=\"nietzsche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3857ea-6dfe-489a-9b86-4e5e0534960f",
   "metadata": {},
   "source": [
    "以前に引用符で保存したタグの中から検索を制限する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abcfaec9-8f42-4789-a5ed-1073fa2932c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He who seeks equality between unequals seeks an absurdity.', 'spinoza'),\n",
       " ('The people are that part of the state that does not know what it wants.',\n",
       "  'hegel')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, tags=[\"politics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fe38f-139f-44a6-a225-a63e40d3ddf5",
   "metadata": {},
   "source": [
    "### 無関係な結果の除外\n",
    "\n",
    "ベクトル類似度検索は一般的に、クエリに最も近いベクトルを返します。これは、より良い結果がない場合でも、やや無関係な結果を含む可能性があることを意味します。\n",
    "\n",
    "この問題を制御するために、クエリと各結果の間の実際の「類似度」を取得し、それに対してカットオフを実装することで、閾値を超える結果を効果的に破棄できます。\n",
    "この閾値を正しく調整することは簡単な問題ではありません。ここでは、その方法をお見せします。\n",
    "\n",
    "これがどのように動作するかを理解するために、以下のクエリを試して、引用文と閾値の選択を変更して結果を比較してみてください。類似度は各結果ドキュメントの特別な`$similarity`フィールドとして返されることに注意してください。これは、検索メソッドに`include_similarity = False`を渡さない限り、デフォルトで返されます。\n",
    "\n",
    "_注記（数学的に興味のある方へ）：この値は、ベクトル間のコサイン差、つまり2つのベクトルのノルムの積で割ったスカラー積の**0と1の間での再スケーリング**です。言い換えると、これは反対方向のベクトルでは0、平行なベクトルでは+1になります。他の類似度測定方法（コサインがデフォルト）については、`AstraDB.create_collection`の`metric`パラメータと[許可される値に関するドキュメント](https://docs.datastax.com/en/astra-serverless/docs/develop/dev-with-json.html#metric-types)を確認してください。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b43721-a3b0-4ac4-b730-7a6aeec52e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 quotes within the threshold:\n",
      "    0. [similarity=0.927] \"The assumption that animals are without rights, and the illusion that ...\"\n",
      "    1. [similarity=0.922] \"Animals are in possession of themselves; their soul is in possession o...\"\n",
      "    2. [similarity=0.920] \"At his best, man is the noblest of all animals; separated from law and...\"\n"
     ]
    }
   ],
   "source": [
    "quote = \"Animals are our equals.\"\n",
    "# quote = \"Be good.\"\n",
    "# quote = \"This teapot is strange.\"\n",
    "\n",
    "metric_threshold = 0.92\n",
    "\n",
    "quote_vector = client.embeddings.create(\n",
    "    input=[quote],\n",
    "    model=embedding_model_name,\n",
    ").data[0].embedding\n",
    "\n",
    "results_full = collection.vector_find(\n",
    "    quote_vector,\n",
    "    limit=8,\n",
    "    fields=[\"quote\"]\n",
    ")\n",
    "results = [res for res in results_full if res[\"$similarity\"] >= metric_threshold]\n",
    "\n",
    "print(f\"{len(results)} quotes within the threshold:\")\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"    {idx}. [similarity={result['$similarity']:.3f}] \\\"{result['quote'][:70]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71871251-169f-4d3f-a687-65f836a9a8fe",
   "metadata": {},
   "source": [
    "## ユースケース2: **引用文ジェネレーター**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9cd63-a131-4819-bf41-c8ffa0b1e1ca",
   "metadata": {},
   "source": [
    "このタスクには、OpenAIの別のコンポーネント、つまりVector Storeへのクエリで取得した入力に基づいて見積もりを生成するLLMが必要です。\n",
    "\n",
    "また、generate-quote LLM完了タスクのために入力されるプロンプトのテンプレートも必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6dd366d-665a-45fd-917b-b6b5312b0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "generation_prompt_template = \"\"\"\"Generate a single short philosophical quote on the given topic,\n",
    "similar in spirit and form to the provided actual example quotes.\n",
    "Do not exceed 20-30 words in your quote.\n",
    "\n",
    "REFERENCE TOPIC: \"{topic}\"\n",
    "\n",
    "ACTUAL EXAMPLES:\n",
    "{examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53073a9e-16de-4e49-9e97-ff31b9b250c2",
   "metadata": {},
   "source": [
    "検索と同様に、この機能は便利な関数にラップするのが最適です（内部的には検索を使用します）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397e6ebd-b30e-413b-be63-81a62947a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(topic, n=2, author=None, tags=None):\n",
    "    quotes = find_quote_and_author(query_quote=topic, n=n, author=author, tags=tags)\n",
    "    if quotes:\n",
    "        prompt = generation_prompt_template.format(\n",
    "            topic=topic,\n",
    "            examples=\"\\n\".join(f\"  - {quote[0]}\" for quote in quotes),\n",
    "        )\n",
    "        # a little logging:\n",
    "        print(\"** quotes found:\")\n",
    "        for q, a in quotes:\n",
    "            print(f\"**    - {q} ({a})\")\n",
    "        print(\"** end of logging\")\n",
    "        #\n",
    "        response = client.chat.completions.create(\n",
    "            model=completion_model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=320,\n",
    "        )\n",
    "        return response.choices[0].message.content.replace('\"', '').strip()\n",
    "    else:\n",
    "        print(\"** no quotes found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f8488-899b-4d4c-a069-73643a778200",
   "metadata": {},
   "source": [
    "_注意：埋め込み計算の場合と同様に、Chat Completion APIのコードはOpenAI v1.0以前では若干異なります。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcc157-e5d4-43ef-8028-d4dcc8a72b9c",
   "metadata": {},
   "source": [
    "#### 見積もり生成をテストする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b3f38-089d-486d-b32c-e665c725faa8",
   "metadata": {},
   "source": [
    "単にテキストを渡すだけです（「引用」ですが、実際にはトピックを提案するだけでも構いません。そのベクトル埋め込みは、ベクトル空間内の適切な場所に配置されるためです）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "806ba758-8988-410e-9eeb-b9c6799e6b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Happiness is the reward of virtue. (aristotle)\n",
      "**    - Our moral virtues benefit mainly other people; intellectual virtues, on the other hand, benefit primarily ourselves; therefore the former make us universally popular, the latter unpopular. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "True politics lies in the virtuous pursuit of justice, for it is through virtue that we build a better world for all.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"politics and virtue\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca032d30-4538-4d0b-aea1-731fb32d2d4b",
   "metadata": {},
   "source": [
    "単一の哲学者からのインスピレーションを使用してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2e2d4e-865f-4b2d-80cd-a695271415d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Because Christian morality leaves animals out of account, they are at once outlawed in philosophical morals; they are mere 'things,' mere means to any ends whatsoever. They can therefore be used for vivisection, hunting, coursing, bullfights, and horse racing, and can be whipped to death as they struggle along with heavy carts of stone. Shame on such a morality that is worthy of pariahs, and that fails to recognize the eternal essence that exists in every living thing, and shines forth with inscrutable significance from all eyes that see the sun! (schopenhauer)\n",
      "**    - The assumption that animals are without rights, and the illusion that our treatment of them has no moral significance, is a positively outrageous example of Western crudity and barbarity. Universal compassion is the only guarantee of morality. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "Excluding animals from ethical consideration reveals a moral blindness that allows for their exploitation and suffering. True morality embraces universal compassion.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"animals\", author=\"schopenhauer\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8368a-9e23-49a5-8694-921728ea9656",
   "metadata": {},
   "source": [
    "## クリーンアップ\n",
    "\n",
    "このデモで使用したすべてのリソースを削除したい場合は、このセルを実行してください（_警告: これによりコレクションとそのデータが不可逆的に削除されます！_）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb0fd16-7e15-4742-8fc5-94d9eeeda620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': {'ok': 1}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_db.delete_collection(coll_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
