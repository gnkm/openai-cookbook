{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46589cdf-1ab6-4028-b07c-08b75acd98e5",
   "metadata": {},
   "source": [
    "# ベクトル埋め込み、OpenAI、CQL を通じた Cassandra / Astra DB を使った哲学\n",
    "\n",
    "### CassIO バージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3496d07-f473-4008-9133-1a54b818c8d3",
   "metadata": {},
   "source": [
    "このクイックスタートでは、OpenAIのベクトル埋め込みと[Apache Cassandra®](https://cassandra.apache.org)、または同等のDataStax [Astra DB through CQL](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html)をベクトルストアとしてデータ永続化に使用して、「哲学の名言検索・生成器」を構築する方法を学びます。\n",
    "\n",
    "このノートブックの基本的なワークフローは以下に概説されています。有名な哲学者による多数の名言のベクトル埋め込みを評価・保存し、それらを使用して強力な検索エンジンを構築し、その後、新しい名言の生成器まで作成します！\n",
    "\n",
    "このノートブックは、ベクトル検索の標準的な使用パターンの一部を例示しており、[Cassandra](https://cassandra.apache.org/doc/trunk/cassandra/vector-search/overview.html) / [Astra DB through CQL](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html)のベクトル機能を使い始めることがいかに簡単かを示しています。\n",
    "\n",
    "ベクトル検索とテキスト埋め込みを使用して質問応答システムを構築する背景については、この優れた実践的なノートブックをご確認ください：[Question answering using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)。\n",
    "\n",
    "#### _フレームワークを選択_\n",
    "\n",
    "このノートブックは[CassIO library](https://cassio.org)を使用していますが、同じタスクを達成するための他の技術選択肢もカバーしています。他のオプションについては、このフォルダの[README](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/cassandra_astradb)をご確認ください。このノートブックはColabノートブックまたは通常のJupyterノートブックとして実行できます。\n",
    "\n",
    "目次：\n",
    "- セットアップ\n",
    "- DB接続の取得\n",
    "- OpenAIへの接続\n",
    "- ベクトルストアへの名言の読み込み\n",
    "- 使用例1：**名言検索エンジン**\n",
    "- 使用例2：**名言生成器**\n",
    "- （オプション）ベクトルストアでのパーティショニングの活用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf17cc-eef4-4021-b72a-4d3832a9b4a7",
   "metadata": {},
   "source": [
    "### 仕組み\n",
    "\n",
    "**インデックス化**\n",
    "\n",
    "各引用文はOpenAIの`Embedding`を使用してエンベディングベクトルに変換されます。これらは後の検索で使用するためにVector Storeに保存されます。著者名やその他のいくつかの事前計算されたタグを含むメタデータも一緒に保存され、検索のカスタマイズを可能にします。\n",
    "\n",
    "![1_vector_indexing](https://user-images.githubusercontent.com/14221764/282440878-dc3ed680-7d0e-4b30-9a74-d2d66a7394f7.png)\n",
    "\n",
    "**検索**\n",
    "\n",
    "提供された検索用引用文に類似した引用文を見つけるために、後者はその場でエンベディングベクトルに変換され、このベクトルを使用してストアから類似したベクトル、つまり以前にインデックス化された類似の引用文を検索します。検索は追加のメタデータによってオプションで制約することができます（「スピノザによるこれに似た引用文を見つけて...」など）。\n",
    "\n",
    "![2_vector_search](https://user-images.githubusercontent.com/14221764/282440908-683e3ee1-0bf1-46b3-8621-86c31fc7f9c9.png)\n",
    "\n",
    "ここでの重要なポイントは、「内容が類似した引用文」がベクトル空間では、互いに距離的に近いベクトルに変換されることです。つまり、ベクトル類似性検索は効果的に意味的類似性を実装します。_これがベクトルエンベディングが非常に強力である主な理由です。_\n",
    "\n",
    "以下のスケッチはこのアイデアを伝えようとしています。各引用文は、ベクトルに変換されると空間内の点になります。この場合、OpenAIのエンベディングベクトルは他の多くのベクトルと同様に_単位長_に正規化されているため、球面上の点になります。そして、この球面は実際には3次元ではなく、1536次元です！\n",
    "\n",
    "つまり、本質的にベクトル空間での類似性検索は、クエリベクトルに最も近いベクトルを返します：\n",
    "\n",
    "![3_vector_space](https://user-images.githubusercontent.com/14221764/262321363-c8c625c1-8be9-450e-8c68-b1ed518f990d.png)\n",
    "\n",
    "**生成**\n",
    "\n",
    "提案（トピックまたは仮の引用文）が与えられると、検索ステップが実行され、最初に返された結果（引用文）がLLMプロンプトに入力されます。このプロンプトは生成モデルに対して、渡された例_および_初期提案に沿った新しいテキストを発明するよう求めます。\n",
    "\n",
    "![4_quote_generation](https://user-images.githubusercontent.com/14221764/282440927-d56f36eb-d611-4342-8026-7736edc6f5c9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493f44-565d-4f23-8bfd-1a7335392c2b",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a14f95-4683-4d0c-a251-0df7b43ca975",
   "metadata": {},
   "source": [
    "まず、必要なパッケージをインストールしてください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39afdb74-56e4-44ff-9c72-ab2669780113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet \"cassio>=0.1.3\" \"openai>=1.0.0\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ceccaf-a55a-4442-89c1-0904aa7cc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from collections import Counter\n",
    "\n",
    "import cassio\n",
    "from cassio.table import MetadataVectorCassandraTable\n",
    "\n",
    "import openai\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb99e33-5cb7-416f-8dca-da18e0cb108d",
   "metadata": {},
   "source": [
    "## DB接続を取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8edc1-4633-491b-9ed3-11163ec24e46",
   "metadata": {},
   "source": [
    "CQLを通じてAstra DBに接続するには、以下の2つが必要です：\n",
    "- \"Database Administrator\"ロールを持つToken（`AstraCS:...`のような形式）\n",
    "- データベースID（`3df2a5b6-...`のような形式）\n",
    "\n",
    "    両方の文字列を確実に取得してください。これらは、サインイン後に[Astra UI](https://astra.datastax.com)で取得できます。詳細については、こちらを参照してください：[データベースID](https://awesome-astra.github.io/docs/pages/astra/faq/#where-should-i-find-a-database-identifier)と[Token](https://awesome-astra.github.io/docs/pages/astra/create-token/#c-procedure)。\n",
    "\n",
    "_Cassandraクラスターに接続したい_場合（ただし、Vector Searchを[サポート](https://cassandra.apache.org/doc/trunk/cassandra/vector-search/overview.html)している必要があります）、`cassio.init(session=..., keyspace=...)`を適切なSessionとクラスター用のキースペース名に置き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5a2f5d-3ff2-43d6-91c0-4a52c0ecd06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your Astra token ('AstraCS:...') ········\n",
      "Please enter your database id ('3df2a5b6-...') 01234567-89ab-dcef-0123-456789abcdef\n"
     ]
    }
   ],
   "source": [
    "astra_token = getpass(\"Please enter your Astra token ('AstraCS:...')\")\n",
    "database_id = input(\"Please enter your database id ('3df2a5b6-...')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe028b0-3a40-4f12-b07c-8fd8bbee29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=astra_token, database_id=database_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4e5ec-2ab2-4d41-b3ec-c946469fed8b",
   "metadata": {},
   "source": [
    "### DB接続の作成\n",
    "\n",
    "以下は、CQLを通じてAstra DBへの接続を作成する方法です：\n",
    "\n",
    "_（ちなみに、以下の`Cluster`インスタンス化の[パラメータを変更する](https://docs.datastax.com/en/developer/python-driver/latest/getting_started/#connecting-to-cassandra)ことで、任意のCassandraクラスター（ベクター機能を提供する限り）も使用できます。）_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60829851-bd48-4461-9243-974f76304933",
   "metadata": {},
   "source": [
    "### CassIOを通じたベクトルストアの作成\n",
    "\n",
    "ベクトルをサポートし、メタデータを備えたテーブルが必要です。これを「philosophers_cassio」と呼びます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691f1a07-cab4-42a1-baba-f17b561ddd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_table = MetadataVectorCassandraTable(table=\"philosophers_cassio\", vector_dimension=1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86f91a-88a6-4997-b0f8-9da0816f8ece",
   "metadata": {},
   "source": [
    "## OpenAIに接続"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b664b5-fd84-492e-a7bd-4dda3863b48a",
   "metadata": {},
   "source": [
    "### シークレットキーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fe7653-dd64-4494-83e1-5702ec41725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass(\"Please enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f2821-7f3f-4dcd-8e0c-49aa397e36f4",
   "metadata": {},
   "source": [
    "### 埋め込みのテストコール\n",
    "\n",
    "入力テキストのリストに対して埋め込みベクトルを取得する方法を素早く確認してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf89454-9a55-4202-ab6b-ea15b2048f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "embedding_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "result = client.embeddings.create(\n",
    "    input=[\n",
    "        \"This is a sentence\",\n",
    "        \"A second sentence\"\n",
    "    ],\n",
    "    model=embedding_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054be36-0300-4c47-ba81-a1fe14c0165f",
   "metadata": {},
   "source": [
    "_注意: 上記はOpenAI v1.0+の構文です。以前のバージョンを使用している場合、埋め込みを取得するコードは異なって見えます。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a8e6f0-0aa7-4ffc-94e9-702b68566815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(result.data)              = 2\n",
      "result.data[1].embedding      = [-0.010821706615388393, 0.001387271680869162, 0.0035479...\n",
      "len(result.data[1].embedding) = 1536\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(result.data)              = {len(result.data)}\")\n",
    "print(f\"result.data[1].embedding      = {str(result.data[1].embedding)[:55]}...\")\n",
    "print(f\"len(result.data[1].embedding) = {len(result.data[1].embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f09c42-fff3-4aa2-922b-043739b4b06a",
   "metadata": {},
   "source": [
    "## ベクトルストアに引用文を読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f3d58-74c2-458b-903d-3d12e61b7846",
   "metadata": {},
   "source": [
    "_注意: 上記はOpenAI v1.0+の構文です。以前のバージョンを使用している場合、埋め込みを取得するコードは異なって見えます。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a486ae9-f8f5-40c5-8fe7-f1328fe026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b08b1-e3db-4c7c-9d7c-2ada7c8bc71d",
   "metadata": {},
   "source": [
    "簡単な検査："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab84ccb-3363-4bdc-9484-0d68c25a58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example entry:\n",
      "{'author': 'aristotle', 'quote': 'Love well, be loved and do something of value.', 'tags': 'love;ethics'}\n"
     ]
    }
   ],
   "source": [
    "print(\"An example entry:\")\n",
    "print(philo_dataset[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e3bca-bded-4523-9550-14dce3a308d1",
   "metadata": {},
   "source": [
    "データセットのサイズを確認してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c08a9b27-df9a-4bba-8da1-8a87aac3cde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 450 quotes. By author:\n",
      "    aristotle           : 50 quotes\n",
      "    schopenhauer        : 50 quotes\n",
      "    spinoza             : 50 quotes\n",
      "    hegel               : 50 quotes\n",
      "    freud               : 50 quotes\n",
      "    nietzsche           : 50 quotes\n",
      "    sartre              : 50 quotes\n",
      "    plato               : 50 quotes\n",
      "    kant                : 50 quotes\n"
     ]
    }
   ],
   "source": [
    "author_count = Counter(entry[\"author\"] for entry in philo_dataset)\n",
    "print(f\"Total: {len(philo_dataset)} quotes. By author:\")\n",
    "for author, count in author_count.most_common():\n",
    "    print(f\"    {author:<20}: {count} quotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15745dc8-e7c1-4781-933b-41eef6ddd657",
   "metadata": {},
   "source": [
    "### ベクターストアに引用文を挿入する\n",
    "\n",
    "引用文の埋め込みを計算し、テキスト自体と後で使用予定のメタデータと共にベクターストアに保存します。著者は、引用文自体に既に含まれている「tags」と共にメタデータフィールドとして追加されることに注意してください。\n",
    "\n",
    "速度を最適化し、呼び出し回数を削減するため、OpenAIの埋め込みサービスに対してバッチ呼び出しを実行します。\n",
    "\n",
    "_（注意：より高速な実行のため、CassandraとCassIOでは並行挿入が可能ですが、よりわかりやすいデモコードにするため、ここでは使用していません。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4392f39c-5588-469b-99e0-940f6482a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to store entries:\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "B ************************************************** done (50)\n",
      "\n",
      "Finished storing entries.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "num_batches = ((len(philo_dataset) + BATCH_SIZE - 1) // BATCH_SIZE)\n",
    "\n",
    "quotes_list = philo_dataset[\"quote\"]\n",
    "authors_list = philo_dataset[\"author\"]\n",
    "tags_list = philo_dataset[\"tags\"]\n",
    "\n",
    "print(\"Starting to store entries:\")\n",
    "for batch_i in range(num_batches):\n",
    "    b_start = batch_i * BATCH_SIZE\n",
    "    b_end = (batch_i + 1) * BATCH_SIZE\n",
    "    # compute the embedding vectors for this batch\n",
    "    b_emb_results = client.embeddings.create(\n",
    "        input=quotes_list[b_start : b_end],\n",
    "        model=embedding_model_name,\n",
    "    )\n",
    "    # prepare the rows for insertion\n",
    "    print(\"B \", end=\"\")\n",
    "    for entry_idx, emb_result in zip(range(b_start, b_end), b_emb_results.data):\n",
    "        if tags_list[entry_idx]:\n",
    "            tags = {\n",
    "                tag\n",
    "                for tag in tags_list[entry_idx].split(\";\")\n",
    "            }\n",
    "        else:\n",
    "            tags = set()\n",
    "        author = authors_list[entry_idx]\n",
    "        quote = quotes_list[entry_idx]\n",
    "        v_table.put(\n",
    "            row_id=f\"q_{author}_{entry_idx}\",\n",
    "            body_blob=quote,\n",
    "            vector=emb_result.embedding,\n",
    "            metadata={**{tag: True for tag in tags}, **{\"author\": author}},\n",
    "        )\n",
    "        print(\"*\", end=\"\")\n",
    "    print(f\" done ({len(b_emb_results.data)})\")\n",
    "\n",
    "print(\"\\nFinished storing entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ee629-b6b9-4a77-8c58-c3b93403a6a6",
   "metadata": {},
   "source": [
    "## ユースケース1: **引用検索エンジン**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b12b3-2557-4826-af5a-16e6cd9a4531",
   "metadata": {},
   "source": [
    "quote-search機能については、まず入力されたquoteをベクトルに変換し、それを使用してストアにクエリを実行する必要があります（検索呼び出しにオプションのメタデータを処理することに加えて）。\n",
    "\n",
    "再利用しやすくするために、検索エンジンの機能を関数にカプセル化します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6fcf182-3ab7-4d28-9472-dce35cc38182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quote_and_author(query_quote, n, author=None, tags=None):\n",
    "    query_vector = client.embeddings.create(\n",
    "        input=[query_quote],\n",
    "        model=embedding_model_name,\n",
    "    ).data[0].embedding\n",
    "    metadata = {}\n",
    "    if author:\n",
    "        metadata[\"author\"] = author\n",
    "    if tags:\n",
    "        for tag in tags:\n",
    "            metadata[tag] = True\n",
    "    #\n",
    "    results = v_table.ann_search(\n",
    "        query_vector,\n",
    "        n=n,\n",
    "        metadata=metadata,\n",
    "    )\n",
    "    return [\n",
    "        (result[\"body_blob\"], result[\"metadata\"][\"author\"])\n",
    "        for result in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539262d-100b-4e8d-864d-e9c612a73e91",
   "metadata": {},
   "source": [
    "### 検索機能のテスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634165c-0882-4281-bc60-ab96261a500d",
   "metadata": {},
   "source": [
    "引用符のみを渡す場合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6722c2c0-3e54-4738-80ce-4d1149e95414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life to the great majority is only a constant struggle for mere existence, with the certainty of losing it at last.',\n",
       "  'schopenhauer'),\n",
       " ('We give up leisure in order that we may have leisure, just as we go to war in order that we may have peace.',\n",
       "  'aristotle'),\n",
       " ('Perhaps the gods are kind to us, by making life more disagreeable as we grow older. In the end death seems less intolerable than the manifold burdens we carry',\n",
       "  'freud')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50828e4c-9bb5-4489-9fe9-87da5fbe1f18",
   "metadata": {},
   "source": [
    "作成者に限定した検索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da9c705f-5c12-42b3-a038-202f89a3c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To live is to suffer, to survive is to find some meaning in the suffering.',\n",
       "  'nietzsche'),\n",
       " ('What makes us heroic?--Confronting simultaneously our supreme suffering and our supreme hope.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, author=\"nietzsche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3857ea-6dfe-489a-9b86-4e5e0534960f",
   "metadata": {},
   "source": [
    "以前に引用符で保存したタグの中から検索を制限する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abcfaec9-8f42-4789-a5ed-1073fa2932c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mankind will never see an end of trouble until lovers of wisdom come to hold political power, or the holders of power become lovers of wisdom',\n",
       "  'plato'),\n",
       " ('Everything the State says is a lie, and everything it has it has stolen.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, tags=[\"politics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fe38f-139f-44a6-a225-a63e40d3ddf5",
   "metadata": {},
   "source": [
    "### 無関係な結果の除外\n",
    "\n",
    "ベクトル類似度検索は一般的に、クエリに最も近いベクトルを返します。これは、より良い結果がない場合でも、やや無関係な結果を含む可能性があることを意味します。\n",
    "\n",
    "この問題をコントロールするために、クエリと各結果の間の実際の「距離」を取得し、それに対してカットオフを設定することで、その閾値を超える結果を効果的に除外することができます。\n",
    "この閾値を正しく調整することは簡単な問題ではありません。ここでは、その方法をお見せします。\n",
    "\n",
    "これがどのように機能するかを理解するために、以下のクエリを試して、引用文と閾値の選択を変更して結果を比較してみてください：\n",
    "\n",
    "_注記（数学的に興味のある方へ）：この「距離」は、ベクトル間のコサイン類似度、つまり2つのベクトルのノルムの積で割ったスカラー積と正確に同じです。そのため、これは-1から+1の範囲の数値で、-1は正確に反対方向を向いているベクトル、+1は同一方向を向いているベクトルを表します。他の場所（例：このデモの「CQL」対応版）では、この量を[0, 1]区間に収まるように再スケーリングしており、これは結果として得られる数値と適切な閾値がそれに応じて変換されることを意味します。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b43721-a3b0-4ac4-b730-7a6aeec52e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 quotes within the threshold:\n",
      "    0. [distance=0.855] \"The assumption that animals are without rights, and the illusion that ...\"\n",
      "    1. [distance=0.843] \"Animals are in possession of themselves; their soul is in possession o...\"\n",
      "    2. [distance=0.841] \"At his best, man is the noblest of all animals; separated from law and...\"\n"
     ]
    }
   ],
   "source": [
    "quote = \"Animals are our equals.\"\n",
    "# quote = \"Be good.\"\n",
    "# quote = \"This teapot is strange.\"\n",
    "\n",
    "metric_threshold = 0.84\n",
    "\n",
    "quote_vector = client.embeddings.create(\n",
    "    input=[quote],\n",
    "    model=embedding_model_name,\n",
    ").data[0].embedding\n",
    "\n",
    "results = list(v_table.metric_ann_search(\n",
    "    quote_vector,\n",
    "    n=8,\n",
    "    metric=\"cos\",\n",
    "    metric_threshold=metric_threshold,\n",
    "))\n",
    "\n",
    "print(f\"{len(results)} quotes within the threshold:\")\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"    {idx}. [distance={result['distance']:.3f}] \\\"{result['body_blob'][:70]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71871251-169f-4d3f-a687-65f836a9a8fe",
   "metadata": {},
   "source": [
    "## ユースケース2: **引用文ジェネレーター**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9cd63-a131-4819-bf41-c8ffa0b1e1ca",
   "metadata": {},
   "source": [
    "このタスクには、OpenAIの別のコンポーネント、つまりLLMが必要です。これは（Vector Storeへのクエリによって取得された入力に基づいて）見積もりを生成するためのものです。\n",
    "\n",
    "また、generate-quote LLM完了タスクのために入力されるプロンプト用のテンプレートも必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6dd366d-665a-45fd-917b-b6b5312b0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "generation_prompt_template = \"\"\"\"Generate a single short philosophical quote on the given topic,\n",
    "similar in spirit and form to the provided actual example quotes.\n",
    "Do not exceed 20-30 words in your quote.\n",
    "\n",
    "REFERENCE TOPIC: \"{topic}\"\n",
    "\n",
    "ACTUAL EXAMPLES:\n",
    "{examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53073a9e-16de-4e49-9e97-ff31b9b250c2",
   "metadata": {},
   "source": [
    "検索と同様に、この機能は便利な関数にラップするのが最適です（内部的に検索を使用します）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397e6ebd-b30e-413b-be63-81a62947a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(topic, n=2, author=None, tags=None):\n",
    "    quotes = find_quote_and_author(query_quote=topic, n=n, author=author, tags=tags)\n",
    "    if quotes:\n",
    "        prompt = generation_prompt_template.format(\n",
    "            topic=topic,\n",
    "            examples=\"\\n\".join(f\"  - {quote[0]}\" for quote in quotes),\n",
    "        )\n",
    "        # a little logging:\n",
    "        print(\"** quotes found:\")\n",
    "        for q, a in quotes:\n",
    "            print(f\"**    - {q} ({a})\")\n",
    "        print(\"** end of logging\")\n",
    "        #\n",
    "        response = client.chat.completions.create(\n",
    "            model=completion_model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=320,\n",
    "        )\n",
    "        return response.choices[0].message.content.replace('\"', '').strip()\n",
    "    else:\n",
    "        print(\"** no quotes found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55189828-31ad-4ca5-b375-dc80639678ab",
   "metadata": {},
   "source": [
    "_注意: 埋め込み計算の場合と同様に、Chat Completion APIのコードはv1.0以前のOpenAIでは若干異なります。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcc157-e5d4-43ef-8028-d4dcc8a72b9c",
   "metadata": {},
   "source": [
    "#### 見積もり生成をテストする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b3f38-089d-486d-b32c-e665c725faa8",
   "metadata": {},
   "source": [
    "テキストを渡すだけです（「引用」ですが、実際にはトピックを提案するだけでも構いません。そのベクトル埋め込みは、ベクトル空間内の適切な場所に配置されるためです）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "806ba758-8988-410e-9eeb-b9c6799e6b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Happiness is the reward of virtue. (aristotle)\n",
      "**    - Our moral virtues benefit mainly other people; intellectual virtues, on the other hand, benefit primarily ourselves; therefore the former make us universally popular, the latter unpopular. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "Virtuous politics purifies society, while corrupt politics breeds chaos and decay.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"politics and virtue\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca032d30-4538-4d0b-aea1-731fb32d2d4b",
   "metadata": {},
   "source": [
    "単一の哲学者からのインスピレーションを使用する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2e2d4e-865f-4b2d-80cd-a695271415d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Because Christian morality leaves animals out of account, they are at once outlawed in philosophical morals; they are mere 'things,' mere means to any ends whatsoever. They can therefore be used for vivisection, hunting, coursing, bullfights, and horse racing, and can be whipped to death as they struggle along with heavy carts of stone. Shame on such a morality that is worthy of pariahs, and that fails to recognize the eternal essence that exists in every living thing, and shines forth with inscrutable significance from all eyes that see the sun! (schopenhauer)\n",
      "**    - The assumption that animals are without rights, and the illusion that our treatment of them has no moral significance, is a positively outrageous example of Western crudity and barbarity. Universal compassion is the only guarantee of morality. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "The true measure of humanity lies not in our dominion over animals, but in our ability to show compassion and respect for all living beings.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"animals\", author=\"schopenhauer\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bc6b3-8258-4f26-96df-29deb898d55e",
   "metadata": {},
   "source": [
    "## (オプション) **パーティショニング**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7cff21-973a-4cba-8e9e-d51518275b3c",
   "metadata": {},
   "source": [
    "このクイックスタートを完了する前に、興味深いトピックを検討してみましょう。一般的に、タグと引用文は任意の関係を持つことができますが（例：引用文が複数のタグを持つ）、_著者_は実質的に正確なグループ化です（引用文の集合に対して「互いに素な分割」を定義します）：各引用文は正確に一人の著者を持ちます（少なくとも私たちにとって）。\n",
    "\n",
    "さて、あなたのアプリケーションが通常（または常に）_単一の著者_に対してクエリを実行することが事前に分かっているとします。その場合、基盤となるデータベース構造を最大限に活用できます：引用文を**パーティション**にグループ化する（著者ごとに1つ）と、特定の著者のみに対するベクトルクエリはより少ないリソースを使用し、はるかに高速に結果を返します。\n",
    "\n",
    "ここではCassandraストレージの内部に関わる詳細には踏み込みませんが、重要なメッセージは**クエリがグループ内で実行される場合、パフォーマンスを向上させるために適切にパーティション化することを検討する**ということです。\n",
    "\n",
    "この選択が実際にどのように動作するかを見てみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7eb294-85e0-4b5f-8a2f-4731361c2bd9",
   "metadata": {},
   "source": [
    "まず、CassIOとは異なるテーブル抽象化が必要です："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49cabc31-47e3-4326-8ef5-d95690317321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassio.table import ClusteredMetadataVectorCassandraTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a614c333-4143-4ad6-abdf-7b3853fbf423",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_table_partitioned = ClusteredMetadataVectorCassandraTable(table=\"philosophers_cassio_partitioned\", vector_dimension=1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bf4a8-3ce7-4542-a636-18c25d1a4426",
   "metadata": {},
   "source": [
    "新しいテーブルに対してcompute-embeddings-and-insertステップを繰り返します。\n",
    "\n",
    "先ほど見たものと比較して、重要な違いがあります。今度は引用の著者が、包括的な\"metadata\"辞書に追加される代わりに、挿入された行の_パーティションID_として保存されます。\n",
    "\n",
    "ついでに、デモンストレーションとして、特定の著者によるすべての引用を_並行して_挿入します：CassIOでは、これは各引用に対して非同期の`put_async`メソッドを使用し、結果として得られる`Future`オブジェクトのリストを収集し、その後すべてに対して`result()`メソッドを呼び出して、すべてが実行されたことを確認することで行われます。Cassandra / Astra DBは、I/O操作において高度な並行性を十分にサポートしています。\n",
    "\n",
    "_（注：以前に計算された埋め込みをキャッシュして、いくつかのAPIトークンを節約することもできましたが、ここではコードを検査しやすく保つことを優先しました。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "424513a6-0a9d-4164-bf30-22d5b7e3bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to store entries:\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "B  done (50)\n",
      "\n",
      "Finished storing entries.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "num_batches = ((len(philo_dataset) + BATCH_SIZE - 1) // BATCH_SIZE)\n",
    "\n",
    "quotes_list = philo_dataset[\"quote\"]\n",
    "authors_list = philo_dataset[\"author\"]\n",
    "tags_list = philo_dataset[\"tags\"]\n",
    "\n",
    "print(\"Starting to store entries:\")\n",
    "for batch_i in range(num_batches):\n",
    "    b_start = batch_i * BATCH_SIZE\n",
    "    b_end = (batch_i + 1) * BATCH_SIZE\n",
    "    # compute the embedding vectors for this batch\n",
    "    b_emb_results = client.embeddings.create(\n",
    "        input=quotes_list[b_start : b_end],\n",
    "        model=embedding_model_name,\n",
    "    )\n",
    "    # prepare the rows for insertion\n",
    "    futures = []\n",
    "    print(\"B \", end=\"\")\n",
    "    for entry_idx, emb_result in zip(range(b_start, b_end), b_emb_results.data):\n",
    "        if tags_list[entry_idx]:\n",
    "            tags = {\n",
    "                tag\n",
    "                for tag in tags_list[entry_idx].split(\";\")\n",
    "            }\n",
    "        else:\n",
    "            tags = set()\n",
    "        author = authors_list[entry_idx]\n",
    "        quote = quotes_list[entry_idx]\n",
    "        futures.append(v_table_partitioned.put_async(\n",
    "            partition_id=author,\n",
    "            row_id=f\"q_{author}_{entry_idx}\",\n",
    "            body_blob=quote,\n",
    "            vector=emb_result.embedding,\n",
    "            metadata={tag: True for tag in tags},\n",
    "        ))\n",
    "    #\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "    #\n",
    "    print(f\" done ({len(b_emb_results.data)})\")\n",
    "\n",
    "print(\"\\nFinished storing entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a05f57-8a54-4ccf-98a2-f391a0597855",
   "metadata": {},
   "source": [
    "この新しいテーブルでは、類似性検索も相応に変更されます（`ann_search`への引数に注意してください）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3217a90-c682-4c72-b834-7717ed13a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quote_and_author_p(query_quote, n, author=None, tags=None):\n",
    "    query_vector = client.embeddings.create(\n",
    "        input=[query_quote],\n",
    "        model=embedding_model_name,\n",
    "    ).data[0].embedding\n",
    "    metadata = {}\n",
    "    partition_id = None\n",
    "    if author:\n",
    "        partition_id = author\n",
    "    if tags:\n",
    "        for tag in tags:\n",
    "            metadata[tag] = True\n",
    "    #\n",
    "    results = v_table_partitioned.ann_search(\n",
    "        query_vector,\n",
    "        n=n,\n",
    "        partition_id=partition_id,\n",
    "        metadata=metadata,\n",
    "    )\n",
    "    return [\n",
    "        (result[\"body_blob\"], result[\"partition_id\"])\n",
    "        for result in results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7a7b3-5ad5-4d38-8125-d1bf07aaf84f",
   "metadata": {},
   "source": [
    "それで完了です：新しいテーブルは「汎用的な」類似検索を問題なくサポートしています..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7343a7a-5a06-47c5-ad96-8b60b6948352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life to the great majority is only a constant struggle for mere existence, with the certainty of losing it at last.',\n",
       "  'schopenhauer'),\n",
       " ('We give up leisure in order that we may have leisure, just as we go to war in order that we may have peace.',\n",
       "  'aristotle'),\n",
       " ('Perhaps the gods are kind to us, by making life more disagreeable as we grow older. In the end death seems less intolerable than the manifold burdens we carry',\n",
       "  'freud')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author_p(\"We struggle all our life for nothing\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7aa840-d17f-44f9-b3d4-786d361a9be0",
   "metadata": {},
   "source": [
    "... しかし、作成者が指定された場合に、_大幅な_パフォーマンスの向上に気づくでしょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1abb677-5a8b-48c2-82c5-dbca94ef56f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To live is to suffer, to survive is to find some meaning in the suffering.',\n",
       "  'nietzsche'),\n",
       " ('What makes us heroic?--Confronting simultaneously our supreme suffering and our supreme hope.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author_p(\"We struggle all our life for nothing\", 2, author=\"nietzsche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871da950-2a06-4a77-a86b-c528935da3a6",
   "metadata": {},
   "source": [
    "まあ、現実的なサイズのデータセットがあれば、パフォーマンスの向上に_気づく_でしょう。このデモでは、数十個のエントリしかないため、目立った違いはありませんが、考え方は理解できるでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08435bae-1bb9-4c14-ba21-7b4a7bdee3f5",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "おめでとうございます！OpenAIをベクトル埋め込みに使用し、Cassandra / Astra DBをCQLによるストレージに使用して、洗練された哲学的検索エンジンと引用生成器を構築する方法を学びました。\n",
    "\n",
    "この例では[CassIO](https://cassio.org)を使用してVector Storeとのインターフェースを行いましたが、これが唯一の選択肢ではありません。他のオプションや人気のフレームワークとの統合については、[README](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/cassandra_astradb)をご確認ください。\n",
    "\n",
    "Astra DBのVector Search機能がML/GenAIアプリケーションの重要な要素となる方法について詳しく知りたい場合は、このトピックに関する[Astra DB](https://docs.datastax.com/en/astra/home/astra.html)のWebページをご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8368a-9e23-49a5-8694-921728ea9656",
   "metadata": {},
   "source": [
    "## クリーンアップ\n",
    "\n",
    "このデモで使用したすべてのリソースを削除したい場合は、このセルを実行してください（_警告: これによりテーブルとその中に挿入されたデータが削除されます！_）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eb0fd16-7e15-4742-8fc5-94d9eeeda620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fdcc42e8f10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we peek at CassIO's config to get a direct handle to the DB connection\n",
    "session = cassio.config.resolve_session()\n",
    "keyspace = cassio.config.resolve_keyspace()\n",
    "\n",
    "session.execute(f\"DROP TABLE IF EXISTS {keyspace}.philosophers_cassio;\")\n",
    "session.execute(f\"DROP TABLE IF EXISTS {keyspace}.philosophers_cassio_partitioned;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
