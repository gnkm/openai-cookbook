{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46589cdf-1ab6-4028-b07c-08b75acd98e5",
   "metadata": {},
   "source": [
    "# Vector Embeddings、OpenAI、Cassandra / Astra DBを使った哲学\n",
    "\n",
    "### CQLバージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3496d07-f473-4008-9133-1a54b818c8d3",
   "metadata": {},
   "source": [
    "このクイックスタートでは、OpenAIのベクトル埋め込みと[Apache Cassandra®](https://cassandra.apache.org)、または同等にDataStax [Astra DB through CQL](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html)をベクトルストアとしてデータ永続化に使用して、「哲学の名言検索・生成器」を構築する方法を学びます。\n",
    "\n",
    "このノートブックの基本的なワークフローは以下の通りです。有名な哲学者による多数の名言のベクトル埋め込みを評価・保存し、それらを使用して強力な検索エンジンを構築し、その後、新しい名言の生成器まで作成します！\n",
    "\n",
    "このノートブックは、ベクトル検索の標準的な使用パターンのいくつかを例示しており、[Cassandra](https://cassandra.apache.org/doc/trunk/cassandra/vector-search/overview.html) / [Astra DB through CQL](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html)のベクトル機能を使い始めることがいかに簡単かを示しています。\n",
    "\n",
    "ベクトル検索とテキスト埋め込みを使用して質問応答システムを構築することの背景については、この優れたハンズオンノートブックをご確認ください：[Question answering using embeddings](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb)。\n",
    "\n",
    "#### _フレームワークの選択_\n",
    "\n",
    "このノートブックは[Cassandraドライバー](https://docs.datastax.com/en/developer/python-driver/latest/)を使用し、CQL（Cassandra Query Language）ステートメントを直接実行することにご注意ください。ただし、同じタスクを達成するための他の技術選択肢もカバーしています。他のオプションについては、このフォルダの[README](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/cassandra_astradb)をご確認ください。このノートブックはColabノートブックまたは通常のJupyterノートブックとして実行できます。\n",
    "\n",
    "目次：\n",
    "- セットアップ\n",
    "- DB接続の取得\n",
    "- OpenAIへの接続\n",
    "- ベクトルストアへの名言の読み込み\n",
    "- ユースケース1：**名言検索エンジン**\n",
    "- ユースケース2：**名言生成器**\n",
    "- （オプション）ベクトルストアでのパーティショニングの活用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf17cc-eef4-4021-b72a-4d3832a9b4a7",
   "metadata": {},
   "source": [
    "### 仕組み\n",
    "\n",
    "**インデックス化**\n",
    "\n",
    "各引用文は、OpenAIの`Embedding`を使用してエンベディングベクトルに変換されます。これらは後の検索で使用するためにVector Storeに保存されます。著者名やその他のいくつかの事前計算されたタグを含むメタデータも一緒に保存され、検索のカスタマイズを可能にします。\n",
    "\n",
    "![1_vector_indexing_cql](https://user-images.githubusercontent.com/14221764/282437237-1e763166-a863-4332-99b8-323ba23d1b87.png)\n",
    "\n",
    "**検索**\n",
    "\n",
    "提供された検索クエリに類似した引用文を見つけるために、検索クエリはその場でエンベディングベクトルに変換され、このベクトルを使用してストアから類似したベクトル、つまり以前にインデックス化された類似の引用文を検索します。検索は追加のメタデータによって制約することもできます（「これに似たスピノザの引用文を見つけて...」など）。\n",
    "\n",
    "![2_vector_search_cql](https://user-images.githubusercontent.com/14221764/282437291-85335612-a845-444e-bed7-e4cf014a9f17.png)\n",
    "\n",
    "ここでの重要なポイントは、「内容が類似した引用文」がベクトル空間では、メトリック的に互いに近いベクトルに変換されることです。つまり、ベクトル類似性検索は効果的にセマンティック類似性を実装します。_これがベクトルエンベディングが非常に強力である主要な理由です。_\n",
    "\n",
    "以下のスケッチはこのアイデアを伝えようとしています。各引用文は、ベクトルに変換されると空間内の点になります。実際には、OpenAIのエンベディングベクトルは、他の多くのベクトルと同様に_単位長_に正規化されているため、球面上の点になります。そして、この球面は実際には3次元ではなく、1536次元です！\n",
    "\n",
    "つまり、本質的にベクトル空間での類似性検索は、クエリベクトルに最も近いベクトルを返します：\n",
    "\n",
    "![3_vector_space](https://user-images.githubusercontent.com/14221764/262321363-c8c625c1-8be9-450e-8c68-b1ed518f990d.png)\n",
    "\n",
    "**生成**\n",
    "\n",
    "提案（トピックまたは仮の引用文）が与えられると、検索ステップが実行され、最初に返された結果（引用文）がLLMプロンプトに入力されます。このプロンプトは、渡された例_および_初期提案に沿って新しいテキストを発明するよう生成モデルに求めます。\n",
    "\n",
    "![4_quote_generation](https://user-images.githubusercontent.com/14221764/282437321-881bd273-3443-4987-9a11-350d3288dd8e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10493f44-565d-4f23-8bfd-1a7335392c2b",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a14f95-4683-4d0c-a251-0df7b43ca975",
   "metadata": {},
   "source": [
    "必要な依存関係をインストールしてインポートします："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39afdb74-56e4-44ff-9c72-ab2669780113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet \"cassandra-driver>=0.28.0\" \"openai>=1.0.0\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5d1a8f-9175-417a-aa21-06fe2ad2998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from getpass import getpass\n",
    "from collections import Counter\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "import openai\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a38ab-3cb1-4dd1-9426-a100c33a86c2",
   "metadata": {},
   "source": [
    "_次のセルはあまり気にしないでください。Colabsを検出し、SCBファイルのアップロードを可能にするために必要です（下記参照）：_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26263ac3-4e73-42c1-a028-a8ee6cb3425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    IS_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb99e33-5cb7-416f-8dca-da18e0cb108d",
   "metadata": {},
   "source": [
    "## DB接続を取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8edc1-4633-491b-9ed3-11163ec24e46",
   "metadata": {},
   "source": [
    "`Session`オブジェクト（Astra DBインスタンスへの接続）を作成するには、いくつかのシークレットが必要です。\n",
    "\n",
    "_（注意：Google ColabとローカルのJupyterでは一部の手順が若干異なるため、ノートブックはランタイムタイプを検出します。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7615e522-574f-427e-9f7f-87fc721207a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the full path to your Secure Connect Bundle zipfile:  /path/to/secure-connect-DatabaseName.zip\n",
      "Please provide your Database Token ('AstraCS:...' string):  ········\n",
      "Please provide the Keyspace name for your Database:  my_keyspace\n"
     ]
    }
   ],
   "source": [
    "# Your database's Secure Connect Bundle zip file is needed:\n",
    "if IS_COLAB:\n",
    "    print('Please upload your Secure Connect Bundle zipfile: ')\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        astraBundleFileTitle = list(uploaded.keys())[0]\n",
    "        ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
    "        )\n",
    "else:\n",
    "    # you are running a local-jupyter notebook:\n",
    "    ASTRA_DB_SECURE_BUNDLE_PATH = input(\"Please provide the full path to your Secure Connect Bundle zipfile: \")\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = getpass(\"Please provide your Database Token ('AstraCS:...' string): \")\n",
    "ASTRA_DB_KEYSPACE = input(\"Please provide the Keyspace name for your Database: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4e5ec-2ab2-4d41-b3ec-c946469fed8b",
   "metadata": {},
   "source": [
    "### DB接続の作成\n",
    "\n",
    "Astra DBへの接続を作成する方法は以下の通りです：\n",
    "\n",
    "_（ちなみに、以下の`Cluster`インスタンス化の[パラメータを変更する](https://docs.datastax.com/en/developer/python-driver/latest/getting_started/#connecting-to-cassandra)ことで、任意のCassandraクラスター（ベクター機能を提供する限り）も使用できます。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949ab020-90c8-499b-a139-f69f07af50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't mind the \"Closing connection\" error after \"downgrading protocol...\" messages you may see,\n",
    "# it is really just a warning: the connection will work smoothly.\n",
    "cluster = Cluster(\n",
    "    cloud={\n",
    "        \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
    "    },\n",
    "    auth_provider=PlainTextAuthProvider(\n",
    "        \"token\",\n",
    "        ASTRA_DB_APPLICATION_TOKEN,\n",
    "    ),\n",
    ")\n",
    "\n",
    "session = cluster.connect()\n",
    "keyspace = ASTRA_DB_KEYSPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60829851-bd48-4461-9243-974f76304933",
   "metadata": {},
   "source": [
    "### CQLでのベクターテーブルの作成\n",
    "\n",
    "ベクターをサポートし、メタデータを備えたテーブルが必要です。これを「philosophers_cql」と呼びます。\n",
    "\n",
    "各行には以下が格納されます：引用文、そのベクター埋め込み、引用文の著者、および「タグ」のセット。また、行の一意性を保証するための主キーも必要です。\n",
    "\n",
    "以下は、テーブルを作成する完全なCQLコマンドです（このステートメントおよび以下のステートメントのCQL構文の詳細については、[このページ](https://docs.datastax.com/en/dse/6.7/cql/cql/cqlQuickReference.html)を参照してください）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db837dc-cd49-41e2-8b5d-edb17ccc470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_statement = f\"\"\"CREATE TABLE IF NOT EXISTS {keyspace}.philosophers_cql (\n",
    "    quote_id UUID PRIMARY KEY,\n",
    "    body TEXT,\n",
    "    embedding_vector VECTOR<FLOAT, 1536>,\n",
    "    author TEXT,\n",
    "    tags SET<TEXT>\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1beab1-bbbe-4714-b817-c3ee3db34d91",
   "metadata": {},
   "source": [
    "このステートメントをデータベースSessionに渡して実行してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a83507-1ebc-420e-8845-bef55f2b7c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7feee37b3460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(create_table_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1be40d-bb6f-46d1-b39a-ac51ce11a466",
   "metadata": {},
   "source": [
    "#### ANN検索のためのベクトルインデックスを追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761df5b-3d92-47e5-889b-8626d3c80b0a",
   "metadata": {},
   "source": [
    "テーブル内のベクトルに対してANN（近似最近傍）検索を実行するには、`embedding_vector`列に特定のインデックスを作成する必要があります。\n",
    "\n",
    "_インデックスを作成する際、ベクトル距離を計算するために使用される「類似度関数」を[オプションで選択](https://docs.datastax.com/en/astra-serverless/docs/vector-search/cql.html#_create_the_vector_schema_and_load_the_data_into_the_database)できます。単位長ベクトル（OpenAIのベクトルなど）の場合、「コサイン差」は「ドット積」と同じであるため、計算コストが低い後者を使用します。_\n",
    "\n",
    "次のCQLステートメントを実行してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd61e12-a7a3-4c99-9ba3-f8d8641ff32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7feeefd3da00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_vector_index_statement = f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS idx_embedding_vector\n",
    "    ON {keyspace}.philosophers_cql (embedding_vector)\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{'similarity_function' : 'dot_product'}};\n",
    "\"\"\"\n",
    "# Note: the double '{{' and '}}' are just the F-string escape sequence for '{' and '}'\n",
    "\n",
    "session.execute(create_vector_index_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d9946-6ada-48ff-99f7-c91a730e841c",
   "metadata": {},
   "source": [
    "#### 著者とタグフィルタリング用のインデックスを追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f7e8a-193e-45ad-90dc-2764ad8e16a1",
   "metadata": {},
   "source": [
    "テーブル上でベクトル検索を実行するには十分ですが... 引用検索を制限するために、オプションで著者や一部のタグを指定できるようにしたいと思います。これをサポートするために、他に2つのインデックスを作成してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691f1a07-cab4-42a1-baba-f17b561ddd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fef2c64af70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_author_index_statement = f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS idx_author\n",
    "    ON {keyspace}.philosophers_cql (author)\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
    "\"\"\"\n",
    "session.execute(create_author_index_statement)\n",
    "\n",
    "create_tags_index_statement = f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS idx_tags\n",
    "    ON {keyspace}.philosophers_cql (VALUES(tags))\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
    "\"\"\"\n",
    "session.execute(create_tags_index_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86f91a-88a6-4997-b0f8-9da0816f8ece",
   "metadata": {},
   "source": [
    "## OpenAIに接続する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b664b5-fd84-492e-a7bd-4dda3863b48a",
   "metadata": {},
   "source": [
    "### シークレットキーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fe7653-dd64-4494-83e1-5702ec41725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass(\"Please enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f2821-7f3f-4dcd-8e0c-49aa397e36f4",
   "metadata": {},
   "source": [
    "### 埋め込みのテストコール\n",
    "\n",
    "入力テキストのリストに対して埋め込みベクトルを取得する方法を簡単に確認してみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf89454-9a55-4202-ab6b-ea15b2048f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "embedding_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "result = client.embeddings.create(\n",
    "    input=[\n",
    "        \"This is a sentence\",\n",
    "        \"A second sentence\"\n",
    "    ],\n",
    "    model=embedding_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33dc452-3449-4035-aea1-f5a64034b493",
   "metadata": {},
   "source": [
    "_注意: 上記はOpenAI v1.0+の構文です。以前のバージョンを使用している場合、埋め込みを取得するコードは異なって見えます。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a8e6f0-0aa7-4ffc-94e9-702b68566815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(result.data)              = 2\n",
      "result.data[1].embedding      = [-0.0108176339417696, 0.0013546717818826437, 0.00362232...\n",
      "len(result.data[1].embedding) = 1536\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(result.data)              = {len(result.data)}\")\n",
    "print(f\"result.data[1].embedding      = {str(result.data[1].embedding)[:55]}...\")\n",
    "print(f\"len(result.data[1].embedding) = {len(result.data[1].embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f09c42-fff3-4aa2-922b-043739b4b06a",
   "metadata": {},
   "source": [
    "## ベクターストアに引用文を読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f3d58-74c2-458b-903d-3d12e61b7846",
   "metadata": {},
   "source": [
    "データセットから引用文を取得します。_（このデモで使用できるよう、[このKaggleデータセット](https://www.kaggle.com/datasets/mertbozkurt5/quotes-by-philosophers)のデータを適応・拡張しました。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ff33fb-4b52-4c15-ab74-4af4fe973cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b08b1-e3db-4c7c-9d7c-2ada7c8bc71d",
   "metadata": {},
   "source": [
    "簡単な検査："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe11475-9fdd-4775-93b2-4267e73f372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example entry:\n",
      "{'author': 'aristotle', 'quote': 'Love well, be loved and do something of value.', 'tags': 'love;ethics'}\n"
     ]
    }
   ],
   "source": [
    "print(\"An example entry:\")\n",
    "print(philo_dataset[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4db57-cb5d-418d-b4c9-d27be28bae79",
   "metadata": {},
   "source": [
    "データセットのサイズを確認してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b522e05-87b4-461c-a61f-6dfb7ad2ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 450 quotes. By author:\n",
      "    aristotle           : 50 quotes\n",
      "    schopenhauer        : 50 quotes\n",
      "    spinoza             : 50 quotes\n",
      "    hegel               : 50 quotes\n",
      "    freud               : 50 quotes\n",
      "    nietzsche           : 50 quotes\n",
      "    sartre              : 50 quotes\n",
      "    plato               : 50 quotes\n",
      "    kant                : 50 quotes\n"
     ]
    }
   ],
   "source": [
    "author_count = Counter(entry[\"author\"] for entry in philo_dataset)\n",
    "print(f\"Total: {len(philo_dataset)} quotes. By author:\")\n",
    "for author, count in author_count.most_common():\n",
    "    print(f\"    {author:<20}: {count} quotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15745dc8-e7c1-4781-933b-41eef6ddd657",
   "metadata": {},
   "source": [
    "### ベクターストアへの引用文の挿入\n",
    "\n",
    "引用文の埋め込みを計算し、テキスト自体と後で使用予定のメタデータと一緒にベクターストアに保存します。\n",
    "\n",
    "速度を最適化し、呼び出し回数を削減するために、OpenAIの埋め込みサービスへのバッチ呼び出しを実行します。\n",
    "\n",
    "DBへの書き込みはCQLステートメントで実行されます。しかし、この特定の挿入を何度も実行する（ただし異なる値で）ため、ステートメントを_準備_してから繰り返し実行するのが最適です。\n",
    "\n",
    "_（注：より高速な挿入のために、Cassandraドライバーは並行挿入を可能にしますが、よりわかりやすいデモコードのためにここでは使用していません。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e80e81-886b-45a4-be61-c33b8028bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to store entries:\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ******************** done (20)\n",
      "B ********** done (10)\n",
      "\n",
      "Finished storing entries.\n"
     ]
    }
   ],
   "source": [
    "prepared_insertion = session.prepare(\n",
    "    f\"INSERT INTO {keyspace}.philosophers_cql (quote_id, author, body, embedding_vector, tags) VALUES (?, ?, ?, ?, ?);\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "num_batches = ((len(philo_dataset) + BATCH_SIZE - 1) // BATCH_SIZE)\n",
    "\n",
    "quotes_list = philo_dataset[\"quote\"]\n",
    "authors_list = philo_dataset[\"author\"]\n",
    "tags_list = philo_dataset[\"tags\"]\n",
    "\n",
    "print(\"Starting to store entries:\")\n",
    "for batch_i in range(num_batches):\n",
    "    b_start = batch_i * BATCH_SIZE\n",
    "    b_end = (batch_i + 1) * BATCH_SIZE\n",
    "    # compute the embedding vectors for this batch\n",
    "    b_emb_results = client.embeddings.create(\n",
    "        input=quotes_list[b_start : b_end],\n",
    "        model=embedding_model_name,\n",
    "    )\n",
    "    # prepare the rows for insertion\n",
    "    print(\"B \", end=\"\")\n",
    "    for entry_idx, emb_result in zip(range(b_start, b_end), b_emb_results.data):\n",
    "        if tags_list[entry_idx]:\n",
    "            tags = {\n",
    "                tag\n",
    "                for tag in tags_list[entry_idx].split(\";\")\n",
    "            }\n",
    "        else:\n",
    "            tags = set()\n",
    "        author = authors_list[entry_idx]\n",
    "        quote = quotes_list[entry_idx]\n",
    "        quote_id = uuid4()  # a new random ID for each quote. In a production app you'll want to have better control...\n",
    "        session.execute(\n",
    "            prepared_insertion,\n",
    "            (quote_id, author, quote, emb_result.embedding, tags),\n",
    "        )\n",
    "        print(\"*\", end=\"\")\n",
    "    print(f\" done ({len(b_emb_results.data)})\")\n",
    "\n",
    "print(\"\\nFinished storing entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ee629-b6b9-4a77-8c58-c3b93403a6a6",
   "metadata": {},
   "source": [
    "## ユースケース1: **引用検索エンジン**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b12b3-2557-4826-af5a-16e6cd9a4531",
   "metadata": {},
   "source": [
    "quote-search機能については、まず入力されたquoteをベクトルに変換し、それを使用してストアにクエリを実行する必要があります（検索呼び出しにオプションのメタデータを処理することに加えて）。\n",
    "\n",
    "再利用しやすくするために、検索エンジンの機能を関数にカプセル化します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6fcf182-3ab7-4d28-9472-dce35cc38182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quote_and_author(query_quote, n, author=None, tags=None):\n",
    "    query_vector = client.embeddings.create(\n",
    "        input=[query_quote],\n",
    "        model=embedding_model_name,\n",
    "    ).data[0].embedding\n",
    "    # depending on what conditions are passed, the WHERE clause in the statement may vary.\n",
    "    where_clauses = []\n",
    "    where_values = []\n",
    "    if author:\n",
    "        where_clauses += [\"author = %s\"]\n",
    "        where_values += [author]\n",
    "    if tags:\n",
    "        for tag in tags:\n",
    "            where_clauses += [\"tags CONTAINS %s\"]\n",
    "            where_values += [tag]\n",
    "    # The reason for these two lists above is that when running the CQL search statement the values passed\n",
    "    # must match the sequence of \"?\" marks in the statement.\n",
    "    if where_clauses:\n",
    "        search_statement = f\"\"\"SELECT body, author FROM {keyspace}.philosophers_cql\n",
    "            WHERE {' AND '.join(where_clauses)}\n",
    "            ORDER BY embedding_vector ANN OF %s\n",
    "            LIMIT %s;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        search_statement = f\"\"\"SELECT body, author FROM {keyspace}.philosophers_cql\n",
    "            ORDER BY embedding_vector ANN OF %s\n",
    "            LIMIT %s;\n",
    "        \"\"\"\n",
    "    # For best performance, one should keep a cache of prepared statements (see the insertion code above)\n",
    "    # for the various possible statements used here.\n",
    "    # (We'll leave it as an exercise to the reader to avoid making this code too long.\n",
    "    # Remember: to prepare a statement you use '?' instead of '%s'.)\n",
    "    query_values = tuple(where_values + [query_vector] + [n])\n",
    "    result_rows = session.execute(search_statement, query_values)\n",
    "    return [\n",
    "        (result_row.body, result_row.author)\n",
    "        for result_row in result_rows\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539262d-100b-4e8d-864d-e9c612a73e91",
   "metadata": {},
   "source": [
    "### 検索をテストする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3634165c-0882-4281-bc60-ab96261a500d",
   "metadata": {},
   "source": [
    "引用のみを渡す場合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6722c2c0-3e54-4738-80ce-4d1149e95414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life to the great majority is only a constant struggle for mere existence, with the certainty of losing it at last.',\n",
       "  'schopenhauer'),\n",
       " ('We give up leisure in order that we may have leisure, just as we go to war in order that we may have peace.',\n",
       "  'aristotle'),\n",
       " ('Perhaps the gods are kind to us, by making life more disagreeable as we grow older. In the end death seems less intolerable than the manifold burdens we carry',\n",
       "  'freud')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50828e4c-9bb5-4489-9fe9-87da5fbe1f18",
   "metadata": {},
   "source": [
    "作成者に制限された検索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9c705f-5c12-42b3-a038-202f89a3c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To live is to suffer, to survive is to find some meaning in the suffering.',\n",
       "  'nietzsche'),\n",
       " ('What makes us heroic?--Confronting simultaneously our supreme suffering and our supreme hope.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, author=\"nietzsche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3857ea-6dfe-489a-9b86-4e5e0534960f",
   "metadata": {},
   "source": [
    "以前に引用符で保存したタグのうち、特定のタグに検索を制限する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abcfaec9-8f42-4789-a5ed-1073fa2932c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mankind will never see an end of trouble until lovers of wisdom come to hold political power, or the holders of power become lovers of wisdom',\n",
       "  'plato'),\n",
       " ('Everything the State says is a lie, and everything it has it has stolen.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author(\"We struggle all our life for nothing\", 2, tags=[\"politics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fe38f-139f-44a6-a225-a63e40d3ddf5",
   "metadata": {},
   "source": [
    "### 無関係な結果の除外\n",
    "\n",
    "ベクトル類似性検索は一般的に、クエリに最も近いベクトルを返します。これは、より良い結果がない場合でも、やや無関係な結果を含む可能性があることを意味します。\n",
    "\n",
    "この問題を制御するために、クエリと各結果の間の実際の「類似性」を取得し、それに対してカットオフを設定することで、その閾値を超える結果を効果的に破棄することができます。\n",
    "この閾値を正しく調整することは簡単な問題ではありません。ここでは、その方法をお見せします。\n",
    "\n",
    "これがどのように動作するかを理解するために、以下のクエリを試して、引用文と閾値の選択を変更して結果を比較してみてください：\n",
    "\n",
    "_注記（数学的に興味のある方へ）：この値は、ベクトル間のコサイン差、つまり2つのベクトルのノルムの積で割ったスカラー積の**0と1の間での再スケーリング**です。言い換えると、これは反対方向のベクトルでは0、平行なベクトルでは+1になります。他の類似性の測定方法については、[ドキュメント](https://docs.datastax.com/en/astra-serverless/docs/vector-search/cql.html#_create_the_vector_schema_and_load_the_data_into_the_database)を確認してください。また、`SELECT`クエリの指標は、意味のある順序付けられた結果を得るために、先ほどインデックスを作成する際に使用したものと一致する必要があることを覚えておいてください。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b43721-a3b0-4ac4-b730-7a6aeec52e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 quotes within the threshold:\n",
      "    0. [similarity=0.927] \"The assumption that animals are without rights, and the illusion that ...\"\n",
      "    1. [similarity=0.922] \"Animals are in possession of themselves; their soul is in possession o...\"\n",
      "    2. [similarity=0.920] \"At his best, man is the noblest of all animals; separated from law and...\"\n"
     ]
    }
   ],
   "source": [
    "quote = \"Animals are our equals.\"\n",
    "# quote = \"Be good.\"\n",
    "# quote = \"This teapot is strange.\"\n",
    "\n",
    "similarity_threshold = 0.92\n",
    "\n",
    "quote_vector = client.embeddings.create(\n",
    "    input=[quote],\n",
    "    model=embedding_model_name,\n",
    ").data[0].embedding\n",
    "\n",
    "# Once more: remember to prepare your statements in production for greater performance...\n",
    "\n",
    "search_statement = f\"\"\"SELECT body, similarity_dot_product(embedding_vector, %s) as similarity\n",
    "    FROM {keyspace}.philosophers_cql\n",
    "    ORDER BY embedding_vector ANN OF %s\n",
    "    LIMIT %s;\n",
    "\"\"\"\n",
    "query_values = (quote_vector, quote_vector, 8)\n",
    "\n",
    "result_rows = session.execute(search_statement, query_values)\n",
    "results = [\n",
    "    (result_row.body, result_row.similarity)\n",
    "    for result_row in result_rows\n",
    "    if result_row.similarity >= similarity_threshold\n",
    "]\n",
    "\n",
    "print(f\"{len(results)} quotes within the threshold:\")\n",
    "for idx, (r_body, r_similarity) in enumerate(results):\n",
    "    print(f\"    {idx}. [similarity={r_similarity:.3f}] \\\"{r_body[:70]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71871251-169f-4d3f-a687-65f836a9a8fe",
   "metadata": {},
   "source": [
    "## ユースケース2: **名言ジェネレーター**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9cd63-a131-4819-bf41-c8ffa0b1e1ca",
   "metadata": {},
   "source": [
    "このタスクには、OpenAIの別のコンポーネント、つまり（Vector Storeへのクエリによって取得した入力に基づいて）見積もりを生成するLLMが必要です。\n",
    "\n",
    "また、generate-quote LLM完了タスクのために入力されるプロンプトのテンプレートも必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6dd366d-665a-45fd-917b-b6b5312b0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_model_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "generation_prompt_template = \"\"\"\"Generate a single short philosophical quote on the given topic,\n",
    "similar in spirit and form to the provided actual example quotes.\n",
    "Do not exceed 20-30 words in your quote.\n",
    "\n",
    "REFERENCE TOPIC: \"{topic}\"\n",
    "\n",
    "ACTUAL EXAMPLES:\n",
    "{examples}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53073a9e-16de-4e49-9e97-ff31b9b250c2",
   "metadata": {},
   "source": [
    "検索と同様に、この機能は便利な関数にラップするのが最適です（内部的に検索を使用します）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397e6ebd-b30e-413b-be63-81a62947a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quote(topic, n=2, author=None, tags=None):\n",
    "    quotes = find_quote_and_author(query_quote=topic, n=n, author=author, tags=tags)\n",
    "    if quotes:\n",
    "        prompt = generation_prompt_template.format(\n",
    "            topic=topic,\n",
    "            examples=\"\\n\".join(f\"  - {quote[0]}\" for quote in quotes),\n",
    "        )\n",
    "        # a little logging:\n",
    "        print(\"** quotes found:\")\n",
    "        for q, a in quotes:\n",
    "            print(f\"**    - {q} ({a})\")\n",
    "        print(\"** end of logging\")\n",
    "        #\n",
    "        response = client.chat.completions.create(\n",
    "            model=completion_model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=320,\n",
    "        )\n",
    "        return response.choices[0].message.content.replace('\"', '').strip()\n",
    "    else:\n",
    "        print(\"** no quotes found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e20f-3e98-47d4-9963-2fbb3d2594de",
   "metadata": {},
   "source": [
    "_注意：埋め込み計算の場合と同様に、Chat Completion APIのコードは、OpenAI v1.0以前では若干異なります。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcc157-e5d4-43ef-8028-d4dcc8a72b9c",
   "metadata": {},
   "source": [
    "#### 見積もり生成のテスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b3f38-089d-486d-b32c-e665c725faa8",
   "metadata": {},
   "source": [
    "テキストを渡すだけです（「引用」ですが、実際にはトピックを提案するだけでも構いません。そのベクトル埋め込みは、ベクトル空間内の適切な場所に配置されるためです）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "806ba758-8988-410e-9eeb-b9c6799e6b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Happiness is the reward of virtue. (aristotle)\n",
      "**    - Our moral virtues benefit mainly other people; intellectual virtues, on the other hand, benefit primarily ourselves; therefore the former make us universally popular, the latter unpopular. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "True politics is not the pursuit of power, but the cultivation of virtue for the betterment of all.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"politics and virtue\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca032d30-4538-4d0b-aea1-731fb32d2d4b",
   "metadata": {},
   "source": [
    "単一の哲学者からインスピレーションを得る："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c2e2d4e-865f-4b2d-80cd-a695271415d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** quotes found:\n",
      "**    - Because Christian morality leaves animals out of account, they are at once outlawed in philosophical morals; they are mere 'things,' mere means to any ends whatsoever. They can therefore be used for vivisection, hunting, coursing, bullfights, and horse racing, and can be whipped to death as they struggle along with heavy carts of stone. Shame on such a morality that is worthy of pariahs, and that fails to recognize the eternal essence that exists in every living thing, and shines forth with inscrutable significance from all eyes that see the sun! (schopenhauer)\n",
      "**    - The assumption that animals are without rights, and the illusion that our treatment of them has no moral significance, is a positively outrageous example of Western crudity and barbarity. Universal compassion is the only guarantee of morality. (schopenhauer)\n",
      "** end of logging\n",
      "\n",
      "A new generated quote:\n",
      "Do not judge the worth of a soul by its outward form, for within every animal lies an eternal essence that deserves our compassion and respect.\n"
     ]
    }
   ],
   "source": [
    "q_topic = generate_quote(\"animals\", author=\"schopenhauer\")\n",
    "print(\"\\nA new generated quote:\")\n",
    "print(q_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86bc6b3-8258-4f26-96df-29deb898d55e",
   "metadata": {},
   "source": [
    "## （オプション）**パーティショニング**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7cff21-973a-4cba-8e9e-d51518275b3c",
   "metadata": {},
   "source": [
    "このクイックスタートを完了する前に、興味深いトピックを検討してみましょう。一般的に、タグと引用文は任意の関係を持つことができますが（例：引用文が複数のタグを持つ）、_著者_は実質的に正確なグループ化を行います（引用文の集合に対して「互いに素な分割」を定義します）：各引用文は正確に一人の著者を持ちます（少なくとも私たちにとって）。\n",
    "\n",
    "さて、あなたのアプリケーションが通常（または常に）_単一の著者_に対してクエリを実行することを事前に知っているとします。その場合、基盤となるデータベース構造を最大限に活用できます：引用文を**パーティション**にグループ化する（著者ごとに1つ）と、特定の著者のみに対するベクトルクエリはより少ないリソースを使用し、はるかに高速に結果を返します。\n",
    "\n",
    "ここではCassandraストレージの内部に関わる詳細には踏み込みませんが、重要なメッセージは**クエリがグループ内で実行される場合、パフォーマンスを向上させるために適切にパーティション分割することを検討する**ということです。\n",
    "\n",
    "これから、この選択が実際にどのように動作するかを見ていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7eb294-85e0-4b5f-8a2f-4731361c2bd9",
   "metadata": {},
   "source": [
    "著者ごとのパーティショニングには新しいテーブルスキーマが必要です。「philosophers_cql_partitioned」という新しいテーブルを必要なインデックスと共に作成してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d849003c-fce8-4bd9-96ee-d826bb4301eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fef149d7940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_p_statement = f\"\"\"CREATE TABLE IF NOT EXISTS {keyspace}.philosophers_cql_partitioned (\n",
    "    author TEXT,\n",
    "    quote_id UUID,\n",
    "    body TEXT,\n",
    "    embedding_vector VECTOR<FLOAT, 1536>,\n",
    "    tags SET<TEXT>,\n",
    "    PRIMARY KEY ( (author), quote_id )\n",
    ") WITH CLUSTERING ORDER BY (quote_id ASC);\"\"\"\n",
    "\n",
    "session.execute(create_table_p_statement)\n",
    "\n",
    "create_vector_index_p_statement = f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS idx_embedding_vector_p\n",
    "    ON {keyspace}.philosophers_cql_partitioned (embedding_vector)\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\n",
    "    WITH OPTIONS = {{'similarity_function' : 'dot_product'}};\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_vector_index_p_statement)\n",
    "\n",
    "create_tags_index_p_statement = f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS idx_tags_p\n",
    "    ON {keyspace}.philosophers_cql_partitioned (VALUES(tags))\n",
    "    USING 'org.apache.cassandra.index.sai.StorageAttachedIndex';\n",
    "\"\"\"\n",
    "session.execute(create_tags_index_p_statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bf4a8-3ce7-4542-a636-18c25d1a4426",
   "metadata": {},
   "source": [
    "新しいテーブルに対してcompute-embeddings-and-insertステップを繰り返します。\n",
    "\n",
    "先ほどと全く同じ挿入コードを使用することもできます。なぜなら、違いは「舞台裏」に隠されているからです：データベースは、この新しいテーブルのパーティショニングスキームに従って、挿入された行を異なる方法で保存します。\n",
    "\n",
    "ただし、デモンストレーションとして、Cassandraドライバーが提供する便利な機能を活用して、複数のクエリ（この場合は`INSERT`）を簡単に並行実行します。これは、Cassandra / Astra DBがCQLを通じて非常によくサポートしている機能で、クライアントコードにほとんど変更を加えることなく、大幅な高速化につながる可能性があります。\n",
    "\n",
    "_（注：さらに、以前に計算した埋め込みをキャッシュしてAPIトークンを節約することもできましたが、ここではコードを検査しやすくするためにそうしませんでした。）_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1576d4a9-4369-43dd-b17b-76940b92ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.concurrent import execute_concurrent_with_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c63b18c0-a866-4ac1-b2a1-37863b6db663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to store entries:\n",
      "[...50] [...50] [...50] [...50] [...50] [...50] [...50] [...50] [...50] \n",
      "Finished storing entries.\n"
     ]
    }
   ],
   "source": [
    "prepared_insertion = session.prepare(\n",
    "    f\"INSERT INTO {keyspace}.philosophers_cql_partitioned (quote_id, author, body, embedding_vector, tags) VALUES (?, ?, ?, ?, ?);\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "num_batches = ((len(philo_dataset) + BATCH_SIZE - 1) // BATCH_SIZE)\n",
    "\n",
    "quotes_list = philo_dataset[\"quote\"]\n",
    "authors_list = philo_dataset[\"author\"]\n",
    "tags_list = philo_dataset[\"tags\"]\n",
    "\n",
    "print(\"Starting to store entries:\")\n",
    "for batch_i in range(num_batches):\n",
    "    print(\"[...\", end=\"\")\n",
    "    b_start = batch_i * BATCH_SIZE\n",
    "    b_end = (batch_i + 1) * BATCH_SIZE\n",
    "    # compute the embedding vectors for this batch\n",
    "    b_emb_results = client.embeddings.create(\n",
    "        input=quotes_list[b_start : b_end],\n",
    "        model=embedding_model_name,\n",
    "    )\n",
    "    # prepare this batch's entries for insertion\n",
    "    tuples_to_insert = []\n",
    "    for entry_idx, emb_result in zip(range(b_start, b_end), b_emb_results.data):\n",
    "        if tags_list[entry_idx]:\n",
    "            tags = {\n",
    "                tag\n",
    "                for tag in tags_list[entry_idx].split(\";\")\n",
    "            }\n",
    "        else:\n",
    "            tags = set()\n",
    "        author = authors_list[entry_idx]\n",
    "        quote = quotes_list[entry_idx]\n",
    "        quote_id = uuid4()  # a new random ID for each quote. In a production app you'll want to have better control...\n",
    "        # append a *tuple* to the list, and in the tuple the values are ordered to match \"?\" in the prepared statement:\n",
    "        tuples_to_insert.append((quote_id, author, quote, emb_result.embedding, tags))\n",
    "    # insert the batch at once through the driver's concurrent primitive\n",
    "    conc_results = execute_concurrent_with_args(\n",
    "        session,\n",
    "        prepared_insertion,\n",
    "        tuples_to_insert,\n",
    "    )\n",
    "    # check that all insertions succeed (better to always do this):\n",
    "    if any([not success for success, _ in conc_results]):\n",
    "        print(\"Something failed during the insertions!\")\n",
    "    else:\n",
    "        print(f\"{len(b_emb_results.data)}] \", end=\"\")\n",
    "\n",
    "print(\"\\nFinished storing entries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a05f57-8a54-4ccf-98a2-f391a0597855",
   "metadata": {},
   "source": [
    "異なるテーブルスキーマにもかかわらず、類似検索の背後にあるDBクエリは本質的に同じです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3217a90-c682-4c72-b834-7717ed13a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quote_and_author_p(query_quote, n, author=None, tags=None):\n",
    "    query_vector = client.embeddings.create(\n",
    "        input=[query_quote],\n",
    "        model=embedding_model_name,\n",
    "    ).data[0].embedding\n",
    "    # Depending on what conditions are passed, the WHERE clause in the statement may vary.\n",
    "    # Construct it accordingly:\n",
    "    where_clauses = []\n",
    "    where_values = []\n",
    "    if author:\n",
    "        where_clauses += [\"author = %s\"]\n",
    "        where_values += [author]\n",
    "    if tags:\n",
    "        for tag in tags:\n",
    "            where_clauses += [\"tags CONTAINS %s\"]\n",
    "            where_values += [tag]\n",
    "    if where_clauses:\n",
    "        search_statement = f\"\"\"SELECT body, author FROM {keyspace}.philosophers_cql_partitioned\n",
    "            WHERE {' AND '.join(where_clauses)}\n",
    "            ORDER BY embedding_vector ANN OF %s\n",
    "            LIMIT %s;\n",
    "        \"\"\"\n",
    "    else:\n",
    "        search_statement = f\"\"\"SELECT body, author FROM {keyspace}.philosophers_cql_partitioned\n",
    "            ORDER BY embedding_vector ANN OF %s\n",
    "            LIMIT %s;\n",
    "        \"\"\"\n",
    "    query_values = tuple(where_values + [query_vector] + [n])\n",
    "    result_rows = session.execute(search_statement, query_values)\n",
    "    return [\n",
    "        (result_row.body, result_row.author)\n",
    "        for result_row in result_rows\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7a7b3-5ad5-4d38-8125-d1bf07aaf84f",
   "metadata": {},
   "source": [
    "それで完了です：新しいテーブルは「汎用的な」類似性検索を問題なくサポートしています..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7343a7a-5a06-47c5-ad96-8b60b6948352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Life to the great majority is only a constant struggle for mere existence, with the certainty of losing it at last.',\n",
       "  'schopenhauer'),\n",
       " ('We give up leisure in order that we may have leisure, just as we go to war in order that we may have peace.',\n",
       "  'aristotle'),\n",
       " ('Perhaps the gods are kind to us, by making life more disagreeable as we grow older. In the end death seems less intolerable than the manifold burdens we carry',\n",
       "  'freud')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author_p(\"We struggle all our life for nothing\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7aa840-d17f-44f9-b3d4-786d361a9be0",
   "metadata": {},
   "source": [
    "... しかし、作成者が指定された場合に、_大幅な_パフォーマンス向上に気づくでしょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1abb677-5a8b-48c2-82c5-dbca94ef56f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To live is to suffer, to survive is to find some meaning in the suffering.',\n",
       "  'nietzsche'),\n",
       " ('What makes us heroic?--Confronting simultaneously our supreme suffering and our supreme hope.',\n",
       "  'nietzsche')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_quote_and_author_p(\"We struggle all our life for nothing\", 2, author=\"nietzsche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871da950-2a06-4a77-a86b-c528935da3a6",
   "metadata": {},
   "source": [
    "まあ、現実的なサイズのデータセットがあれば、パフォーマンスの向上に_気づく_でしょう。このデモでは、数十個のエントリしかないため、目立った違いはありませんが、考え方は理解できるでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08435bae-1bb9-4c14-ba21-7b4a7bdee3f5",
   "metadata": {},
   "source": [
    "## 結論\n",
    "\n",
    "おめでとうございます！ベクトル埋め込みにOpenAIを使用し、ストレージにAstra DB / Cassandraを使用して、洗練された哲学的検索エンジンと引用生成器を構築する方法を学習しました。\n",
    "\n",
    "この例では[Cassandraドライバー](https://docs.datastax.com/en/developer/python-driver/latest/)を使用し、CQL（Cassandra Query Language）ステートメントを直接実行してVector Storeとのインターフェースを行いましたが、これが唯一の選択肢ではありません。他のオプションや人気のフレームワークとの統合については、[README](https://github.com/openai/openai-cookbook/tree/main/examples/vector_databases/cassandra_astradb)をご確認ください。\n",
    "\n",
    "Astra DBのVector Search機能がML/GenAIアプリケーションの重要な要素となる方法について詳しく知りたい場合は、このトピックに関する[Astra DB](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html)のWebページをご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7309d1-158c-4425-8f50-30918f4aee43",
   "metadata": {},
   "source": [
    "## クリーンアップ\n",
    "\n",
    "このデモで使用したすべてのリソースを削除したい場合は、このセルを実行してください（_警告: これによりテーブルとその中に挿入されたデータが削除されます！_）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f2dd55-82df-4c3f-8aef-4ae0a03e7b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7fef149096a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(f\"DROP TABLE IF EXISTS {keyspace}.philosophers_cql;\")\n",
    "session.execute(f\"DROP TABLE IF EXISTS {keyspace}.philosophers_cql_partitioned;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
