{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZillizとOpenAIを使ったフィルタ検索\n",
    "### あなたの次の映画を見つける\n",
    "\n",
    "このノートブックでは、OpenAIを使って映画の説明文の埋め込みを生成し、それらの埋め込みをZilliz内で使用して関連する映画を見つける方法について説明します。検索結果を絞り込み、新しいことを試すために、メタデータ検索を行うフィルタリングを使用します。この例で使用するデータセットはHuggingFace datasetsから取得したもので、8千を少し超える映画エントリが含まれています。\n",
    "\n",
    "まず、このノートブックに必要なライブラリをダウンロードすることから始めましょう：\n",
    "- `openai`はOpenAI埋め込みサービスとの通信に使用されます\n",
    "- `pymilvus`はZillizサーバーとの通信に使用されます\n",
    "- `datasets`はデータセットのダウンロードに使用されます\n",
    "- `tqdm`はプログレスバーに使用されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai pymilvus datasets tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zillizを起動して実行するには、[こちら](https://zilliz.com/doc/quick_start)をご覧ください。アカウントとデータベースの設定が完了したら、以下の値を設定してください：\n",
    "- URI: データベースが実行されているURI\n",
    "- USER: データベースのユーザー名\n",
    "- PASSWORD: データベースのパスワード\n",
    "- COLLECTION_NAME: Zilliz内でコレクションに付ける名前\n",
    "- DIMENSION: 埋め込みの次元数\n",
    "- OPENAI_ENGINE: 使用する埋め込みモデル\n",
    "- openai.api_key: OpenAIアカウントキー\n",
    "- INDEX_PARAM: コレクションに使用するインデックス設定\n",
    "- QUERY_PARAM: 使用する検索パラメータ\n",
    "- BATCH_SIZE: 一度に埋め込みと挿入を行うテキストの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "URI = 'your_uri'\n",
    "TOKEN = 'your_token' # TOKEN == user:password or api_key\n",
    "COLLECTION_NAME = 'book_search'\n",
    "DIMENSION = 1536\n",
    "OPENAI_ENGINE = 'text-embedding-3-small'\n",
    "openai.api_key = 'sk-your_key'\n",
    "\n",
    "INDEX_PARAM = {\n",
    "    'metric_type':'L2',\n",
    "    'index_type':\"AUTOINDEX\",\n",
    "    'params':{}\n",
    "}\n",
    "\n",
    "QUERY_PARAM = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {},\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "\n",
    "# Connect to Zilliz Database\n",
    "connections.connect(uri=URI, token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove collection if it already exists\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection which includes the id, title, and embedding.\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='type', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='release_year', dtype=DataType.INT64),\n",
    "    FieldSchema(name='rating', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='description', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields)\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index on the collection and load it.\n",
    "collection.create_index(field_name=\"embedding\", index_params=INDEX_PARAM)\n",
    "collection.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット\n",
    "Zillizが稼働している状態で、データの取得を開始できます。`Hugging Face Datasets`は多くの異なるユーザーデータセットを保持するハブであり、この例ではHuggingLearnersのnetflix-showsデータセットを使用しています。このデータセットには8千以上の映画とそのメタデータのペアが含まれています。各説明文を埋め込み、タイトル、タイプ、リリース年、評価と共にZilliz内に保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filiphaltmayer/miniconda3/envs/haystack/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset csv (/Users/filiphaltmayer/.cache/huggingface/datasets/hugginglearners___csv/hugginglearners--netflix-shows-03475319fc65a05a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Download the dataset \n",
    "dataset = datasets.load_dataset('hugginglearners/netflix-shows', split='train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの挿入\n",
    "データがマシン上に準備できたので、埋め込み処理を行ってZillizに挿入を開始できます。埋め込み関数はテキストを受け取り、リスト形式で埋め込みを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that converts the texts to embeddings\n",
    "def embed(texts):\n",
    "    embeddings = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        engine=OPENAI_ENGINE\n",
    "    )\n",
    "    return [x['embedding'] for x in embeddings['data']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のステップでは実際の挿入を行います。すべてのエントリを反復処理し、設定されたバッチサイズに達したらバッチを作成して挿入します。ループが終了した後、残りの最後のバッチが存在する場合はそれを挿入します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8807/8807 [00:54<00:00, 162.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = [\n",
    "    [], # title\n",
    "    [], # type\n",
    "    [], # release_year\n",
    "    [], # rating\n",
    "    [], # description\n",
    "]\n",
    "\n",
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, len(dataset))):\n",
    "    data[0].append(dataset[i]['title'] or '')\n",
    "    data[1].append(dataset[i]['type'] or '')\n",
    "    data[2].append(dataset[i]['release_year'] or -1)\n",
    "    data[3].append(dataset[i]['rating'] or '')\n",
    "    data[4].append(dataset[i]['description'] or '')\n",
    "    if len(data[0]) % BATCH_SIZE == 0:\n",
    "        data.append(embed(data[4]))\n",
    "        collection.insert(data)\n",
    "        data = [[],[],[],[],[]]\n",
    "\n",
    "# Embed and insert the remainder \n",
    "if len(data[0]) != 0:\n",
    "    data.append(embed(data[4]))\n",
    "    collection.insert(data)\n",
    "    data = [[],[],[],[],[]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データベースのクエリ\n",
    "データがZillizに安全に挿入されたので、クエリを実行できるようになりました。クエリは、検索したい映画の説明と使用するフィルターのタプルを受け取ります。フィルターの詳細については[こちら](https://milvus.io/docs/boolean.md)をご覧ください。検索では、まず説明とフィルター式が出力されます。その後、各結果について、結果の映画のスコア、タイトル、タイプ、公開年、評価、説明が出力されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: movie about a fluffly animal Expression: release_year < 2019 and rating like \"PG%\"\n",
      "Results:\n",
      "\tRank: 1 Score: 0.30085673928260803 Title: The Lamb\n",
      "\t\tType: Movie Release Year: 2017 Rating: PG\n",
      "A big-dreaming donkey escapes his menial existence and befriends some free-spirited\n",
      "animal pals in this imaginative retelling of the Nativity Story.\n",
      "\n",
      "\tRank: 2 Score: 0.3352621793746948 Title: Puss in Boots\n",
      "\t\tType: Movie Release Year: 2011 Rating: PG\n",
      "The fabled feline heads to the Land of Giants with friends Humpty Dumpty and Kitty\n",
      "Softpaws on a quest to nab its greatest treasure: the Golden Goose.\n",
      "\n",
      "\tRank: 3 Score: 0.3415083587169647 Title: Show Dogs\n",
      "\t\tType: Movie Release Year: 2018 Rating: PG\n",
      "A rough and tough police dog must go undercover with an FBI agent as a prim and proper\n",
      "pet at a dog show to save a baby panda from an illegal sale.\n",
      "\n",
      "\tRank: 4 Score: 0.3428957462310791 Title: Open Season 2\n",
      "\t\tType: Movie Release Year: 2008 Rating: PG\n",
      "Elliot the buck and his forest-dwelling cohorts must rescue their dachshund pal from\n",
      "some spoiled pets bent on returning him to domesticity.\n",
      "\n",
      "\tRank: 5 Score: 0.34376364946365356 Title: Stuart Little 2\n",
      "\t\tType: Movie Release Year: 2002 Rating: PG\n",
      "Zany misadventures are in store as lovable city mouse Stuart and his human brother,\n",
      "George, raise the roof in this sequel to the 1999 blockbuster.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def query(query, top_k = 5):\n",
    "    text, expr = query\n",
    "    res = collection.search(embed(text), anns_field='embedding', expr = expr, param=QUERY_PARAM, limit = top_k, output_fields=['title', 'type', 'release_year', 'rating', 'description'])\n",
    "    for i, hit in enumerate(res):\n",
    "        print('Description:', text, 'Expression:', expr)\n",
    "        print('Results:')\n",
    "        for ii, hits in enumerate(hit):\n",
    "            print('\\t' + 'Rank:', ii + 1, 'Score:', hits.score, 'Title:', hits.entity.get('title'))\n",
    "            print('\\t\\t' + 'Type:', hits.entity.get('type'), 'Release Year:', hits.entity.get('release_year'), 'Rating:', hits.entity.get('rating'))\n",
    "            print(textwrap.fill(hits.entity.get('description'), 88))\n",
    "            print()\n",
    "\n",
    "my_query = ('movie about a fluffly animal', 'release_year < 2019 and rating like \\\"PG%\\\"')\n",
    "\n",
    "query(my_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
