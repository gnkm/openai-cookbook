{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI埋め込みのベクターデータベースとしてPolarDB-PGを使用する\n",
    "\n",
    "このノートブックでは、OpenAI埋め込みのベクターデータベースとしてPolarDB-PGを使用する方法を段階的にガイドします。\n",
    "\n",
    "このノートブックでは、以下のエンドツーエンドのプロセスを紹介します：\n",
    "1. OpenAI APIによって作成された事前計算済み埋め込みの使用\n",
    "2. PolarDB-PGのクラウドインスタンスへの埋め込みの保存\n",
    "3. OpenAI APIを使用した生テキストクエリの埋め込みへの変換\n",
    "4. PolarDB-PGを使用した作成されたコレクションでの最近傍検索の実行\n",
    "\n",
    "### PolarDB-PGとは\n",
    "\n",
    "[PolarDB-PG](https://www.alibabacloud.com/help/en/polardb/latest/what-is-polardb-2)は、読み書き分離アーキテクチャを採用した高性能ベクターデータベースです。Alibaba Cloudによって管理されるクラウドネイティブデータベースで、PostgreSQLと100%互換性があり、Oracle構文との高い互換性を持っています。大規模なベクターデータの保存とクエリの処理をサポートし、基盤となる実行アルゴリズムの最適化によってベクター計算の効率を大幅に向上させ、ユーザーに高速、弾力的、高性能、大容量ストレージ、安全で信頼性の高いベクターデータベースサービスを提供します。さらに、PolarDB-PGは多次元・マルチモーダル時空間情報エンジンと地理情報エンジンもサポートしています。同時に、PolarDB-PGは完全なOLAP機能とサービスレベル契約を備えており、多くのユーザーに認められ使用されています。\n",
    "\n",
    "### デプロイメントオプション\n",
    "\n",
    "- [PolarDB-PGクラウドベクターデータベース](https://www.alibabacloud.com/product/polardb-for-postgresql)を使用。[こちらをクリック](https://www.alibabacloud.com/product/polardb-for-postgresql?spm=a3c0i.147400.6791778070.243.9f204881g5cjpP)して高速デプロイメント。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "この演習を行うために、いくつかの準備が必要です：\n",
    "\n",
    "1. PolarDB-PGクラウドサーバーインスタンス\n",
    "2. ベクトルデータベースとやり取りするための'psycopg2'ライブラリ。他のPostgreSQLクライアントライブラリでも構いません。\n",
    "3. [OpenAI APIキー](https://beta.openai.com/account/api-keys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サーバーが正常に起動したかどうかを確認するために、簡単な curl コマンドを実行して検証することができます："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なパッケージのインストール\n",
    "\n",
    "このノートブックは明らかに`openai`と`psycopg2`パッケージが必要ですが、使用する他の追加ライブラリもいくつかあります。以下のコマンドですべてをインストールできます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai psycopg2 pandas wget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI APIキーを準備する\n",
    "OpenAI APIキーは、ドキュメントとクエリのベクトル化に使用されます。\n",
    "\n",
    "OpenAI APIキーをお持ちでない場合は、https://beta.openai.com/account/api-keys から取得できます。\n",
    "\n",
    "キーを取得したら、環境変数として`OPENAI_API_KEY`に追加してください。\n",
    "\n",
    "環境変数を通じてAPIキーを設定することについて疑問がある場合は、[APIキー安全性のベストプラクティス](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Test that your OpenAI API key is correctly set as an environment variable\n",
    "# Note. if you run this notebook locally, you will need to reload your terminal and the notebook for the env variables to be live.\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolarDBに接続する\n",
    "まず環境変数に追加してください。または、以下の\"psycopg2.connect\"パラメータを直接変更することもできます。\n",
    "\n",
    "実行中のPolarDBサーバーインスタンスへの接続は、公式のPythonライブラリを使用すると簡単です："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Note. alternatively you can set a temporary env variable like this:\n",
    "# os.environ[\"PGHOST\"] = \"your_host\"\n",
    "# os.environ[\"PGPORT\"] \"5432\"),\n",
    "# os.environ[\"PGDATABASE\"] \"postgres\"),\n",
    "# os.environ[\"PGUSER\"] \"user\"),\n",
    "# os.environ[\"PGPASSWORD\"] \"password\"),\n",
    "\n",
    "connection = psycopg2.connect(\n",
    "    host=os.environ.get(\"PGHOST\", \"localhost\"),\n",
    "    port=os.environ.get(\"PGPORT\", \"5432\"),\n",
    "    database=os.environ.get(\"PGDATABASE\", \"postgres\"),\n",
    "    user=os.environ.get(\"PGUSER\", \"user\"),\n",
    "    password=os.environ.get(\"PGPASSWORD\", \"password\")\n",
    ")\n",
    "\n",
    "# Create a new cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用可能な任意のメソッドを実行して接続をテストできます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Execute a simple query to test the connection\n",
    "cursor.execute(\"SELECT 1;\")\n",
    "result = cursor.fetchone()\n",
    "\n",
    "# Check the query result\n",
    "if result == (1,):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_database_wikipedia_articles_embedded.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "embeddings_url = \"https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip\"\n",
    "\n",
    "# The file is ~700 MB so this will take some time\n",
    "wget.download(embeddings_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたファイルを展開する必要があります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file vector_database_wikipedia_articles_embedded.csv exists in the data directory.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "zip_file_path = os.path.join(current_directory, \"vector_database_wikipedia_articles_embedded.zip\")\n",
    "output_directory = os.path.join(current_directory, \"../../data\")\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_directory)\n",
    "\n",
    "\n",
    "# check the csv file exist\n",
    "file_name = \"vector_database_wikipedia_articles_embedded.csv\"\n",
    "data_directory = os.path.join(current_directory, \"../../data\")\n",
    "file_path = os.path.join(data_directory, file_name)\n",
    "\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file {file_name} exists in the data directory.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist in the data directory.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インデックスデータ\n",
    "\n",
    "PolarDBは__relation__にデータを格納し、各オブジェクトは少なくとも1つのベクトルで記述されます。私たちのrelationは**articles**と呼ばれ、各オブジェクトは**title**と**content**の両方のベクトルで記述されます。\n",
    "\n",
    "まず、relationを作成し、**title**と**content**の両方にベクトルインデックスを作成してから、事前に計算された埋め込みでそれを埋めていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = '''\n",
    "CREATE TABLE IF NOT EXISTS public.articles (\n",
    "    id INTEGER NOT NULL,\n",
    "    url TEXT,\n",
    "    title TEXT,\n",
    "    content TEXT,\n",
    "    title_vector vector(1536),\n",
    "    content_vector vector(1536),\n",
    "    vector_id INTEGER\n",
    ");\n",
    "\n",
    "ALTER TABLE public.articles ADD PRIMARY KEY (id);\n",
    "'''\n",
    "\n",
    "# SQL statement for creating indexes\n",
    "create_indexes_sql = '''\n",
    "CREATE INDEX ON public.articles USING ivfflat (content_vector) WITH (lists = 1000);\n",
    "\n",
    "CREATE INDEX ON public.articles USING ivfflat (title_vector) WITH (lists = 1000);\n",
    "'''\n",
    "\n",
    "# Execute the SQL statements\n",
    "cursor.execute(create_table_sql)\n",
    "cursor.execute(create_indexes_sql)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み\n",
    "\n",
    "このセクションでは、このセッションの前に準備されたデータを読み込みます。これにより、あなた自身のクレジットを使ってWikipedia記事の埋め込みを再計算する必要がありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Path to your local CSV file\n",
    "csv_file_path = '../../data/vector_database_wikipedia_articles_embedded.csv'\n",
    "\n",
    "# Define a generator function to process the file line by line\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield line\n",
    "\n",
    "# Create a StringIO object to store the modified lines\n",
    "modified_lines = io.StringIO(''.join(list(process_file(csv_file_path))))\n",
    "\n",
    "# Create the COPY command for the copy_expert method\n",
    "copy_command = '''\n",
    "COPY public.articles (id, url, title, content, title_vector, content_vector, vector_id)\n",
    "FROM STDIN WITH (FORMAT CSV, HEADER true, DELIMITER ',');\n",
    "'''\n",
    "\n",
    "# Execute the COPY command using the copy_expert method\n",
    "cursor.copy_expert(copy_command, modified_lines)\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:25000\n"
     ]
    }
   ],
   "source": [
    "# Check the collection size to make sure all the points have been stored\n",
    "count_sql = \"\"\"select count(*) from public.articles;\"\"\"\n",
    "cursor.execute(count_sql)\n",
    "result = cursor.fetchone()\n",
    "print(f\"Count:{result[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの検索\n",
    "\n",
    "データがQdrantに格納されたら、最も近いベクトルを求めてコレクションにクエリを開始します。タイトルベースの検索からコンテンツベースの検索に切り替えるために、追加パラメータ`vector_name`を提供することができます。事前計算された埋め込みは`text-embedding-3-small` OpenAIモデルで作成されたため、検索時にも同じモデルを使用する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_polardb(query, collection_name, vector_name=\"title_vector\", top_k=20):\n",
    "\n",
    "    # Creates embedding vector from user query\n",
    "    embedded_query = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-3-small\",\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # Convert the embedded_query to PostgreSQL compatible format\n",
    "    embedded_query_pg = \"[\" + \",\".join(map(str, embedded_query)) + \"]\"\n",
    "\n",
    "    # Create SQL query\n",
    "    query_sql = f\"\"\"\n",
    "    SELECT id, url, title, l2_distance({vector_name},'{embedded_query_pg}'::VECTOR(1536)) AS similarity\n",
    "    FROM {collection_name}\n",
    "    ORDER BY {vector_name} <-> '{embedded_query_pg}'::VECTOR(1536)\n",
    "    LIMIT {top_k};\n",
    "    \"\"\"\n",
    "    # Execute the query\n",
    "    cursor.execute(query_sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Museum of Modern Art (Score: 0.5)\n",
      "2. Western Europe (Score: 0.485)\n",
      "3. Renaissance art (Score: 0.479)\n",
      "4. Pop art (Score: 0.472)\n",
      "5. Northern Europe (Score: 0.461)\n",
      "6. Hellenistic art (Score: 0.457)\n",
      "7. Modernist literature (Score: 0.447)\n",
      "8. Art film (Score: 0.44)\n",
      "9. Central Europe (Score: 0.439)\n",
      "10. European (Score: 0.437)\n",
      "11. Art (Score: 0.437)\n",
      "12. Byzantine art (Score: 0.436)\n",
      "13. Postmodernism (Score: 0.434)\n",
      "14. Eastern Europe (Score: 0.433)\n",
      "15. Europe (Score: 0.433)\n",
      "16. Cubism (Score: 0.432)\n",
      "17. Impressionism (Score: 0.432)\n",
      "18. Bauhaus (Score: 0.431)\n",
      "19. Surrealism (Score: 0.429)\n",
      "20. Expressionism (Score: 0.429)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "query_results = query_polardb(\"modern art in Europe\", \"Articles\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Battle of Bannockburn (Score: 0.489)\n",
      "2. Wars of Scottish Independence (Score: 0.474)\n",
      "3. 1651 (Score: 0.457)\n",
      "4. First War of Scottish Independence (Score: 0.452)\n",
      "5. Robert I of Scotland (Score: 0.445)\n",
      "6. 841 (Score: 0.441)\n",
      "7. 1716 (Score: 0.441)\n",
      "8. 1314 (Score: 0.429)\n",
      "9. 1263 (Score: 0.428)\n",
      "10. William Wallace (Score: 0.426)\n",
      "11. Stirling (Score: 0.419)\n",
      "12. 1306 (Score: 0.419)\n",
      "13. 1746 (Score: 0.418)\n",
      "14. 1040s (Score: 0.414)\n",
      "15. 1106 (Score: 0.412)\n",
      "16. 1304 (Score: 0.411)\n",
      "17. David II of Scotland (Score: 0.408)\n",
      "18. Braveheart (Score: 0.407)\n",
      "19. 1124 (Score: 0.406)\n",
      "20. July 27 (Score: 0.405)\n"
     ]
    }
   ],
   "source": [
    "# This time we'll query using content vector\n",
    "query_results = query_polardb(\"Famous battles in Scottish history\", \"Articles\", \"content_vector\")\n",
    "for i, result in enumerate(query_results):\n",
    "    print(f\"{i + 1}. {result[2]} (Score: {round(1 - result[3], 3)})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
