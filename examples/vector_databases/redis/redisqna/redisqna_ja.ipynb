{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redis を OpenAI Chat のコンテキストストアとして使用する\n",
    "このノートブックでは、Redis を ChatGPT の高速コンテキストメモリとして使用する方法を説明します。\n",
    "\n",
    "## 前提条件\n",
    "* Redis Search と Redis JSON モジュールを含む Redis インスタンス\n",
    "* Redis-py クライアントライブラリ\n",
    "* OpenAI Python クライアントライブラリ\n",
    "* OpenAI API キー\n",
    "\n",
    "## インストール\n",
    "サンプルに必要な Python モジュールをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -q redis openai python-dotenv 'openai[datalib]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API キー\n",
    ".envファイルを作成し、OpenAI キーを追加してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=your_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI セットアップ\n",
    "キーの読み込み + チャット補完のヘルパー関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "oai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験 - モデルの知識カットオフ日以降のトピックに関するチャット補完\n",
    "Gpt-3.5-turboは2021年9月までのデータで訓練されました。その日付以降の出来事について質問してみましょう。この場合、FTX/Sam Bankman-Friedスキャンダルについてです。ここではデモンストレーションのために古いモデルを使用しています。gpt-4oなどの新しいモデルは、より新しい知識カットオフ（2023年後半）を持っており、ここでも機能するでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, FTX is generally considered a well-managed company. Sam Bankman-Fried, the founder and CEO of FTX, has a strong track record in the cryptocurrency industry and has successfully grown the company into one of the leading cryptocurrency exchanges in the world. FTX has also received positive reviews for its user-friendly platform, innovative products, and strong customer service. Additionally, FTX has been proactive in regulatory compliance and has taken steps to ensure the security of its users' funds. Overall, FTX is seen as a well-managed company in the cryptocurrency space.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Is Sam Bankman-Fried's company, FTX, considered a well-managed company?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不完全な情報\n",
    "これらのAIシステムの残念な動作として、システムが結果に確信を持てない場合でも、自信に満ちた響きの回答を提供してしまうことがあります。これを軽減する一つの方法は、以下に示すようなプロンプトの再設計です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTX is generally considered a well-managed company. Sam Bankman-Fried, the founder and CEO, has a strong reputation in the cryptocurrency industry for his leadership and strategic vision. FTX has also experienced significant growth and success since its founding in 2017. However, without specific insider knowledge or data, it is ultimately unknown whether FTX is definitively considered a well-managed company.\n"
     ]
    }
   ],
   "source": [
    "prompt =\"Is Sam Bankman-Fried's company, FTX, considered a well-managed company?  If you don't know for certain, say unknown.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加のコンテキスト\n",
    "不完全な情報に対処するもう一つの方法は、システムが推測ではなく知的な判断を下せるよう、より多くの情報を提供することです。この追加のコンテキストのソースとしてRedisを使用します。GPTの知識カットオフ日以降のビジネスニュース記事を取り込むことで、システムがFTXが実際にどのように運営されていたかをより良く理解できるようにします。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redis Stack Docker コンテナを開始する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redisクライアントの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redis import from_url\n",
    "\n",
    "REDIS_URL = 'redis://localhost:6379'\n",
    "client = from_url(REDIS_URL)\n",
    "client.ping()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インデックスの作成\n",
    "[FT.CREATE](https://redis.io/commands/ft.create/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'OK'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redis.commands.search.field import TextField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "\n",
    "schema = [ VectorField('$.vector', \n",
    "            \"FLAT\", \n",
    "            {   \"TYPE\": 'FLOAT32', \n",
    "                \"DIM\": 1536, \n",
    "                \"DISTANCE_METRIC\": \"COSINE\"\n",
    "            },  as_name='vector' ),\n",
    "            TextField('$.content', as_name='content')\n",
    "        ]\n",
    "idx_def = IndexDefinition(index_type=IndexType.JSON, prefix=['doc:'])\n",
    "try: \n",
    "    client.ft('idx').dropindex()\n",
    "except:\n",
    "    pass\n",
    "client.ft('idx').create_index(schema, definition=idx_def)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データファイルをテキストフィールドとベクターフィールドを持つJSONオブジェクトとしてRedisに読み込む\n",
    "[Redis JSON](https://redis.io/docs/stack/json/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './assets/'\n",
    "model = 'text-embedding-3-small'\n",
    "i = 1\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    with open(os.path.join(directory, file), 'r') as f:\n",
    "        content = f.read()\n",
    "        # Create the embedding using the new client-based method\n",
    "        response = oai_client.embeddings.create(\n",
    "            model=model,\n",
    "            input=[content]\n",
    "        )\n",
    "        # Access the embedding from the response object\n",
    "        vector = response.data[0].embedding\n",
    "        \n",
    "        # Store the content and vector using your JSON client\n",
    "        client.json().set(f'doc:{i}', '$', {'content': content, 'vector': vector})\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 質問を埋め込み、VSSを実行して最も関連性の高いドキュメントを見つける\n",
    "[KNN Search](https://redis.io/docs/stack/search/reference/vectors/#knn-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis.commands.search.query import Query\n",
    "import numpy as np\n",
    "\n",
    "response = oai_client.embeddings.create(\n",
    "    input=[prompt],\n",
    "    model=model\n",
    ")\n",
    "# Extract the embedding vector from the response\n",
    "embedding_vector = response.data[0].embedding\n",
    "\n",
    "# Convert the embedding to a numpy array of type float32 and then to bytes\n",
    "vec = np.array(embedding_vector, dtype=np.float32).tobytes()\n",
    "\n",
    "# Build and execute the Redis query\n",
    "q = Query('*=>[KNN 1 @vector $query_vec AS vector_score]') \\\n",
    "    .sort_by('vector_score') \\\n",
    "    .return_fields('content') \\\n",
    "    .dialect(2)\n",
    "params = {\"query_vec\": vec}\n",
    "\n",
    "context = client.ft('idx').search(q, query_params=params).docs[0].content\n",
    "print(context)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンテキストを含めてOpenAIに質問を繰り返す\n",
    "関連するコンテキストが得られたので、それをOpenAIへのプロンプトに追加して、大きく異なる応答を得ましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, FTX, Sam Bankman-Fried's company, is not considered a well-managed company. The company has faced bankruptcy proceedings, mishandling of customer funds, unauthorized transactions, freezing of assets by regulatory authorities, and a lack of trustworthy financial information. The new CEO, John J. Ray III, described the situation as a \"complete failure of corporate controls\" and indicated gross mismanagement. Additionally, the company's financial situation, lack of record-keeping, and use of inadequate accounting tools despite handling billions of dollars have raised serious concerns about its management practices.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Using the information delimited by triple backticks, answer this question: Is Sam Bankman-Fried's company, FTX, considered a well-managed company?\n",
    "\n",
    "Context: ```{context}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
