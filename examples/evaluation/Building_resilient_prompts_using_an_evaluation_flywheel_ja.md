## 概要

### このクックブックの目的

このクックブックは、OpenAI Platformを使用してプロンプトに簡単に回復力を組み込む方法についての実用的なガイドを提供します。

> **回復力のあるプロンプト**とは、可能な入力の全範囲にわたって高品質な応答を提供するプロンプトです。

プロンプトの回復力は、本番環境でAIアプリケーションを展開する際の重要な要素です。この特性がなければ、プロンプトはエッジケースで予期しない結果を生み出し、通常のケースでも劣った応答を提供し、AIアプリケーションの効果を損なう可能性があります。

プロンプトに回復力を組み込むために、私たちは**評価フライホイール**プロセスを推奨します。これは、開発者が時間をかけて測定可能な方法でAIアプリケーションを継続的に改善できる手法です。

### 対象読者

このクックブックは、プロンプトの一般的な一貫性と品質を向上させたい、またはAIアプリケーションの特定のエッジケースに対処したい専門家、ソリューションアーキテクト、データサイエンティスト、AIエンジニア向けに設計されています。

## 評価フライホイール

AIアプリケーションはしばしば脆弱に感じられます。ある日うまく機能していたプロンプトが、翌日には予期しない低品質な結果を生み出すことがあります。これは、プロンプトがユーザー入力やコンテキストの小さな変化に敏感である可能性があるためです。信頼性の高いAI製品を構築するには、プロンプトをより回復力のあるものにする体系的な方法が必要です。

解決策は、**評価フライホイール**と呼ばれる継続的で反復的なプロセスです。プロンプトを改善する可能性のあることを推測する（「プロンプト・アンド・プレイ」）代わりに、このライフサイクルは問題を診断、測定、解決するための構造化されたエンジニアリング規律を提供します。

フライホイールは3つのフェーズで構成されます：

1. **分析**：
   定性的なレビューを通じて、システムがどのように、なぜ失敗するかを理解します。モデルが正しく動作しない例を手動で検査し、注釈を付けて、繰り返し発生する失敗モードを特定します。

2. **測定**：
   特定された失敗モードを定量化し、ベースラインを設定します。測定できないものは改善できません。テストデータセットを作成し、システムのパフォーマンスを大規模に採点する自動評価器（「グレーダー」）を構築します。

3. **改善**：
   プロンプトの書き直し、より良い例の追加、システムコンポーネントの調整などの的を絞った改善を行います。測定が整っていれば、変更の影響を即座に確認し、失敗率が許容可能な低さになるまで反復できます。

これは継続的なサイクルです。システムを改善すると、新しい、より微妙な失敗モードが現れ、フライホイールが再び始まります。このプロセスは、堅牢で信頼性の高いAIアプリケーションを構築するための中核的な手法です。

![Evaluation flywheel](/images/evaluation-flywheel.png)
> **出典:** Shankar, S., & Husain, H. (2025). *Application-Centric AI Evals for Engineers and Technical Product Managers*. AI Evals Course Reader.

## 例

評価プロセスを説明するために、本番環境の**アパート賃貸アシスタント**のデータを使用しましょう。

これは、以下のような見込み借主からの質問に答えます：

* "アパートの広さはどのくらいですか？"
* "いつ見学に来ることができますか？"

アプリケーション内で分析したい特定のプロンプトがあるとします。OpenAI Platformでプロンプトを追加し、入力と出力データをデータセットにアップロードすることから始められます（これを行う方法の詳細については[ドキュメント](https://platform.openai.com/docs/guides/evaluations-getting-started)をご覧ください）。

![Leasing agent data](/images/dataset.png)

プロンプトとトレースが読み込まれたので、プロンプトの効果を分析する準備が整いました。

## プロンプトの効果の分析

システムを改善するには、まずそれがどのように失敗するかを理解する必要があります。自動化されたメトリクスは進捗を追跡するのに有用ですが、失敗が*なぜ*発生したかを明らかにすることはできません。モデル出力の手動分析は、問題を診断し、的を絞った改善のための洞察を得る最も効果的な方法です。

この分析の中核は**注釈**です。これは、失敗モードを分類し理解するために、テキストに構造化されたラベルを適用することです。これにより、構造化されていない失敗が改善のための実行可能なロードマップに変わります。私たちは、質的研究から引き出された2段階の方法を推奨します：オープンコーディングと軸コーディングです。

### 1. オープンコーディング：失敗モードの発見

最初のステップは、失敗したトレースのサンプル（約50から始めることを推奨）を読み通し、見つけた各エラーに記述的なラベルを適用することです。この段階では、完璧で構造化された分類法を作成することを心配する必要はありません。目標は発見です。

OpenAI Platformでは、注釈列を使用してデータセットをオープンコーディングできます。ここでは、結果を捉えるために`open_coding`というタイトルの**Feedback**タイプの注釈列を追加します。

![Creating a feedback column](/images/creating-feedback-column.png)

アパート賃貸アシスタントの場合、初期のオープンコードは次のようになるかもしれません：

* "ボットが利用できない見学時間を提案した"
* "アメニティのリストが単一のテキストブロックだった"
* "再スケジュール時に元の予約をキャンセルできなかった"
* "間取り図へのリンクが壊れていた"

これらの具体的で、データに基づいたラベルが、次のステップの原材料となります。

![Open coding](/images/open-coding.png)

これがオープンコーディング後のデータセットです。

### 2. 軸コーディング：洞察の構造化

オープンコードのセットができたら、次のステップはそれらをより高レベルのカテゴリにグループ化することです。これが軸コーディングです。初期ラベル間の関係を特定して、中核的な問題の構造化された理解を構築するプロセスです。

オープンコードを事前定義された軸コードにグループ化できます：

* **見学スケジュール/再スケジュールの問題：**
  * ボットが利用できない見学時間を提案した
  * 再スケジュール時に元の予約をキャンセルできなかった
* **出力のフォーマットエラー：**
  * アメニティのリストが単一のテキストブロックだった
  * 間取り図へのリンクが壊れていた

これを捉えるために、データセットに`axial_coding`というタイトルの新しい**Label**タイプの注釈列を追加します。

![Axial coding](/images/axial-coding.png)

このシンプルな分類法により、システムの主要な弱点の明確で定量的な全体像が得られます。失敗の35%が見学スケジュールに関連し、フォーマットエラーは10%のみであることがわかるかもしれません。これにより、改善努力をどこに集中すべきかが正確にわかります。エラー分析の実施方法の詳細については、[このウォークスルー](https://youtu.be/qH1dZ8JLLdU?si=Sxczt-LpKVVnMEdG)をご覧ください。

## 自動グレーダーによる堅牢性の追加

分類法とデータセットを手に入れたので、評価フライホイールの自動化を開始する準備が整いました。OpenAI Platformは[さまざまなグレーダータイプ](https://platform.openai.com/docs/guides/graders)（PythonグレーダーやLLMグレーダーを含む）をサポートしており、データセットで一括実行できます（詳細は[こちら](https://platform.openai.com/docs/guides/evaluation-getting-started#adding-graders)）。この例では、以下のLLMグレーダーを構築して実行できます：

* **フォーマットグレーダー：** モデルの応答が望ましい形式と一致するかを評価
* **利用可能性精度グレーダー：** モデルが返す利用可能性を、データセットで指定した正解値と比較

フォーマットグレーダーは非常に直接的な指示です。
![Creating formatting grader](/images/creating-formatting-grader.png)

利用可能性精度グレーダーは、営業時間と日の利用可能性を捉えるためにデータセットに追加した追加の入力列を参照します。
![Creating availability grader](/images/creating-availability-grader.png)
![Ground truth columns](/images/ground-truth-columns.png)

自動グレーダーが整備されれば、システムへの任意の変更（更新されたプロンプト、更新されたモデルパラメータ、新しく発見されたエッジケース）に対するパフォーマンスを簡単に評価できます。

グレーダーを正しく設定する方法の詳細については、以下の「LLMジャッジの調整」セクションをご覧ください。

## プロンプトの最適化

エラーを特定・分類し、フライホイールを自動化するためのグレーディングを構築しました。この段階で、データを使用してプロンプトへの手動変更を行うことを選択できます。しかし、OpenAI Platformは、このプロセスを高速化する自動[プロンプト最適化ツール](https://platform.openai.com/docs/guides/prompt-optimizer)をサポートしています。

プロンプトオプティマイザーは、生成された出力、カスタム注釈列、グレーダーを考慮して、改善されたプロンプトを構築します。ここではかなり小さな例を構築しましたが、本格的なデータセット（例えば、先ほど推奨した50行）があれば、オプティマイザーは特定されたエラーの多くを解決する新しいプロンプトを生成します。

新しいモデル出力に再注釈を付け、グレーダーを追加または改良し、再最適化することで、さらに反復したくなるかもしれません。グレーダーと注釈列の仕様はタブ間で保持されるため、作業中に新しいタブで追加のプロンプトバージョンを作成し続けることができます。タブでは異なるモデル間のパフォーマンスを比較することもでき、グレーダーを使用してどのモデルパラメータ構成が最高のパフォーマンスを発揮するかを測定できます。

このプロセスにより、新しいエラーや新しいモデルリリースに積極的に対応しながら、時間をかけてプロンプトを改善できます。

## 高度なテクニック

### 合成データによるデータセットの拡張

中核的な評価フライホイールは、システムを改善するための主要なツールです。しかし、本番ログから収集できる以上のテストデータが必要な場合があります。合成データ生成は、このような状況のための強力な追加技術です。特定の失敗モードをより広範囲に探索したい場合、製品をまだ出荷しておらず初期データが必要な場合、または弱点についての仮説があるが検証するための実世界の例がない場合に特に有用です。

LLMに単純に「N個の例を生成して」と依頼することは、しばしば均質なテストケースのセットを生成します。より構造化されたアプローチは、クエリの主要な次元を定義し、それらの組み合わせにわたってデータを生成し、タプルを形成することです。これにより、テストセットでより大きな多様性とカバレッジが確保されます。

賃貸アシスタントの場合、以下のような次元を定義できます：

* **チャネル：** 音声、チャット、テキスト
* **意図：** 見学スケジュール、メンテナンス、一般情報・問い合わせ
* **ペルソナ：** 見込み居住者、代理店

これらを`(テキスト、見学スケジュール、見込み居住者)`のようなタプルに組み合わせ、このプロファイルに一致する特定のテストケースを生成するようLLMにプロンプトできます。この構造化された方法により、よりシンプルな生成プロセスでは見逃される可能性のある、挑戦的で現実的なシナリオが作成されます。

クエリの中核コンポーネントを変化させることに加えて、**摂動**を適用してテストケースをより困難で現実的にすることができます。これは、システムの回復力をテストするために生成された例を少し変更することを含みます。一般的な摂動には、無関係な情報の追加、間違いの導入、異なるスラングの使用などがあります。

このトピックの詳細については、[この議論](https://hamel.dev/blog/posts/evals-faq/#q-what-is-the-best-approach-for-generating-synthetic-data)をご覧ください。

### LLMジャッジの調整

自動化されたLLMジャッジは、その判断が信頼できる場合にのみ有用です。これを確保するには、「ゴールドスタンダード」データセットを使用して、人間の専門家（SME）に対するパフォーマンスを体系的に測定する必要があります。

しかし、ほとんどのテストセットは**不均衡**です。「失敗」例よりもはるかに多くの「合格」例が含まれています。これにより、単純な精度スコアは誤解を招きます。常に「合格」を推測するジャッジは95%正確かもしれませんが、単一の失敗も見つけることはありません。

* **真陽性率（TPR）：** ジャッジは*失敗*をどの程度正確に特定するか？
* **真陰性率（TNR）：** ジャッジは*合格*をどの程度正確に特定するか？

目標は、TPRとTNRの両方で高いスコアを達成することです。これにより、ジャッジが過度に批判的になることなく、実際の問題を見つけるのに効果的であることが確認されます。この測定プロセスは標準的なデータセット分割を使用します。

1. **訓練セット（約20%）**
   このセットの唯一の仕事は、ジャッジのプロンプトの「few-shot」例を提供することです。このセットから明確な合格/失敗ケースを少数選択し、強力な出発点を与えるためにプロンプトに直接埋め込みます。

2. **検証セット（約40%）**
   ここでジャッジを反復的に改善します。このセットに対してジャッジを実行し、その決定が専門家の決定と異なるケースを分析します。ジャッジのプロンプト指示を調整して、TPRとTNRの両方を改善します。

3. **テストセット（約40%）**
   この最終的な、保留されたセットが成績表です。調整後、このセットでジャッジを一度実行します。最終的なTPRとTNRスコアは、過学習していないことを確認し、ジャッジのパフォーマンスの信頼できる測定値を提供します。

LLMジャッジをSMEと調整する方法の詳細なガイダンスについては、[この議論](https://hamel.dev/blog/posts/llm-judge/)をご覧ください。AIの判定にどのモデルを使用すべきかについてのガイダンスについては、[この投稿](https://hamel.dev/blog/posts/evals-faq/#q-can-i-use-the-same-model-for-both-the-main-task-and-evaluation)をご覧ください。

## 次のステップ

このクックブックは、回復力のあるプロンプトを構築するための基本的なワークフローを提供しますが、評価フライホイールは1サイクル後に止まりません。次のステップは、グレーダーをCI/CDパイプラインに統合し、本番データを監視して新しい失敗モードを発見することで、このプロセスをエンジニアリング実践の中核部分にすることです。

さらに、AI評価の世界は深く、ここでカバーできなかった課題に満ちています。評価戦略を構築する際に、以下のようなより複雑な質問に遭遇する可能性があります：
* チームに評価への投資の必要性をどのように説明するか？
* なぜバイナリ（合格/不合格）評価が1-5の評価スケールよりも良いことが多いのか？
* 複雑なマルチターン会話トレースをデバッグする最良の方法は何か？
* RAGシステムの評価にどのようにアプローチすべきか？
* このワークフローはエージェントシステムにどのように適応するか？

さらなる学習のために、[この評価に関するFAQ](https://hamel.dev/blog/posts/evals-faq/)を探索することをお勧めします。