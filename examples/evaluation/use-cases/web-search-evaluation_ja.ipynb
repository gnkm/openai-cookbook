{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カスタムデータセットを使用したWeb検索品質の評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、カスタムのインメモリデータセットを使用してOpenAI **Evals**フレームワークを用いて、モデルがWebから正しい回答を取得する能力を評価する方法を実演します。\n",
    "\n",
    "**目標:**\n",
    "- Web検索品質の評価を設定・実行する方法を示す\n",
    "- LLMの情報検索能力を評価するためのテンプレートを提供する\n",
    "\n",
    "\n",
    "\n",
    "## 環境設定\n",
    "\n",
    "必要なライブラリをインポートし、OpenAIクライアントを設定することから始めます。  \n",
    "これにより、OpenAI APIと評価に必要なすべてのユーティリティにアクセスできるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Update OpenAI client\n",
    "%pip install --upgrade openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"_OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カスタム評価データセットの定義\n",
    "\n",
    "ウェブ検索評価用の質問-回答ペアからなる小さなインメモリデータセットを定義します。  \n",
    "各項目には`query`（ユーザーの検索プロンプト）と`answer`（期待される正解）が含まれています。\n",
    "\n",
    "> **ヒント:**  \n",
    "> このデータセットは、あなた自身のユースケースに合わせて変更や拡張することができ、より広範な検索シナリオをテストすることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(limit=None):\n",
    "    dataset = [\n",
    "        {\n",
    "            \"query\": \"coolest person in the world, the 100m dash at the 2008 olympics was the best sports event of all time\",\n",
    "            \"answer\": \"usain bolt\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"best library in the world, there is nothing better than a dataframe\",\n",
    "            \"answer\": \"pandas\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"most fun place to visit, I am obsessed with the Philbrook Museum of Art\",\n",
    "            \"answer\": \"tulsa, oklahoma\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"who created the python programming language, beloved by data scientists everywhere\",\n",
    "            \"answer\": \"guido van rossum\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"greatest chess player in history, famous for the 1972 world championship\",\n",
    "            \"answer\": \"bobby fischer\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"the city of lights, home to the eiffel tower and louvre museum\",\n",
    "            \"answer\": \"paris\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"most popular search engine, whose name is now a verb\",\n",
    "            \"answer\": \"google\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"the first man to walk on the moon, giant leap for mankind\",\n",
    "            \"answer\": \"neil armstrong\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"groundbreaking electric car company founded by elon musk\",\n",
    "            \"answer\": \"tesla\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"founder of microsoft, philanthropist and software pioneer\",\n",
    "            \"answer\": \"bill gates\",\n",
    "        },\n",
    "    ]\n",
    "    return dataset[:limit] if limit else dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 採点ロジックの定義\n",
    "\n",
    "モデルの回答を評価するために、LLMベースの合格/不合格判定器を使用します：\n",
    "\n",
    "- **合格/不合格判定器：**  \n",
    "  モデルの回答（ウェブ検索から）が期待される回答（正解）と一致するか、または正しい情報を含んでいるかをチェックするLLMベースの判定器。\n",
    "\n",
    "> **ベストプラクティス：**  \n",
    "> LLMベースの判定器を使用することで、自由回答形式や曖昧な回答の評価に柔軟性を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_fail_grader = \"\"\"\n",
    "You are a helpful assistant that grades the quality of a web search.\n",
    "You will be given a query and an answer.\n",
    "You should grade the quality of the web search.\n",
    "\n",
    "You should either say \"pass\" or \"fail\", if the query contains the answer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pass_fail_grader_user_prompt = \"\"\"\n",
    "<Query>\n",
    "{{item.query}}\n",
    "</Query>\n",
    "\n",
    "<Web Search Result>\n",
    "{{sample.output_text}}\n",
    "</Web Search Result>\n",
    "\n",
    "<Ground Truth>\n",
    "{{item.answer}}\n",
    "</Ground Truth>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価設定の定義\n",
    "\n",
    "OpenAI Evalsフレームワークを使用して評価を設定します。\n",
    "\n",
    "このステップでは以下を指定します：\n",
    "- 評価名とデータセット\n",
    "- 各項目のスキーマ（各Q&Aペアに存在するフィールド）\n",
    "- 使用するグレーダー（LLMベースの合格/不合格判定）\n",
    "- 合格基準とラベル\n",
    "\n",
    "> **ベストプラクティス：**  \n",
    "> 評価スキーマと採点ロジックを事前に明確に定義することで、再現性と透明性が確保されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evaluation definition using the OpenAI Evals client.\n",
    "logs_eval = client.evals.create(\n",
    "    name=\"Web-Search Eval\",\n",
    "    data_source_config={\n",
    "        \"type\": \"custom\",\n",
    "        \"item_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\"},\n",
    "                \"answer\": {\"type\": \"string\"},\n",
    "            },\n",
    "        },\n",
    "        \"include_sample_schema\": True,\n",
    "    },\n",
    "    testing_criteria=[\n",
    "        {\n",
    "            \"type\": \"label_model\",\n",
    "            \"name\": \"Web Search Evaluator\",\n",
    "            \"model\": \"o3\",\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": pass_fail_grader,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": pass_fail_grader_user_prompt,\n",
    "                },\n",
    "            ],\n",
    "            \"passing_labels\": [\"pass\"],\n",
    "            \"labels\": [\"pass\", \"fail\"],\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを実行して完了を監視する\n",
    "\n",
    "選択されたモデル（`gpt-4.1`と`gpt-4.1-mini`）に対して評価を実行します。\n",
    "\n",
    "評価実行を開始した後、完了するまで（`completed`または`failed`のいずれかになるまで）ポーリングを行います。\n",
    "\n",
    "> **ベストプラクティス：**  \n",
    "> 遅延を設けたポーリングにより、過度なAPI呼び出しを避け、効率的なリソース使用を確保できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the evaluation run for gpt-4.1 using web search\n",
    "gpt_4one_responses_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1\",\n",
    "    eval_id=logs_eval.id,\n",
    "    data_source={\n",
    "        \"type\": \"responses\",\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [{\"item\": item} for item in get_dataset()],\n",
    "        },\n",
    "        \"input_messages\": {\n",
    "            \"type\": \"template\",\n",
    "            \"template\": [\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"You are a helpful assistant that searches the web and gives contextually relevant answers.\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Search the web for the answer to the query {{item.query}}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"sampling_params\": {\n",
    "            \"seed\": 42,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_completions_tokens\": 10000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"tools\": [{\"type\": \"web_search_preview\"}],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the evaluation run for gpt-4.1-mini using web search\n",
    "gpt_4one_mini_responses_run = client.evals.runs.create(\n",
    "    name=\"gpt-4.1-mini\",\n",
    "    eval_id=logs_eval.id,\n",
    "    data_source={\n",
    "        \"type\": \"responses\",\n",
    "        \"source\": {\n",
    "            \"type\": \"file_content\",\n",
    "            \"content\": [{\"item\": item} for item in get_dataset()],\n",
    "        },\n",
    "        \"input_messages\": {\n",
    "            \"type\": \"template\",\n",
    "            \"template\": [\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"You are a helpful assistant that searches the web and gives contextually relevant answers.\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"message\",\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": \"Search the web for the answer to the query {{item.query}}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"model\": \"gpt-4.1-mini\",\n",
    "        \"sampling_params\": {\n",
    "            \"seed\": 42,\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_completions_tokens\": 10000,\n",
    "            \"top_p\": 0.9,\n",
    "            \"tools\": [{\"type\": \"web_search_preview\"}],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalrun_68477e0f56a481919eea5e7d8a04225e completed ResultCounts(errored=0, failed=1, passed=9, total=10)\n",
      "evalrun_68477e712bb48191bc7368b084f8c52c completed ResultCounts(errored=0, failed=0, passed=10, total=10)\n"
     ]
    }
   ],
   "source": [
    "# poll both runs at the same time, until they are complete or failed\n",
    "def poll_runs(eval_id, run_ids):\n",
    "    while True:\n",
    "        runs = [client.evals.runs.retrieve(run_id, eval_id=eval_id) for run_id in run_ids]\n",
    "        for run in runs:\n",
    "            print(run.id, run.status, run.result_counts)\n",
    "        if all(run.status in {\"completed\", \"failed\"} for run in runs):\n",
    "            break\n",
    "        time.sleep(5)\n",
    "\n",
    "# Start polling the run until completion\n",
    "poll_runs(logs_eval.id, [gpt_4one_responses_run.id, gpt_4one_mini_responses_run.id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル出力の表示と解釈\n",
    "\n",
    "最後に、手動検査とさらなる分析のために、モデルからの出力を表示します。\n",
    "\n",
    "- データセット内の各クエリに対して、それぞれの回答が出力されます。\n",
    "- 出力を期待される回答と比較して、品質、関連性、正確性を評価することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT-4.1 Output</th>\n",
       "      <th>GPT-4.1-mini Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you're captivated by the Philbrook Museum o...</td>\n",
       "      <td>Bobby Fischer is widely regarded as one of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n## [Paris, France](https://www.google.com/ma...</td>\n",
       "      <td>The 2008 Olympic 100m dash is widely regarded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill Gates, born on October 28, 1955, in Seatt...</td>\n",
       "      <td>If you're looking for fun places to visit in T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usain Bolt's performance in the 100-meter fina...</td>\n",
       "      <td>On July 20, 1969, astronaut Neil Armstrong bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It seems you're interested in both the world's...</td>\n",
       "      <td>Bill Gates is a renowned software pioneer, phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neil Armstrong was the first person to walk on...</td>\n",
       "      <td>Your statement, \"there is nothing better than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tesla, Inc. is an American electric vehicle an...</td>\n",
       "      <td>The search engine whose name has become synony...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bobby Fischer, widely regarded as one of the g...</td>\n",
       "      <td>\\n## [Paris, France](https://www.google.com/ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Guido van Rossum, a Dutch programmer born on J...</td>\n",
       "      <td>Guido van Rossum, a Dutch programmer born on J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The most popular search engine whose name has ...</td>\n",
       "      <td>Elon Musk is the CEO and largest shareholder o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      GPT-4.1 Output  \\\n",
       "0  If you're captivated by the Philbrook Museum o...   \n",
       "1  \\n## [Paris, France](https://www.google.com/ma...   \n",
       "2  Bill Gates, born on October 28, 1955, in Seatt...   \n",
       "3  Usain Bolt's performance in the 100-meter fina...   \n",
       "4  It seems you're interested in both the world's...   \n",
       "5  Neil Armstrong was the first person to walk on...   \n",
       "6  Tesla, Inc. is an American electric vehicle an...   \n",
       "7  Bobby Fischer, widely regarded as one of the g...   \n",
       "8  Guido van Rossum, a Dutch programmer born on J...   \n",
       "9  The most popular search engine whose name has ...   \n",
       "\n",
       "                                 GPT-4.1-mini Output  \n",
       "0  Bobby Fischer is widely regarded as one of the...  \n",
       "1  The 2008 Olympic 100m dash is widely regarded ...  \n",
       "2  If you're looking for fun places to visit in T...  \n",
       "3  On July 20, 1969, astronaut Neil Armstrong bec...  \n",
       "4  Bill Gates is a renowned software pioneer, phi...  \n",
       "5  Your statement, \"there is nothing better than ...  \n",
       "6  The search engine whose name has become synony...  \n",
       "7  \\n## [Paris, France](https://www.google.com/ma...  \n",
       "8  Guido van Rossum, a Dutch programmer born on J...  \n",
       "9  Elon Musk is the CEO and largest shareholder o...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve output items for the 4.1 model after completion\n",
    "four_one = client.evals.runs.output_items.list(\n",
    "    run_id=gpt_4one_responses_run.id, eval_id=logs_eval.id\n",
    ")\n",
    "\n",
    "# Retrieve output items for the 4.1-mini model after completion\n",
    "four_one_mini = client.evals.runs.output_items.list(\n",
    "    run_id=gpt_4one_mini_responses_run.id, eval_id=logs_eval.id\n",
    ")\n",
    "\n",
    "# Collect outputs for both models\n",
    "four_one_outputs = [item.sample.output[0].content for item in four_one]\n",
    "four_one_mini_outputs = [item.sample.output[0].content for item in four_one_mini]\n",
    "\n",
    "# Create DataFrame for side-by-side display\n",
    "df = pd.DataFrame({\n",
    "    \"GPT-4.1 Output\": four_one_outputs,\n",
    "    \"GPT-4.1-mini Output\": four_one_mini_outputs\n",
    "})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の画像に示すように、https://platform.openai.com/evaluations にアクセスして、evalsダッシュボードで結果を可視化できます：\n",
    "\n",
    "![evals-websearch-dashboard](../../../images/evals_websearch_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックでは、OpenAI Evalsフレームワークを使用して言語モデルのウェブ検索機能を評価するワークフローを実演しました。\n",
    "\n",
    "**カバーした主要なポイント：**\n",
    "- ウェブ検索評価のための焦点を絞ったカスタムデータセットを定義しました。\n",
    "- 堅牢な評価のためのLLMベースの採点者を設定しました。\n",
    "- 最新のOpenAIモデルとウェブ検索ツールを使用して再現可能な評価を実行しました。\n",
    "- 検査のためにモデル出力を取得し表示しました。\n",
    "\n",
    "**次のステップと提案：**\n",
    "- **データセットの拡張：** より多様で挑戦的なクエリを追加して、モデルの能力をより適切に評価する。\n",
    "- **結果の分析：** 合格/不合格率をまとめ、パフォーマンスを可視化し、または強みと弱みを特定するためのエラー分析を実行する。\n",
    "- **モデル/ツールの実験：** 追加のモデルを試し、ツール設定を調整し、または他のタイプの情報検索タスクでテストする。\n",
    "- **レポートの自動化：** より簡単な共有と意思決定のためのサマリーテーブルやプロットを生成する。\n",
    "\n",
    "詳細については、[OpenAI Evalsドキュメント](https://platform.openai.com/docs/guides/evals)を参照してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
