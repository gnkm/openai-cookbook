{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価例：プッシュ通知要約機能の監視\n",
    "\n",
    "評価は**タスク指向**で反復的であり、LLM統合の状況を確認し改善するための最良の方法です。\n",
    "\n",
    "以下の評価では、**プロンプト変更による回帰の検出**というタスクに焦点を当てます。\n",
    "\n",
    "私たちのユースケースは以下の通りです：\n",
    "1. 本番環境のチャット補完リクエストで`store=True`を設定することで、チャット補完リクエストをログに記録しています。なお、管理パネル（https://platform.openai.com/settings/organization/data-controls/data-retention）で「デフォルトでオン」のログ記録を有効にすることも可能です。\n",
    "2. プロンプトの変更が回帰を引き起こしていないかを確認したいと考えています。\n",
    "\n",
    "## 評価の構造\n",
    "\n",
    "評価には「Eval」と「Run」の2つの部分があります。「Eval」はテスト基準の設定と「Run」のデータ構造を保持します。1つのEvalは複数のRunを持つことができ、それぞれがテスト基準を使用して評価されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "import asyncio\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", \"your-api-key\")\n",
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ユースケース\n",
    "\n",
    "以下の統合をテストしています。プッシュ通知サマリー機能で、複数のプッシュ通知を受け取り、それらを1つにまとめるものです。これはchat completions呼び出しです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータの生成\n",
    "\n",
    "本番環境のチャット補完リクエストをシミュレートして、2つの異なるプロンプトバージョンをテストし、それぞれのパフォーマンスを確認します。1つ目は「良い」プロンプト、2つ目は「悪い」プロンプトです。これらには異なるメタデータが含まれており、後で使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_notification_data = [\n",
    "        \"\"\"\n",
    "- New message from Sarah: \"Can you call me later?\"\n",
    "- Your package has been delivered!\n",
    "- Flash sale: 20% off electronics for the next 2 hours!\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Weather alert: Thunderstorm expected in your area.\n",
    "- Reminder: Doctor's appointment at 3 PM.\n",
    "- John liked your photo on Instagram.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Breaking News: Local elections results are in.\n",
    "- Your daily workout summary is ready.\n",
    "- Check out your weekly screen time report.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Your ride is arriving in 2 minutes.\n",
    "- Grocery order has been shipped.\n",
    "- Don't miss the season finale of your favorite show tonight!\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Event reminder: Concert starts at 7 PM.\n",
    "- Your favorite team just scored!\n",
    "- Flashback: Memories from 3 years ago.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Low battery alert: Charge your device.\n",
    "- Your friend Mike is nearby.\n",
    "- New episode of \"The Tech Hour\" podcast is live!\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- System update available.\n",
    "- Monthly billing statement is ready.\n",
    "- Your next meeting starts in 15 minutes.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Alert: Unauthorized login attempt detected.\n",
    "- New comment on your blog post: \"Great insights!\"\n",
    "- Tonight's dinner recipe: Pasta Primavera.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Special offer: Free coffee with any breakfast order.\n",
    "- Your flight has been delayed by 30 minutes.\n",
    "- New movie release: \"Adventures Beyond\" now streaming.\n",
    "\"\"\",\n",
    "        \"\"\"\n",
    "- Traffic alert: Accident reported on Main Street.\n",
    "- Package out for delivery: Expected by 5 PM.\n",
    "- New friend suggestion: Connect with Emma.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = [\n",
    "    (\n",
    "        \"\"\"\n",
    "        You are a helpful assistant that summarizes push notifications.\n",
    "        You are given a list of push notifications and you need to collapse them into a single one.\n",
    "        Output only the final summary, nothing else.\n",
    "        \"\"\",\n",
    "        \"v1\"\n",
    "    ),\n",
    "    (\n",
    "        \"\"\"\n",
    "        You are a helpful assistant that summarizes push notifications.\n",
    "        You are given a list of push notifications and you need to collapse them into a single one.\n",
    "        The summary should be longer than it needs to be and include more information than is necessary.\n",
    "        Output only the final summary, nothing else.\n",
    "        \"\"\",\n",
    "        \"v2\"\n",
    "    )\n",
    "]\n",
    "\n",
    "tasks = []\n",
    "for notifications in push_notification_data:\n",
    "    for (prompt, version) in PROMPTS:\n",
    "        tasks.append(client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": notifications},\n",
    "            ],\n",
    "            store=True,\n",
    "            metadata={\"prompt_version\": version, \"usecase\": \"push_notifications_summarizer\"},\n",
    "        ))\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した補完は https://platform.openai.com/logs で確認できます。\n",
    "\n",
    "**次のステップに必要なため、チャット補完が表示されていることを確認してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = await client.chat.completions.list()\n",
    "assert completions.data, \"No completions found. You may need to enable logs in your admin panel.\"\n",
    "completions.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalの設定\n",
    "\n",
    "Evalは複数の*Run*間で共有される設定を保持し、2つのコンポーネントで構成されています：\n",
    "1. データソース設定 `data_source_config` - 将来の*Run*が準拠するスキーマ（列）。\n",
    "    - `data_source_config`はJSON Schemaを使用して、Evalで利用可能な変数を定義します。\n",
    "2. テスト基準 `testing_criteria` - データソースの各*行*に対してインテグレーションが機能しているかどうかを判断する方法。\n",
    "\n",
    "このユースケースでは、stored-completionsを使用するため、そのdata_source_configを設定します。\n",
    "\n",
    "**重要**\n",
    "stored completionsのユースケースは多数存在する可能性が高いため、メタデータを使用してこれらを追跡し、evalを集中的かつタスク指向に保つことが最良の方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want our input data to be available in our variables, so we set the item_schema to\n",
    "# PushNotifications.model_json_schema()\n",
    "data_source_config = {\n",
    "    \"type\": \"stored_completions\",\n",
    "    \"metadata\": {\n",
    "        \"usecase\": \"push_notifications_summarizer\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このdata_source_configは、eval全体で利用可能な変数を定義します。\n",
    "\n",
    "stored completions configは、eval全体で使用できる2つの変数を提供します：\n",
    "1. {{item.input}} - completions呼び出しに送信されたメッセージ\n",
    "2. {{sample.output_text}} - アシスタントからのテキスト応答\n",
    "\n",
    "**次に、これらの変数を使用してテスト基準を設定します。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRADER_DEVELOPER_PROMPT = \"\"\"\n",
    "Label the following push notification summary as either correct or incorrect.\n",
    "The push notification and the summary will be provided below.\n",
    "A good push notificiation summary is concise and snappy.\n",
    "If it is good, then label it as correct, if not, then incorrect.\n",
    "\"\"\"\n",
    "GRADER_TEMPLATE_PROMPT = \"\"\"\n",
    "Push notifications: {{item.input}}\n",
    "Summary: {{sample.output_text}}\n",
    "\"\"\"\n",
    "push_notification_grader = {\n",
    "    \"name\": \"Push Notification Summary Grader\",\n",
    "    \"type\": \"label_model\",\n",
    "    \"model\": \"o3-mini\",\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": GRADER_DEVELOPER_PROMPT,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": GRADER_TEMPLATE_PROMPT,\n",
    "        },\n",
    "    ],\n",
    "    \"passing_labels\": [\"correct\"],\n",
    "    \"labels\": [\"correct\", \"incorrect\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`push_notification_grader`は、モデルグレーダー（llm-as-a-judge）であり、入力`{{item.input}}`と生成された要約`{{sample.output_text}}`を確認して、「正しい」または「間違っている」とラベル付けします。\n",
    "\n",
    "注意：内部的には、構造化出力を使用しているため、ラベルは常に有効です。\n",
    "\n",
    "**それでは評価を作成し、データの追加を開始しましょう！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_create_result = await client.evals.create(\n",
    "    name=\"Push Notification Completion Monitoring\",\n",
    "    metadata={\"description\": \"This eval monitors completions\"},\n",
    "    data_source_config=data_source_config,\n",
    "    testing_criteria=[push_notification_grader],\n",
    ")\n",
    "\n",
    "eval_id = eval_create_result.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実行の作成\n",
    "\n",
    "テストクライテリアを使用してevalのセットアップが完了したので、実行を追加し始めることができます。\n",
    "2つの**プロンプトバージョン**間のパフォーマンスを比較したいと思います。\n",
    "\n",
    "これを行うために、各プロンプトバージョンに対してメタデータフィルターを使用して、ソースを\"stored_completions\"として定義するだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt_version=v1\n",
    "eval_run_result = await client.evals.runs.create(\n",
    "    eval_id=eval_id,\n",
    "    name=\"v1-run\",\n",
    "    data_source={\n",
    "        \"type\": \"completions\",\n",
    "        \"source\": {\n",
    "            \"type\": \"stored_completions\",\n",
    "            \"metadata\": {\n",
    "                \"prompt_version\": \"v1\",\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(eval_run_result.report_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt_version=v2\n",
    "eval_run_result_v2 = await client.evals.runs.create(\n",
    "    eval_id=eval_id,\n",
    "    name=\"v2-run\",\n",
    "    data_source={\n",
    "        \"type\": \"completions\",\n",
    "        \"source\": {\n",
    "            \"type\": \"stored_completions\",\n",
    "            \"metadata\": {\n",
    "                \"prompt_version\": \"v2\",\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(eval_run_result_v2.report_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "念のため、4o-miniの代わりに4oを使って、両方のプロンプトバージョンを出発点として、このプロンプトがどのような性能を示すかを確認してみましょう。\n",
    "\n",
    "必要なのは、入力メッセージ（{{item.input}}）を参照し、モデルを4oに設定することだけです。4o用の保存された補完結果がまだないため、この評価実行では新しい補完結果が生成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "for prompt_version in [\"v1\", \"v2\"]:\n",
    "    tasks.append(client.evals.runs.create(\n",
    "        eval_id=eval_id,\n",
    "        name=f\"post-fix-new-model-run-{prompt_version}\",\n",
    "        data_source={\n",
    "            \"type\": \"completions\",\n",
    "            \"input_messages\": {\n",
    "                \"type\": \"item_reference\",\n",
    "                \"item_reference\": \"item.input\",\n",
    "            },\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"source\": {\n",
    "                \"type\": \"stored_completions\",\n",
    "                \"metadata\": {\n",
    "                    \"prompt_version\": prompt_version,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ))\n",
    "result = await asyncio.gather(*tasks)\n",
    "for run in result:\n",
    "    print(run.report_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのレポートを確認すると、`prompt_version=v2`にリグレッションがあることが分かります！\n",
    "\n",
    "## おめでとうございます。バグを発見しました。これを元に戻すか、別のプロンプト変更を行うなどができます！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
