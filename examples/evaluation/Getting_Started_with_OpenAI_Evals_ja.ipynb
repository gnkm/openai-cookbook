{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# OpenAI Evalsを始める\n",
    "\n",
    "OpenAI Evalsは、言語モデルの性能を評価するためのフレームワークです。このガイドでは、基本的な使用方法から始めて、カスタム評価の作成まで説明します。\n",
    "\n",
    "## インストール\n",
    "\n",
    "まず、OpenAI Evalsをインストールします：\n",
    "\n",
    "```bash\n",
    "pip install evals\n",
    "```\n",
    "\n",
    "## 基本的な使用方法\n",
    "\n",
    "### 1. 既存の評価を実行する\n",
    "\n",
    "利用可能な評価を確認するには：\n",
    "\n",
    "```bash\n",
    "oaieval list\n",
    "```\n",
    "\n",
    "評価を実行するには：\n",
    "\n",
    "```bash\n",
    "oaieval gpt-3.5-turbo test-match\n",
    "```\n",
    "\n",
    "### 2. 評価結果の確認\n",
    "\n",
    "評価結果は`/tmp/evallogs/`ディレクトリに保存されます。結果を表示するには：\n",
    "\n",
    "```bash\n",
    "oaieval gpt-3.5-turbo test-match --log_to_file /path/to/logfile.jsonl\n",
    "```\n",
    "\n",
    "## カスタム評価の作成\n",
    "\n",
    "### 評価ファイルの構造\n",
    "\n",
    "評価は通常、以下の構造を持ちます：\n",
    "\n",
    "```yaml\n",
    "id: my-custom-eval\n",
    "description: \"カスタム評価の説明\"\n",
    "disclaimer: \"この評価は例示目的です\"\n",
    "metrics: [accuracy]\n",
    "```\n",
    "\n",
    "### サンプルデータの準備\n",
    "\n",
    "評価データは`jsonl`形式で準備します：\n",
    "\n",
    "```json\n",
    "{\"input\": \"質問1\", \"ideal\": \"正解1\"}\n",
    "{\"input\": \"質問2\", \"ideal\": \"正解2\"}\n",
    "```\n",
    "\n",
    "### 評価クラスの実装\n",
    "\n",
    "カスタム評価クラスを作成します：\n",
    "\n",
    "```python\n",
    "import evals\n",
    "from evals.api import CompletionFn\n",
    "from evals.elsuite.basic.match import Match\n",
    "\n",
    "class MyCustomEval(evals.Eval):\n",
    "    def __init__(self, completion_fns: list[CompletionFn], *args, **kwargs):\n",
    "        super().__init__(completion_fns, *args, **kwargs)\n",
    "        \n",
    "    def eval_sample(self, sample, *_):\n",
    "        prompt = sample[\"input\"]\n",
    "        result = self.completion_fn(\n",
    "            prompt=prompt,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        \n",
    "        return evals.record_and_check_match(\n",
    "            prompt=prompt,\n",
    "            sampled=result.get_completions()[0],\n",
    "            expected=sample[\"ideal\"]\n",
    "        )\n",
    "```\n",
    "\n",
    "## 高度な機能\n",
    "\n",
    "### メトリクスのカスタマイズ\n",
    "\n",
    "独自のメトリクスを定義できます：\n",
    "\n",
    "```python\n",
    "def custom_accuracy(samples):\n",
    "    correct = sum(1 for sample in samples if sample[\"match\"])\n",
    "    return {\"accuracy\": correct / len(samples)}\n",
    "```\n",
    "\n",
    "### バッチ処理\n",
    "\n",
    "大量のデータを効率的に処理するには：\n",
    "\n",
    "```python\n",
    "def run_eval_batch(self, samples):\n",
    "    results = []\n",
    "    for batch in self.get_batches(samples, batch_size=10):\n",
    "        batch_results = self.process_batch(batch)\n",
    "        results.extend(batch_results)\n",
    "    return results\n",
    "```\n",
    "\n",
    "## ベストプラクティス\n",
    "\n",
    "1. **明確な評価基準**: 評価基準を明確に定義する\n",
    "2. **多様なテストケース**: 様々なシナリオをカバーする\n",
    "3. **再現可能性**: 同じ条件で同じ結果が得られるようにする\n",
    "4. **継続的な改善**: 評価結果を基にモデルを改善する\n",
    "\n",
    "## トラブルシューティング\n",
    "\n",
    "### よくある問題\n",
    "\n",
    "- **API制限**: レート制限に注意し、適切な間隔を設ける\n",
    "- **メモリ不足**: 大きなデータセットの場合はバッチ処理を使用\n",
    "- **設定エラー**: 環境変数とAPIキーが正しく設定されているか確認\n",
    "\n",
    "### デバッグのヒント\n",
    "\n",
    "```bash\n",
    "# 詳細なログを有効にする\n",
    "export EVALS_LOG_LEVEL=DEBUG\n",
    "\n",
    "# 特定の評価をデバッグモードで実行\n",
    "oaieval --debug gpt-3.5-turbo my-eval\n",
    "```\n",
    "\n",
    "これで、OpenAI Evalsの基本的な使用方法から高度な機能まで理解できました。独自の評価を作成して、言語モデルの性能を効果的に測定しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**注意：OpenAIは現在、APIを備えたホスト型evalsプロダクトを提供しています！代わりにこちらの使用を推奨します。\n",
    "[Evals](https://platform.openai.com/docs/guides/evals)をご覧ください**\n",
    "\n",
    "[OpenAI Evals](https://github.com/openai/evals/tree/main)フレームワークは以下で構成されています：\n",
    "1. LLM（大規模言語モデル）またはLLM上に構築されたシステムを評価するためのフレームワーク\n",
    "2. 挑戦的なevalsのオープンソースレジストリ\n",
    "\n",
    "このノートブックでは以下を扱います：\n",
    "* 評価と[OpenAI Evals](https://github.com/openai/evals/tree/main)ライブラリの紹介\n",
    "* Evalの構築\n",
    "* Evalの実行\n",
    "\n",
    "#### 評価/`evals`とは何か？\n",
    "\n",
    "評価とは、LLMアプリケーションが生成する出力を検証・テストするプロセスです。強力な評価（「evals」）を持つことで、コードやモデルの変更に対して堅牢で、より安定した信頼性の高いアプリケーションを実現できます。evalは、LLMまたはLLMシステムの出力品質を測定するために使用されるタスクです。入力プロンプトが与えられると、出力が生成されます。この出力を理想的な回答のセットと照らし合わせて評価し、LLMシステムの品質を判定します。\n",
    "\n",
    "#### 評価の重要性\n",
    "\n",
    "`GPT-4`のような基盤モデルを使用して構築している場合、高品質なevalsを作成することは、最もインパクトのある取り組みの一つです。AI ソリューションの開発には反復的な設計プロセスが含まれます。[evalsがないと、異なるモデルバージョンやプロンプトがユースケースにどのような影響を与えるかを理解することが非常に困難で時間がかかる場合があります](https://youtu.be/XGJNo8TpuVA?feature=shared&t=1089)。\n",
    "\n",
    "OpenAIの[継続的なモデルアップグレード](https://platform.openai.com/docs/models/continuous-model-upgrades)により、evalsを使用することで、ユースケースに対するモデルパフォーマンスを標準化された方法で効率的にテストできます。目標に合わせてカスタマイズされたevalsスイートを開発することで、新しいモデルがユースケースでどのようなパフォーマンスを発揮するかを迅速かつ効果的に理解できます。また、evalsをCI/CDパイプラインの一部にして、デプロイ前に望ましい精度を確実に達成することも可能です。\n",
    "\n",
    "#### evalsの種類\n",
    "\n",
    "完了を評価/採点する主な方法は2つあります：コードで検証ロジックを書く方法と、モデル自体を使用して回答を検査する方法です。それぞれを例とともに紹介します。\n",
    "\n",
    "**回答チェックのためのロジック記述**\n",
    "\n",
    "最もシンプルで一般的なタイプのevalは、入力と理想的な応答または回答を持ちます。例えば、入力が「オバマが初めて大統領に選出されたのは何年ですか？」で、理想的な回答が「2008」であるevalサンプルを持つことができます。入力をモデルに与えて完了を得ます。モデルが「2008」と言った場合、正解として採点されます。完了に「2008」という語句が含まれているかをチェックする文字列マッチを書くことができます。含まれていれば、正解と見なします。\n",
    "\n",
    "有効なJSONを生成する入力を持つ別のevalを考えてみましょう：完了をJSONとして解析しようとするコードを書き、解析可能であれば完了を正解と見なすことができます。\n",
    "\n",
    "**モデル採点：モデルがまず質問に回答し、次にモデルに応答を見て正解かどうかをチェックしてもらう2段階プロセス。**\n",
    "\n",
    "モデルに面白いジョークを書くよう求める入力を考えてみましょう。モデルが完了を生成します。次に、完了を含む「次のジョークは面白いですか？まず段階的に理由を述べ、次にyes または no で答えてください」という質問に答えるための新しい入力をモデルに作成します。新しいモデルの完了が「yes」で終わる場合、元の完了を正解と見なします。\n",
    "\n",
    "モデル採点は、`GPT-4`のような最新で最も強力なモデルで最もよく機能し、判断を下す前に推論する能力を与える場合に効果的です。モデル採点にはエラー率があるため、evalsを大規模に実行する前に人間による評価でパフォーマンスを検証することが重要です。最良の結果を得るには、完了を行ったモデルとは異なるモデルを採点に使用することが理にかなっています。例えば、`GPT-4`を使用して`GPT-3.5`の回答を採点するなどです。\n",
    "\n",
    "#### OpenAI Evalテンプレート\n",
    "\n",
    "evalsを使用する中で、多くの異なるベンチマークに対応するいくつかの「テンプレート」を発見しました。新しいevalsの開発を簡素化するため、OpenAI Evalsライブラリにこれらのテンプレートを実装しました。例えば、すぐに使用できる2種類のevalテンプレートを定義しています：\n",
    "\n",
    "* **基本Evalテンプレート**：出力を理想的な回答と比較する決定論的関数を含みます。多肢選択問題への回答や単純で直接的な回答を持つ簡単な質問など、望ましいモデル応答のバリエーションが非常に少ない場合に、以下のテンプレートが有用であることがわかりました。\n",
    "\n",
    "* **モデル採点テンプレート**：LLMが出力を理想的な回答と比較し、精度を判定しようとする関数を含みます。オープンエンドな質問への回答など、望ましいモデル応答に大きなバリエーションが含まれる可能性がある場合、モデルに自己採点させることが自動評価の実行可能な戦略であることがわかりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### セットアップ\n",
    "\n",
    "まず、[github.com/openai/evals](https://github.com/openai/evals)にアクセスし、`git clone git@github.com:openai/evals.git`でリポジトリをクローンして、[セットアップ手順](https://github.com/openai/evals)を実行してください。\n",
    "\n",
    "このノートブックで後ほどevalsを実行するには、OpenAI APIキーを設定して指定する必要があります。APIキーを取得した後、`OPENAI_API_KEY`環境変数を使用して指定してください。\n",
    "\n",
    "evalsを実行する際のAPI使用に関連するコストにご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T02:24:59.629Z",
     "start_time": "2024-03-27T02:24:50.505893Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## OpenAI Evalsフレームワーク用の評価の構築\n",
    "\n",
    "基本的に、evalはデータセットとYAMLファイルで定義されるevalクラスです。evalの作成を開始するには、以下が必要です：\n",
    "\n",
    "1. `jsonl`形式のテストデータセット\n",
    "2. 使用するevalテンプレート\n",
    "\n",
    "### evalデータセットの作成\n",
    "構文的に正しいSQLを生成するモデルの能力を評価するユースケース用のデータセットを作成しましょう。このユースケースでは、自動車製造に関連する一連のテーブルがあります。\n",
    "\n",
    "まず、評価したいシステムプロンプトを作成する必要があります。モデルへの指示とテーブル構造の概要を渡します：\n",
    "```\n",
    "\"TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]\"\n",
    "```\n",
    "\n",
    "このプロンプトに対して、特定の質問をすることができます：\n",
    "```\n",
    "\"Q: how many car makers are their in germany?\"\n",
    "```\n",
    "\n",
    "そして期待される回答があります：\n",
    "```\n",
    "\"A: SELECT count ( * )  FROM CAR_MAKERS AS T1 JOIN COUNTRIES AS T2 ON T1.Country   =   T2.CountryId WHERE T2.CountryName   =   'germany'\"\n",
    "```\n",
    "\n",
    "データセットは以下の形式である必要があります：\n",
    "```\n",
    "\"input\": [{\"role\": \"system\", \"content\": \"<input prompt>\"}, {\"role\": \"user\", \"content\": <user input>}, \"ideal\": \"correct answer\"]\n",
    "```\n",
    "\n",
    "すべてをまとめると、以下のようになります：\n",
    "```\n",
    "{\"input\": [{\"role\": \"system\", \"content\": \"TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]\\n\"}, {\"role\": \"system\", \"content\": \"Q: how many car makers are their in germany\"}, \"ideal\": [\"A: SELECT count ( * )  FROM CAR_MAKERS AS T1 JOIN COUNTRIES AS T2 ON T1.Country   =   T2.CountryId WHERE T2.CountryName   =   'germany'\"]}\n",
    "```\n",
    "\n",
    "evalデータセットの構築プロセスを高速化する一つの方法は、`GPT-4`を使用して合成データを生成することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:23:04.862331Z",
     "start_time": "2024-03-18T07:23:04.717601Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the average horsepower for cars made in Europe?\n",
      "A: SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.Continent = 'Europe'\n",
      "\n",
      "Q: What is the average horsepower for cars made in the USA?\n",
      "A: SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN car_makers ON car_names.MakeId = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId WHERE countries.CountryName = 'USA'\n",
      "\n",
      "Q: What is the average horsepower for cars produced in countries from the continent with the id '3'?\n",
      "A: SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.ContId = '3'\n",
      "\n",
      "Q: What is the average horsepower for cars made by makers from Europe?\n",
      "A: SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.Continent = 'Europe'\n",
      "\n",
      "Q: What is the average horsepower for cars made in the USA?\n",
      "\n",
      "A: SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN car_makers ON car_names.MakeId = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId WHERE countries.CountryName = 'USA'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Use GPT-4 to generate synthetic data\n",
    "# Define the system prompt and user input (these should be filled as per the specific use case)\n",
    "system_prompt = \"\"\"You are a helpful assistant that can ask questions about a database table and write SQL queries to answer the question.\n",
    "    A user will pass in a table schema and your job is to return a question answer pairing. The question should relevant to the schema of the table,\n",
    "    and you can speculate on its contents. You will then have to generate a SQL query to answer the question. Below are some examples of what this should look like.\n",
    "\n",
    "    Example 1\n",
    "    ```````````\n",
    "    User input: Table museum, columns = [*,Museum_ID,Name,Num_of_Staff,Open_Year]\\nTable visit, columns = [*,Museum_ID,visitor_ID,Num_of_Ticket,Total_spent]\\nTable visitor, columns = [*,ID,Name,Level_of_membership,Age]\\nForeign_keys = [visit.visitor_ID = visitor.ID,visit.Museum_ID = museum.Museum_ID]\\n\n",
    "    Assistant Response:\n",
    "    Q: How many visitors have visited the museum with the most staff?\n",
    "    A: SELECT count ( * )  FROM VISIT AS T1 JOIN MUSEUM AS T2 ON T1.Museum_ID   =   T2.Museum_ID WHERE T2.Num_of_Staff   =   ( SELECT max ( Num_of_Staff )  FROM MUSEUM ) \n",
    "    ```````````\n",
    "\n",
    "    Example 2\n",
    "    ```````````\n",
    "    User input: Table museum, columns = [*,Museum_ID,Name,Num_of_Staff,Open_Year]\\nTable visit, columns = [*,Museum_ID,visitor_ID,Num_of_Ticket,Total_spent]\\nTable visitor, columns = [*,ID,Name,Level_of_membership,Age]\\nForeign_keys = [visit.visitor_ID = visitor.ID,visit.Museum_ID = museum.Museum_ID]\\n\n",
    "    Assistant Response:\n",
    "    Q: What are the names who have a membership level higher than 4?\n",
    "    A: SELECT Name   FROM VISITOR AS T1 WHERE T1.Level_of_membership   >   4 \n",
    "    ```````````\n",
    "\n",
    "    Example 3\n",
    "    ```````````\n",
    "    User input: Table museum, columns = [*,Museum_ID,Name,Num_of_Staff,Open_Year]\\nTable visit, columns = [*,Museum_ID,visitor_ID,Num_of_Ticket,Total_spent]\\nTable visitor, columns = [*,ID,Name,Level_of_membership,Age]\\nForeign_keys = [visit.visitor_ID = visitor.ID,visit.Museum_ID = museum.Museum_ID]\\n\n",
    "    Assistant Response:\n",
    "    Q: How many tickets of customer id 5?\n",
    "    A: SELECT count ( * )  FROM VISIT AS T1 JOIN VISITOR AS T2 ON T1.visitor_ID   =   T2.ID WHERE T2.ID   =   5 \n",
    "    ```````````\n",
    "    \"\"\"\n",
    "\n",
    "user_input = \"Table car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]\"\n",
    "\n",
    "messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    "    n=5\n",
    ")\n",
    "\n",
    "for choice in completion.choices:\n",
    "    print(choice.message.content + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合成データを取得したら、評価データセットの形式に合わせて変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': [{'role': 'system', 'content': 'TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]'}, {'role': 'user', 'content': 'What is the average horsepower for cars made in Europe?'}], 'ideal': \"SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.Continent = 'Europe'\"}\n",
      "{'input': [{'role': 'system', 'content': 'TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]'}, {'role': 'user', 'content': 'What is the average horsepower for cars made in the USA?'}], 'ideal': \"SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN car_makers ON car_names.MakeId = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId WHERE countries.CountryName = 'USA'\"}\n",
      "{'input': [{'role': 'system', 'content': 'TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]'}, {'role': 'user', 'content': \"What is the average horsepower for cars produced in countries from the continent with the id '3'?\"}], 'ideal': \"SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.ContId = '3'\"}\n",
      "{'input': [{'role': 'system', 'content': 'TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]'}, {'role': 'user', 'content': 'What is the average horsepower for cars made by makers from Europe?'}], 'ideal': \"SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN model_list ON car_names.Model = model_list.Model JOIN car_makers ON model_list.Maker = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId JOIN continents ON countries.Continent = continents.ContId WHERE continents.Continent = 'Europe'\"}\n",
      "{'input': [{'role': 'system', 'content': 'TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]'}, {'role': 'user', 'content': 'What is the average horsepower for cars made in the USA?'}], 'ideal': \"SELECT AVG(cars_data.Horsepower) FROM cars_data JOIN car_names ON cars_data.Id = car_names.MakeId JOIN car_makers ON car_names.MakeId = car_makers.Id JOIN countries ON car_makers.Country = countries.CountryId WHERE countries.CountryName = 'USA'\"}\n"
     ]
    }
   ],
   "source": [
    "eval_data = []\n",
    "input_prompt = \"TASK: Answer the following question with syntactically correct SQLite SQL. The SQL should be correct and be in context of the previous question-answer pairs.\\nTable car_makers, columns = [*,Id,Maker,FullName,Country]\\nTable car_names, columns = [*,MakeId,Model,Make]\\nTable cars_data, columns = [*,Id,MPG,Cylinders,Edispl,Horsepower,Weight,Accelerate,Year]\\nTable continents, columns = [*,ContId,Continent]\\nTable countries, columns = [*,CountryId,CountryName,Continent]\\nTable model_list, columns = [*,ModelId,Maker,Model]\\nForeign_keys = [countries.Continent = continents.ContId,car_makers.Country = countries.CountryId,model_list.Maker = car_makers.Id,car_names.Model = model_list.Model,cars_data.Id = car_names.MakeId]\"\n",
    "\n",
    "for choice in completion.choices:\n",
    "    question = choice.message.content.split(\"Q: \")[1].split(\"\\n\")[0]  # Extracting the question\n",
    "    answer = choice.message.content.split(\"\\nA: \")[1].split(\"\\n\")[0]  # Extracting the answer\n",
    "    eval_data.append({\n",
    "        \"input\": [\n",
    "            {\"role\": \"system\", \"content\": input_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "        \"ideal\": answer\n",
    "    })\n",
    "\n",
    "for item in eval_data:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、フレームワークで実行するためのevalレジストリを作成する必要があります。\n",
    "\n",
    "evalsフレームワークには、以下のプロパティで構成された`.yaml`ファイルが必要です：\n",
    "* `id` - evalの識別子\n",
    "* `description` - evalの短い説明\n",
    "* `disclaimer` - evalに関する追加の注意事項\n",
    "* `metrics` - 選択できるevalメトリクスには3つのタイプがあります：match、includes、fuzzyMatch\n",
    "\n",
    "私たちのevalでは、以下のように設定します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T20:59:19.220486Z",
     "start_time": "2024-06-05T20:59:19.215426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nspider-sql:\\n  id: spider-sql.dev.v0\\n  metrics: [accuracy]\\n  description: Eval that scores SQL code from 194 examples in the Spider Text-to-SQL test dataset. The problems are selected by taking the first 10 problems for each database that appears in the test set.\\n    Yu, Tao, et al. \"Spider; A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task.\" Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, https://doi.org/10.18653/v1/d18-1425.\\n  disclaimer: Problems are solved zero-shot with no prompting other than the schema; performance may improve with training examples, fine tuning, or a different schema format. Evaluation is currently done through model-grading, where SQL code is not actually executed; the model may judge correct SQL to be incorrect, or vice-versa.\\nspider-sql.dev.v0:\\n  class: evals.elsuite.modelgraded.classify:ModelBasedClassify\\n  args:\\n    samples_jsonl: sql/spider_sql.jsonl\\n    eval_type: cot_classify\\n    modelgraded_spec: sql\\n  '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "spider-sql:\n",
    "  id: spider-sql.dev.v0\n",
    "  metrics: [accuracy]\n",
    "  description: Eval that scores SQL code from 194 examples in the Spider Text-to-SQL test dataset. The problems are selected by taking the first 10 problems for each database that appears in the test set.\n",
    "    Yu, Tao, et al. \\\"Spider; A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task.\\\" Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018, https://doi.org/10.18653/v1/d18-1425.\n",
    "  disclaimer: Problems are solved zero-shot with no prompting other than the schema; performance may improve with training examples, fine tuning, or a different schema format. Evaluation is currently done through model-grading, where SQL code is not actually executed; the model may judge correct SQL to be incorrect, or vice-versa.\n",
    "spider-sql.dev.v0:\n",
    "  class: evals.elsuite.modelgraded.classify:ModelBasedClassify\n",
    "  args:\n",
    "    samples_jsonl: sql/spider_sql.jsonl\n",
    "    eval_type: cot_classify\n",
    "    modelgraded_spec: sql\n",
    "  \"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 評価の実行\n",
    "\n",
    "`oaieval` CLIを使用してこの評価を実行できます。セットアップするには、ライブラリをインストールしてください：`pip install .`（[OpenAI Evalsライブラリ](github.com/openai/evals)をローカルで実行している場合）または、既存の評価を実行している場合は`pip install oaieval`を使用してください。\n",
    "\n",
    "次に、CLIを使用して評価を実行します：`oaieval gpt-3.5-turbo spider-sql`\n",
    "\n",
    "このコマンドはモデル名と評価セット名を期待します。2つのコマンドラインインターフェース（CLI）を提供していることに注意してください：単一の評価を実行するための`oaieval`と、評価のセットを実行するための`oaievalset`です。有効な評価名は`evals/registry/evals`下のYAMLファイルで指定されており、対応する実装は`evals/elsuite`で見つけることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:29:03.774758Z",
     "start_time": "2024-03-18T07:26:29.321664Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install evals --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`oaieval` CLIは、デフォルトの動作を変更するために様々なフラグを受け入れることができます。`oaieval --help`を実行すると、CLIオプションの完全なリストを確認できます。\n",
    "\n",
    "そのコマンドを実行した後、精度の最終レポートがコンソールに出力され、完全なレポートを含む一時ファイルのファイルパスも表示されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`oaieval`は、上記のセル4で指定された形式に従って、`evals/registry/evals`ディレクトリ内の`spider-sql`評価YAMLファイルを検索します。評価データセットへのパスは、評価YAMLファイル内のargs:パラメータの下で`samples_jsonl: sql/spider_sql.jsonl`として指定されており、ファイルの内容はJSONL形式（上記のステップ3で生成されたもの）になっています。\n",
    "\n",
    "そのコマンドを実行すると、精度の最終レポートがコンソールに出力され、完全なレポートを含む一時ファイルへのファイルパスも表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T07:31:42.602736Z",
     "start_time": "2024-03-18T07:29:03.776339Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-26 19:44:39,836] [registry.py:257] Loading registry from /Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry/evals\n",
      "[2024-03-26 19:44:43,623] [registry.py:257] Loading registry from /Users/shyamal/.evals/evals\n",
      "[2024-03-26 19:44:43,635] [oaieval.py:189] \u001b[1;35mRun started: 240327024443FACXGMKA\u001b[0m\n",
      "[2024-03-26 19:44:43,663] [registry.py:257] Loading registry from /Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry/modelgraded\n",
      "[2024-03-26 19:44:43,851] [registry.py:257] Loading registry from /Users/shyamal/.evals/modelgraded\n",
      "[2024-03-26 19:44:43,853] [data.py:90] Fetching /Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry/data/sql/spider_sql.jsonl\n",
      "[2024-03-26 19:44:43,878] [eval.py:36] Evaluating 25 samples\n",
      "[2024-03-26 19:44:43,952] [eval.py:144] Running in threaded mode with 10 threads!\n",
      "  0%|                                                    | 0/25 [00:00<?, ?it/s][2024-03-26 19:44:44,810] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:44,829] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:44,991] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:45,090] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:45,145] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:45,971] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:46,040] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:46,069] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:46,378] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:46,587] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:47,412] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  4%|█▊                                          | 1/25 [00:03<01:23,  3.46s/it][2024-03-26 19:44:47,714] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "  8%|███▌                                        | 2/25 [00:03<00:36,  1.60s/it][2024-03-26 19:44:47,947] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 12%|█████▎                                      | 3/25 [00:03<00:21,  1.02it/s][2024-03-26 19:44:48,413] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:48,643] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 16%|███████                                     | 4/25 [00:04<00:18,  1.15it/s][2024-03-26 19:44:48,909] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|████████▊                                   | 5/25 [00:04<00:12,  1.54it/s][2024-03-26 19:44:49,131] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:49,500] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:49,530] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 24%|██████████▌                                 | 6/25 [00:05<00:12,  1.56it/s][2024-03-26 19:44:49,962] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:49,964] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:49,967] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 28%|████████████▎                               | 7/25 [00:06<00:10,  1.73it/s][2024-03-26 19:44:50,577] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:50,602] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:50,634] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:50,862] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:51,503] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:51,608] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|█████████████████▏                         | 10/25 [00:07<00:08,  1.79it/s][2024-03-26 19:44:51,801] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 44%|██████████████████▉                        | 11/25 [00:07<00:06,  2.09it/s][2024-03-26 19:44:51,856] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:51,969] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:52,227] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 52%|██████████████████████▎                    | 13/25 [00:08<00:04,  2.65it/s][2024-03-26 19:44:52,450] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:52,526] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:52,615] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 56%|████████████████████████                   | 14/25 [00:08<00:04,  2.64it/s][2024-03-26 19:44:52,625] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:52,777] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:53,653] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|█████████████████████████▊                 | 15/25 [00:09<00:05,  1.87it/s][2024-03-26 19:44:53,670] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:54,028] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 68%|█████████████████████████████▏             | 17/25 [00:10<00:03,  2.54it/s][2024-03-26 19:44:54,388] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:54,396] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 72%|██████████████████████████████▉            | 18/25 [00:10<00:02,  2.58it/s][2024-03-26 19:44:54,529] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2024-03-26 19:44:54,585] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 76%|████████████████████████████████▋          | 19/25 [00:10<00:02,  2.94it/s][2024-03-26 19:44:54,980] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|██████████████████████████████████▍        | 20/25 [00:11<00:01,  2.82it/s][2024-03-26 19:44:55,152] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 84%|████████████████████████████████████       | 21/25 [00:11<00:01,  3.27it/s][2024-03-26 19:44:56,420] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 88%|█████████████████████████████████████▊     | 22/25 [00:12<00:01,  1.75it/s][2024-03-26 19:44:56,984] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 92%|███████████████████████████████████████▌   | 23/25 [00:13<00:01,  1.76it/s][2024-03-26 19:44:57,370] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 96%|█████████████████████████████████████████▎ | 24/25 [00:13<00:00,  1.94it/s][2024-03-26 19:44:59,589] [_client.py:1026] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|███████████████████████████████████████████| 25/25 [00:15<00:00,  1.60it/s]\n",
      "[2024-03-26 19:44:59,607] [record.py:360] Final report: {'counts/Correct': 20, 'counts/Incorrect': 5, 'score': 0.8}. Logged to /tmp/evallogs/240327024443FACXGMKA_gpt-3.5-turbo_spider-sql.jsonl\n",
      "[2024-03-26 19:44:59,608] [oaieval.py:229] Final report:\n",
      "[2024-03-26 19:44:59,608] [oaieval.py:231] counts/Correct: 20\n",
      "[2024-03-26 19:44:59,608] [oaieval.py:231] counts/Incorrect: 5\n",
      "[2024-03-26 19:44:59,608] [oaieval.py:231] score: 0.8\n",
      "[2024-03-26 19:44:59,640] [record.py:349] Logged 75 rows of events to /tmp/evallogs/240327024443FACXGMKA_gpt-3.5-turbo_spider-sql.jsonl: insert_time=27.915ms\n"
     ]
    }
   ],
   "source": [
    "!oaieval gpt-3.5-turbo spider-sql --max_samples 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`oaievalset`はモデル名と評価セット名を期待しており、有効なオプションは`evals/registry/eval_sets`配下のYAMLファイルで指定されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evalログの確認\n",
    "\n",
    "evalログは `/tmp/evallogs` に配置されており、各評価実行ごとに異なるログファイルが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T20:37:01.920497Z",
     "start_time": "2024-03-18T20:37:01.553288Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec</th>\n",
       "      <th>final_report</th>\n",
       "      <th>run_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>type</th>\n",
       "      <th>data</th>\n",
       "      <th>created_by</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'completion_fns': ['gpt-3.5-turbo'], 'eval_name': 'spider-sql.dev.v0', 'base_eval': 'spider-sql', 'split': 'dev', 'run_config': {'completion_fns': ['gpt-3.5-turbo'], 'eval_spec': {'cls': 'evals.elsuite.modelgraded.classify:ModelBasedClassify', 'registry_path': '/Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry', 'args': {'samples_jsonl': 'sql/spider_sql.jsonl', 'eval_type': 'cot_classify', 'modelgraded_spec': 'sql'}, 'key': 'spider-sql.dev.v0', 'group': 'sql'}, 'seed': 20220722, 'max_samples': 25, 'command': '/Users/shyamal/.virtualenvs/openai/bin/oaieval gpt-3.5-turbo spider-sql --max_samples 25', 'initial_settings': {'visible': False}}, 'created_by': '', 'run_id': '240327024443FACXGMKA', 'created_at': '2024-03-27 02:44:43.626043'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'counts/Correct': 20, 'counts/Incorrect': 5, 'score': 0.8}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240327024443FACXGMKA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>spider-sql.dev.88</td>\n",
       "      <td>sampling</td>\n",
       "      <td>{'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\n",
       "Table: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\n",
       "Table: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\n",
       "\n",
       "Question: Find the average rank of winners in all matches.\n",
       "', 'role': 'system'}], 'sampled': ['SELECT AVG(winner_rank) AS average_rank_of_winners\n",
       "FROM matches;']}</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-27 02:44:44.821110+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240327024443FACXGMKA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spider-sql.dev.82</td>\n",
       "      <td>sampling</td>\n",
       "      <td>{'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\n",
       "Table: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\n",
       "Table: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\n",
       "\n",
       "Question: Find the total number of matches.\n",
       "', 'role': 'system'}], 'sampled': ['SELECT COUNT(*) AS total_matches\n",
       "FROM matches;']}</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-27 02:44:44.831848+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240327024443FACXGMKA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>spider-sql.dev.25</td>\n",
       "      <td>sampling</td>\n",
       "      <td>{'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: continents. Columns: ContId (number), Continent (text)\n",
       "Table: countries. Columns: CountryId (number), CountryName (text), Continent (number)\n",
       "Table: car_makers. Columns: Id (number), Maker (text), FullName (text), Country (text)\n",
       "Table: model_list. Columns: ModelId (number), Maker (number), Model (text)\n",
       "Table: car_names. Columns: MakeId (number), Model (text), Make (text)\n",
       "Table: cars_data. Columns: Id (number), MPG (text), Cylinders (number), Edispl (number), Horsepower (text), Weight (number), Accelerate (number), Year (number)\n",
       "\n",
       "Question: How many countries exist?\n",
       "', 'role': 'system'}], 'sampled': ['SELECT COUNT(*) AS TotalCountries\n",
       "FROM countries;']}</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-27 02:44:44.996647+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   spec  \\\n",
       "0  {'completion_fns': ['gpt-3.5-turbo'], 'eval_name': 'spider-sql.dev.v0', 'base_eval': 'spider-sql', 'split': 'dev', 'run_config': {'completion_fns': ['gpt-3.5-turbo'], 'eval_spec': {'cls': 'evals.elsuite.modelgraded.classify:ModelBasedClassify', 'registry_path': '/Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry', 'args': {'samples_jsonl': 'sql/spider_sql.jsonl', 'eval_type': 'cot_classify', 'modelgraded_spec': 'sql'}, 'key': 'spider-sql.dev.v0', 'group': 'sql'}, 'seed': 20220722, 'max_samples': 25, 'command': '/Users/shyamal/.virtualenvs/openai/bin/oaieval gpt-3.5-turbo spider-sql --max_samples 25', 'initial_settings': {'visible': False}}, 'created_by': '', 'run_id': '240327024443FACXGMKA', 'created_at': '2024-03-27 02:44:43.626043'}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "                                                  final_report  \\\n",
       "0                                                          NaN   \n",
       "1  {'counts/Correct': 20, 'counts/Incorrect': 5, 'score': 0.8}   \n",
       "2                                                          NaN   \n",
       "3                                                          NaN   \n",
       "4                                                          NaN   \n",
       "\n",
       "                 run_id  event_id          sample_id      type  \\\n",
       "0                   NaN       NaN                NaN       NaN   \n",
       "1                   NaN       NaN                NaN       NaN   \n",
       "2  240327024443FACXGMKA       0.0  spider-sql.dev.88  sampling   \n",
       "3  240327024443FACXGMKA       1.0  spider-sql.dev.82  sampling   \n",
       "4  240327024443FACXGMKA       2.0  spider-sql.dev.25  sampling   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           data  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN   \n",
       "2  {'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\n",
       "Table: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\n",
       "Table: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\n",
       "\n",
       "Question: Find the average rank of winners in all matches.\n",
       "', 'role': 'system'}], 'sampled': ['SELECT AVG(winner_rank) AS average_rank_of_winners\n",
       "FROM matches;']}   \n",
       "3                                   {'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\n",
       "Table: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\n",
       "Table: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\n",
       "\n",
       "Question: Find the total number of matches.\n",
       "', 'role': 'system'}], 'sampled': ['SELECT COUNT(*) AS total_matches\n",
       "FROM matches;']}   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                   {'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: continents. Columns: ContId (number), Continent (text)\n",
       "Table: countries. Columns: CountryId (number), CountryName (text), Continent (number)\n",
       "Table: car_makers. Columns: Id (number), Maker (text), FullName (text), Country (text)\n",
       "Table: model_list. Columns: ModelId (number), Maker (number), Model (text)\n",
       "Table: car_names. Columns: MakeId (number), Model (text), Make (text)\n",
       "Table: cars_data. Columns: Id (number), MPG (text), Cylinders (number), Edispl (number), Horsepower (text), Weight (number), Accelerate (number), Year (number)\n",
       "\n",
       "Question: How many countries exist?\n",
       "', 'role': 'system'}], 'sampled': ['SELECT COUNT(*) AS TotalCountries\n",
       "FROM countries;']}   \n",
       "\n",
       "  created_by                       created_at  \n",
       "0        NaN                              NaT  \n",
       "1        NaN                              NaT  \n",
       "2            2024-03-27 02:44:44.821110+00:00  \n",
       "3            2024-03-27 02:44:44.831848+00:00  \n",
       "4            2024-03-27 02:44:44.996647+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_name = '240327024443FACXGMKA_gpt-3.5-turbo_spider-sql.jsonl' # \"EDIT THIS\" - copy from above\n",
    "events = f\"/tmp/evallogs/{log_name}\"\n",
    "display(pd.read_json(events, lines=True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# processing the log events generated by oaieval\n",
    "\n",
    "with open(events, \"r\") as f:\n",
    "    events_df = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このファイルには評価の構造化されたログが含まれます。最初のエントリでは、完了関数、評価名、実行設定、作成者名、実行ID、作成タイムスタンプを含む評価の詳細な仕様が提供されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_fns': ['gpt-3.5-turbo'],\n",
       " 'eval_name': 'spider-sql.dev.v0',\n",
       " 'base_eval': 'spider-sql',\n",
       " 'split': 'dev',\n",
       " 'run_config': {'completion_fns': ['gpt-3.5-turbo'],\n",
       "  'eval_spec': {'cls': 'evals.elsuite.modelgraded.classify:ModelBasedClassify',\n",
       "   'registry_path': '/Users/shyamal/.virtualenvs/openai/lib/python3.11/site-packages/evals/registry',\n",
       "   'args': {'samples_jsonl': 'sql/spider_sql.jsonl',\n",
       "    'eval_type': 'cot_classify',\n",
       "    'modelgraded_spec': 'sql'},\n",
       "   'key': 'spider-sql.dev.v0',\n",
       "   'group': 'sql'},\n",
       "  'seed': 20220722,\n",
       "  'max_samples': 25,\n",
       "  'command': '/Users/shyamal/.virtualenvs/openai/bin/oaieval gpt-3.5-turbo spider-sql --max_samples 25',\n",
       "  'initial_settings': {'visible': False}},\n",
       " 'created_by': '',\n",
       " 'run_id': '240327024443FACXGMKA',\n",
       " 'created_at': '2024-03-27 02:44:43.626043'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(events_df.iloc[0].spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価の最終レポートを提供するエントリも見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counts/Correct': 20, 'counts/Incorrect': 5, 'score': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(events_df.dropna(subset=['final_report']).iloc[0]['final_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特定のサンプル（`sample_id`）、結果、イベントタイプ、メタデータを提供する個別の評価イベントも確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                240327024443FACXGMKA\n",
       "event_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               0.0\n",
       "sample_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                spider-sql.dev.88\n",
       "type                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              sampling\n",
       "data          {'prompt': [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\n",
       "Use only the following tables and columns:\n",
       "Table: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\n",
       "Table: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\n",
       "Table: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\n",
       "\n",
       "Question: Find the average rank of winners in all matches.\n",
       "', 'role': 'system'}], 'sampled': ['SELECT AVG(winner_rank) AS average_rank_of_winners\n",
       "FROM matches;']}\n",
       "created_at                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2024-03-27 02:44:44.821110+00:00\n",
       "Name: 2, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # None means no truncation\n",
    "display(events_df.iloc[2][['run_id', 'event_id', 'sample_id', 'type', 'data', 'created_at']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\\nUse only the following tables and columns:\\nTable: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\\nTable: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\\nTable: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\\n\\nQuestion: Find the average rank of winners in all matches.\\n', 'role': 'system'}]\n",
      "Sampled: ['SELECT AVG(winner_rank) AS average_rank_of_winners\\nFROM matches;']\n",
      "----------\n",
      "Prompt: [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\\nUse only the following tables and columns:\\nTable: players. Columns: player_id (number), first_name (text), last_name (text), hand (text), birth_date (time), country_code (text)\\nTable: matches. Columns: best_of (number), draw_size (number), loser_age (number), loser_entry (text), loser_hand (text), loser_ht (number), loser_id (number), loser_ioc (text), loser_name (text), loser_rank (number), loser_rank_points (number), loser_seed (number), match_num (number), minutes (number), round (text), score (text), surface (text), tourney_date (time), tourney_id (text), tourney_level (text), tourney_name (text), winner_age (number), winner_entry (text), winner_hand (text), winner_ht (number), winner_id (number), winner_ioc (text), winner_name (text), winner_rank (number), winner_rank_points (number), winner_seed (number), year (number)\\nTable: rankings. Columns: ranking_date (time), ranking (number), player_id (number), ranking_points (number), tours (number)\\n\\nQuestion: Find the total number of matches.\\n', 'role': 'system'}]\n",
      "Sampled: ['SELECT COUNT(*) AS total_matches\\nFROM matches;']\n",
      "----------\n",
      "Prompt: [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\\nUse only the following tables and columns:\\nTable: continents. Columns: ContId (number), Continent (text)\\nTable: countries. Columns: CountryId (number), CountryName (text), Continent (number)\\nTable: car_makers. Columns: Id (number), Maker (text), FullName (text), Country (text)\\nTable: model_list. Columns: ModelId (number), Maker (number), Model (text)\\nTable: car_names. Columns: MakeId (number), Model (text), Make (text)\\nTable: cars_data. Columns: Id (number), MPG (text), Cylinders (number), Edispl (number), Horsepower (text), Weight (number), Accelerate (number), Year (number)\\n\\nQuestion: How many countries exist?\\n', 'role': 'system'}]\n",
      "Sampled: ['SELECT COUNT(*) AS TotalCountries\\nFROM countries;']\n",
      "----------\n",
      "Prompt: [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\\nUse only the following tables and columns:\\nTable: TV_Channel. Columns: id (text), series_name (text), Country (text), Language (text), Content (text), Pixel_aspect_ratio_PAR (text), Hight_definition_TV (text), Pay_per_view_PPV (text), Package_Option (text)\\nTable: TV_series. Columns: id (number), Episode (text), Air_Date (text), Rating (text), Share (number), 18_49_Rating_Share (text), Viewers_m (text), Weekly_Rank (number), Channel (text)\\nTable: Cartoon. Columns: id (number), Title (text), Directed_by (text), Written_by (text), Original_air_date (text), Production_code (number), Channel (text)\\n\\nQuestion: What is the name and directors of all the cartoons that are ordered by air date?\\n', 'role': 'system'}]\n",
      "Sampled: ['SELECT Title, Directed_by\\nFROM Cartoon\\nORDER BY Original_air_date;']\n",
      "----------\n",
      "Prompt: [{'content': 'Answer the following question with syntactically correct SQLite SQL. Be creative but the SQL must be correct.\\nUse only the following tables and columns:\\nTable: stadium. Columns: Stadium_ID (number), Location (text), Name (text), Capacity (number), Highest (number), Lowest (number), Average (number)\\nTable: singer. Columns: Singer_ID (number), Name (text), Country (text), Song_Name (text), Song_release_year (text), Age (number), Is_male (others)\\nTable: concert. Columns: concert_ID (number), concert_Name (text), Theme (text), Stadium_ID (text), Year (text)\\nTable: singer_in_concert. Columns: concert_ID (number), Singer_ID (text)\\n\\nQuestion: Show the name and the release year of the song by the youngest singer.\\n', 'role': 'system'}]\n",
      "Sampled: ['```sql\\nSELECT s.Name, s.Song_release_year\\nFROM singer s\\nWHERE s.Age = (SELECT MIN(Age) FROM singer)\\n```']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Inspect samples\n",
    "for i, row in events_df[events_df['type'] == 'sampling'].head(5).iterrows():\n",
    "    data = pd.json_normalize(row['data'])\n",
    "    print(f\"Prompt: {data['prompt'].iloc[0]}\")\n",
    "    print(f\"Sampled: {data['sampled'].iloc[0]}\")\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストが成功しなかった原因を理解するために、失敗を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_text(prompt):\n",
    "    # Define markers for the sections\n",
    "    markers = {\n",
    "        \"question\": \"[Question]:\",\n",
    "        \"expert\": \"[Expert]:\",\n",
    "        \"submission\": \"[Submission]:\",\n",
    "        \"end\": \"[END DATA]\"\n",
    "    }\n",
    "    \n",
    "    # Function to extract text between markers\n",
    "    def extract_text(start_marker, end_marker):\n",
    "        start = prompt.find(start_marker) + len(start_marker)\n",
    "        end = prompt.find(end_marker)\n",
    "        text = prompt[start:end].strip()\n",
    "        if start_marker == markers[\"question\"]:\n",
    "            text = text.split(\"\\n\\nQuestion:\")[-1].strip() if \"\\n\\nQuestion:\" in text else text\n",
    "        elif start_marker == markers[\"submission\"]:\n",
    "            text = text.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "        return text\n",
    "    \n",
    "    # Extracting text for each section\n",
    "    question_text = extract_text(markers[\"question\"], markers[\"expert\"])\n",
    "    expert_text = extract_text(markers[\"expert\"], markers[\"submission\"])\n",
    "    submission_text = extract_text(markers[\"submission\"], markers[\"end\"])\n",
    "    \n",
    "    # HTML color codes and formatting\n",
    "    colors = {\n",
    "        \"question\": '<span style=\"color: #0000FF;\">QUESTION:<br>', \n",
    "        \"expert\": '<span style=\"color: #008000;\">EXPECTED:<br>',  \n",
    "        \"submission\": '<span style=\"color: #FFA500;\">SUBMISSION:<br>' \n",
    "    }\n",
    "    color_end = '</span>'\n",
    "    \n",
    "    # Display each section with color\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"{colors['question']}{question_text}{color_end}\"))\n",
    "    display(HTML(f\"{colors['expert']}{expert_text}{color_end}\"))\n",
    "    display(HTML(f\"{colors['submission']}{submission_text}{color_end}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: #0000FF;\">QUESTION:<br>How many countries have a republic as their form of government?\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #008000;\">EXPECTED:<br>SELECT count(*) FROM country WHERE GovernmentForm  =  \"Republic\"\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #FFA500;\">SUBMISSION:<br>SELECT COUNT(*) \n",
       "FROM country \n",
       "WHERE GovernmentForm LIKE '%Republic%'\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #0000FF;\">QUESTION:<br>Return the document id, template id, and description for the document with the name Robbin CV.\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #008000;\">EXPECTED:<br>SELECT document_id ,  template_id ,  Document_Description FROM Documents WHERE document_name  =  \"Robbin CV\"\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #FFA500;\">SUBMISSION:<br>SELECT Documents.Document_ID, Documents.Template_ID, Documents.Document_Description\n",
       "FROM Documents\n",
       "JOIN Templates ON Documents.Template_ID = Templates.Template_ID\n",
       "WHERE Documents.Document_Name = 'Robbin CV';\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #0000FF;\">QUESTION:<br>Which professionals live in the state of Indiana or have done treatment on more than 2 treatments? List his or her id, last name and cell phone.\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #008000;\">EXPECTED:<br>SELECT professional_id ,  last_name ,  cell_number FROM Professionals WHERE state  =  'Indiana' UNION SELECT T1.professional_id ,  T1.last_name ,  T1.cell_number FROM Professionals AS T1 JOIN Treatments AS T2 ON T1.professional_id  =  T2.professional_id GROUP BY T1.professional_id HAVING count(*)  >  2\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #FFA500;\">SUBMISSION:<br>SELECT professional_id, last_name, cell_number\n",
       "FROM Professionals\n",
       "WHERE state = 'Indiana'\n",
       "OR professional_id IN (\n",
       "    SELECT professional_id\n",
       "    FROM Treatments\n",
       "    GROUP BY professional_id\n",
       "    HAVING COUNT(*) > 2\n",
       ");\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #0000FF;\">QUESTION:<br>What is the continent name which Anguilla belongs to?\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #008000;\">EXPECTED:<br>SELECT Continent FROM country WHERE Name  =  \"Anguilla\"\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #FFA500;\">SUBMISSION:<br>SELECT c.Continent\n",
       "FROM country c\n",
       "WHERE c.Code = 'AIA';\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #0000FF;\">QUESTION:<br>How many airlines do we have?\n",
       "\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #008000;\">EXPECTED:<br>SELECT count(*) FROM AIRLINES\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: #FFA500;\">SUBMISSION:<br>SELECT COUNT(DISTINCT Airline) AS TotalAirlines\n",
       "FROM airlines;\n",
       "************</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect metrics where choice is made and print only the prompt, result, and expected result if the choice is incorrect\n",
    "for i, row in events_df[events_df['type'] == 'metrics'].iterrows():\n",
    "    if row['data']['choice'] == 'Incorrect':\n",
    "        # Get the previous row's data, which contains the prompt and the expected result\n",
    "        prev_row = events_df.iloc[i-1]\n",
    "        prompt = prev_row['data']['prompt'][0]['content'] if 'prompt' in prev_row['data'] and len(prev_row['data']['prompt']) > 0 else \"Prompt not available\"\n",
    "        expected_result = prev_row['data'].get('ideal', 'Expected result not provided')\n",
    "        \n",
    "        # Current row's data will be the actual result\n",
    "        result = row['data'].get('result', 'Actual result not provided')\n",
    "        \n",
    "        pretty_print_text(prompt)\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "発生している失敗例を確認すると、以下のことがわかります：\n",
    "* 2番目の不正解では、'Templates'テーブルとの不要な結合がありました。我々の評価システムはこれを正確に識別し、不正解としてフラグを立てることができました。\n",
    "* その他のいくつかの回答では、軽微な構文の違いが原因で不正解としてフラグが立てられました。\n",
    "  * このような状況では、特定のスタイル選択を確実にするためにプロンプトの反復を続けるべきか、それとも評価スイートを修正してこの変動を捉えるべきかを検討する価値があります。\n",
    "  * この種の失敗は、結果の採点精度を確保する方法として、モデルによる評価の潜在的な必要性を示唆しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "効果的なevalsの構築は、LLMベースのアプリケーションの開発サイクルにおける中核的な部分です。OpenAI Evalsフレームワークは、すぐに使えるevalsを構築するための基本構造を提供し、様々なユースケースに対して新しいテストを素早く立ち上げることを可能にします。このガイドでは、evalを作成し、実行し、結果を分析する方法をステップバイステップで実演しました。\n",
    "\n",
    "このガイドで示した例は、evalsの直接的なユースケースを表しています。このフレームワークを引き続き探求する際は、実際の本番環境のユースケースに向けて、より複雑なモデル評価型evalsの作成を探求することをお勧めします。評価を楽しんでください！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
