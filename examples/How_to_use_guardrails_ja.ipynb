{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea66173",
   "metadata": {},
   "source": [
    "# ガードレールの使用方法\n",
    "\n",
    "このノートブックでは、LLMアプリケーションにガードレールを実装する方法の例を紹介します。ガードレールは、アプリケーションを適切な方向に導くことを目的とした**検出制御**の総称です。LLMに固有のランダム性を考慮すると、より高い制御性は一般的な要件であり、効果的なガードレールの作成は、LLMをプロトタイプから本番環境に移行する際の最も一般的なパフォーマンス最適化領域の一つとなっています。\n",
    "\n",
    "ガードレールは非常に[多様](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/README.md)で、LLMで問題が発生する可能性があると想像できるほぼすべてのコンテキストに展開できます。このノートブックは、あなた独自のユースケースに合わせて拡張できる簡単な例を提供し、ガードレールを実装するかどうかを決定する際に考慮すべきトレードオフと、その実装方法を概説することを目的としています。\n",
    "\n",
    "このノートブックでは以下に焦点を当てます：\n",
    "1. **入力ガードレール** - 不適切なコンテンツがLLMに到達する前にフラグを立てる\n",
    "2. **出力ガードレール** - LLMが生成したものが顧客に届く前に検証する\n",
    "\n",
    "**注意：** このノートブックでは、ガードレールをLLM周辺の検出制御の総称として扱います。事前構築されたガードレールフレームワークの配布を提供する公式ライブラリについては、以下をご確認ください：\n",
    "- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails/tree/main)\n",
    "- [Guardrails AI](https://github.com/ShreyaR/guardrails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef059e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "GPT_MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d917f0",
   "metadata": {},
   "source": [
    "## 1. 入力ガードレール\n",
    "\n",
    "入力ガードレールは、不適切なコンテンツがLLMに到達することを最初から防ぐことを目的としています。一般的な使用例は以下の通りです：\n",
    "- **トピック別ガードレール：** ユーザーがトピック外の質問をした場合を特定し、LLMがサポートできるトピックについてアドバイスを提供します。\n",
    "- **ジェイルブレイキング：** ユーザーがLLMを乗っ取り、そのプロンプトを上書きしようとしている場合を検出します。\n",
    "- **プロンプトインジェクション：** ユーザーがLLMが実行する下流の関数で実行される悪意のあるコードを隠そうとするプロンプトインジェクションのインスタンスを検出します。\n",
    "\n",
    "これらすべてにおいて、予防的制御として機能し、LLMの前または並行して実行され、これらの基準のいずれかが満たされた場合にアプリケーションが異なる動作をするようトリガーします。\n",
    "\n",
    "### ガードレールの設計\n",
    "\n",
    "ガードレールを設計する際は、**精度**、**レイテンシ**、**コスト**のトレードオフを考慮することが重要です。ここでは、収益とユーザーエクスペリエンスへの影響を最小限に抑えながら、最大の精度を達成することを目指します。\n",
    "\n",
    "まず、トピック外の質問を検出し、トリガーされた場合にLLMが回答することを防ぐことを目的とした、シンプルな**トピック別ガードレール**から始めます。このガードレールはシンプルなプロンプトで構成され、`gpt-4o-mini`を使用してレイテンシ/コストを最大化しながら十分な精度を保持しますが、さらに最適化したい場合は以下を検討できます：\n",
    "- **精度：** `gpt-4o-mini`のファインチューニングやfew-shotの例を検討して精度を向上させることができます。コンテンツが許可されているかどうかを判断するのに役立つ情報のコーパスがある場合、RAGも効果的です。\n",
    "- **レイテンシ/コスト：** `babbage-002`やLlamaなどのオープンソースの提供物など、より小さなモデルのファインチューニングを試すことができます。これらは十分な訓練例が与えられた場合、非常に良いパフォーマンスを発揮できます。オープンソースの提供物を使用する場合、推論に使用するマシンを調整して、コストまたはレイテンシの削減のいずれかを最大化することもできます。\n",
    "\n",
    "このシンプルなガードレールは、LLMが事前定義されたトピックセットにのみ回答し、範囲外のクエリには定型メッセージで応答することを確実にすることを目的としています。\n",
    "\n",
    "### 非同期の活用\n",
    "\n",
    "レイテンシを最小化する一般的な設計は、メインのLLM呼び出しと並行してガードレールを非同期で送信することです。ガードレールがトリガーされた場合はその応答を返し、そうでなければLLMの応答を返します。\n",
    "\n",
    "このアプローチを使用して、LLMの`get_chat_response`と`topical_guardrail`ガードレールを並行して実行し、ガードレールが`allowed`を返す場合のみLLMの応答を返す`execute_chat_with_guardrails`関数を作成します。\n",
    "\n",
    "### 制限事項\n",
    "\n",
    "設計を開発する際は、常にガードレールの制限事項を考慮する必要があります。認識すべき主要な制限事項は以下の通りです：\n",
    "- LLMをガードレールとして使用する場合、ベースのLLM呼び出し自体と同じ脆弱性を持つことに注意してください。例えば、**プロンプトインジェクション**の試みは、ガードレールと実際のLLM呼び出しの両方を回避することに成功する可能性があります。\n",
    "- 会話が長くなるにつれて、指示が追加のテキストによって希釈されるため、LLMは**ジェイルブレイキング**により影響を受けやすくなります。\n",
    "- 上記の問題を補償するためにガードレールを過度に制限的にすると、ユーザーエクスペリエンスを損なう可能性があります。これは**過度の拒否**として現れ、プロンプトインジェクションやジェイルブレイキングの試みとの類似性があるため、ガードレールが無害なユーザーリクエストを拒否します。\n",
    "\n",
    "### 軽減策\n",
    "\n",
    "ガードレールをルールベースまたはより従来の機械学習モデルと組み合わせて検出に使用できれば、これらのリスクの一部を軽減できます。また、長い会話によってモデルが混乱するリスクを軽減するために、最新のメッセージのみを考慮するガードレールを使用している顧客も見てきました。\n",
    "\n",
    "また、プロンプトインジェクションやジェイルブレイキングのインスタンスを検出できるよう、会話の積極的な監視を伴う段階的なロールアウトを行うことをお勧めします。これにより、これらの新しいタイプの行動をカバーするためにより多くのガードレールを追加するか、既存のガードレールの訓練例として含めることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e95efc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "bad_request = \"I want to talk about horses\"\n",
    "good_request = \"What are the best breeds of dog for people that like cats?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fee948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def get_chat_response(user_request):\n",
    "    print(\"Getting LLM response\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=messages, temperature=0.5\n",
    "    )\n",
    "    print(\"Got LLM response\")\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topics are cats and dogs. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=messages, temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "async def execute_chat_with_guardrail(user_request):\n",
    "    topical_guardrail_task = asyncio.create_task(topical_guardrail(user_request))\n",
    "    chat_task = asyncio.create_task(get_chat_response(user_request))\n",
    "\n",
    "    while True:\n",
    "        done, _ = await asyncio.wait(\n",
    "            [topical_guardrail_task, chat_task], return_when=asyncio.FIRST_COMPLETED\n",
    "        )\n",
    "        if topical_guardrail_task in done:\n",
    "            guardrail_response = topical_guardrail_task.result()\n",
    "            if guardrail_response == \"not_allowed\":\n",
    "                chat_task.cancel()\n",
    "                print(\"Topical guardrail triggered\")\n",
    "                return \"I can only talk about cats and dogs, the best animals that ever lived.\"\n",
    "            elif chat_task in done:\n",
    "                chat_response = chat_task.result()\n",
    "                return chat_response\n",
    "        else:\n",
    "            await asyncio.sleep(0.1)  # sleep for a bit before checking the tasks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eba51754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "If you like cats and are considering getting a dog, there are several breeds known for their compatibility with feline friends. Here are some of the best dog breeds that tend to get along well with cats:\n",
      "\n",
      "1. **Golden Retriever**: Friendly and tolerant, Golden Retrievers often get along well with other animals, including cats.\n",
      "\n",
      "2. **Labrador Retriever**: Similar to Golden Retrievers, Labs are social and friendly, making them good companions for cats.\n",
      "\n",
      "3. **Cavalier King Charles Spaniel**: This breed is gentle and affectionate, often forming strong bonds with other pets.\n",
      "\n",
      "4. **Basset Hound**: Basset Hounds are laid-back and generally have a calm demeanor, which can help them coexist peacefully with cats.\n",
      "\n",
      "5. **Beagle**: Beagles are friendly and sociable, and they often enjoy the company of other animals, including cats.\n",
      "\n",
      "6. **Pug**: Pugs are known for their playful and friendly nature, which can make them good companions for cats.\n",
      "\n",
      "7. **Shih Tzu**: Shih Tzus are typically friendly and adaptable, often getting along well with other pets.\n",
      "\n",
      "8. **Collie**: Collies are known for their gentle and protective nature, which can extend to their relationships with cats.\n",
      "\n",
      "9. **Newfoundland**: These gentle giants are known for their calm demeanor and often get along well with other animals.\n",
      "\n",
      "10. **Cocker Spaniel**: Cocker Spaniels are friendly and affectionate dogs that can get along well with cats if introduced properly.\n",
      "\n",
      "When introducing a dog to a cat, it's important to do so gradually and supervise their interactions to ensure a positive relationship. Each dog's personality can vary, so individual temperament is key in determining compatibility.\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with the good request - this should go through\n",
    "response = await execute_chat_with_guardrail(good_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d88b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "Topical guardrail triggered\n",
      "I can only talk about cats and dogs, the best animals that ever lived.\n"
     ]
    }
   ],
   "source": [
    "# Call the main function with the bad request - this should get blocked\n",
    "response = await execute_chat_with_guardrail(bad_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b408e",
   "metadata": {},
   "source": [
    "ガードレールが機能しているようです - 最初の質問は通されましたが、2番目の質問はトピックから外れているためブロックされました。今度はこの概念を拡張して、LLMから得られるレスポンスも同様にモデレートしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af0154",
   "metadata": {},
   "source": [
    "## 2. 出力ガードレール\n",
    "\n",
    "出力ガードレールは、LLMが返す内容を制御します。これらは多くの形態を取ることができ、最も一般的なものには以下があります：\n",
    "\n",
    "- **幻覚/事実確認ガードレール：** 正確な情報のコーパスや幻覚的な応答の訓練セットを使用して、幻覚的な応答をブロックします。\n",
    "- **モデレーションガードレール：** ブランドや企業のガイドラインを適用してLLMの結果をモデレートし、ガイドラインに違反する場合は応答をブロックまたは書き換えます。\n",
    "- **構文チェック：** LLMからの構造化された出力は破損したり、パースできない状態で返される可能性があります - これらのガードレールはそれを検出し、再試行するか適切に失敗し、下流のアプリケーションでの障害を防ぎます。\n",
    "    - これは関数呼び出しで適用される一般的な制御で、LLMが`function_call`を返す際に`arguments`で期待されるスキーマが返されることを保証します。\n",
    "\n",
    "### モデレーションガードレール\n",
    "\n",
    "ここでは、[G-Eval](https://arxiv.org/abs/2303.16634)評価手法のバージョンを使用して、LLMの応答における不要なコンテンツの存在をスコア化する**モデレーションガードレール**を実装します。この手法は、他の[ノートブック](https://github.com/openai/openai-cookbook/blob/main/examples/evaluation/How_to_eval_abstractive_summarization.ipynb)でより詳細に実演されています。\n",
    "\n",
    "これを実現するために、`domain`を受け取り、一連の`steps`を使用して`content`の一部に`criteria`を適用するコンテンツモデレーションのための拡張可能なフレームワークを作成します：\n",
    "\n",
    "1. ドメイン名を設定し、モデレートするコンテンツのタイプを記述します。\n",
    "2. コンテンツに含まれるべきものと含まれるべきでないものを明確に概説する基準を提供します。\n",
    "3. LLMがコンテンツを評価するためのステップバイステップの指示を提供します。\n",
    "4. LLMは1-5の離散的なスコアを返します。\n",
    "\n",
    "### ガードレール閾値の設定\n",
    "\n",
    "私たちの出力ガードレールはLLMの応答を評価し、3以上のスコアのものをブロックします。この閾値の設定は最適化の一般的な領域です - 評価セットを構築し、混同行列を使用して結果を評価し、ガードレールに適切な許容度を設定することをお勧めします。ここでのトレードオフは一般的に以下の通りです：\n",
    "\n",
    "- 偽陽性が多いと、顧客が苛立ち、アシスタントがあまり役に立たないように見える、断片的なユーザー体験につながります。\n",
    "- 偽陰性が多いと、人々がアシスタントに不適切な質問に答えさせたり、プロンプトインジェクション/ジェイルブレイクを行ったりして、ビジネスに永続的な害をもたらす可能性があります。\n",
    "\n",
    "例えば、ジェイルブレイクに対しては非常に低い閾値を設定したい場合があります。なぜなら、LLMがハイジャックされて危険なコンテンツを生成し、それがソーシャルメディアに掲載された場合のビジネスへのリスクが非常に高いからです。しかし、私たちのユースケースでは、いくつかの偽陰性を受け入れる用意があります。最悪の場合でも、誰かがラブラドールの方が適していたかもしれないビション・フリーゼを飼うことになるだけで、悲しいことではありますが、おそらく私たちのビジネスに永続的な損害を与えることはないでしょう（そう願っています）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7b459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"animal breed recommendation\"\n",
    "\n",
    "animal_advice_criteria = \"\"\"\n",
    "Assess the presence of explicit recommendation of cat or dog breeds in the content.\n",
    "The content should contain only general advice about cats and dogs, not specific breeds to purchase.\"\"\"\n",
    "\n",
    "animal_advice_steps = \"\"\"\n",
    "1. Read the content and the criteria carefully.\n",
    "2. Assess how much explicit recommendation of cat or dog breeds is contained in the content.\n",
    "3. Assign an animal advice score from 1 to 5, with 1 being no explicit cat or dog breed advice, and 5 being multiple named cat or dog breeds.\n",
    "\"\"\"\n",
    "\n",
    "moderation_system_prompt = \"\"\"\n",
    "You are a moderation assistant. Your role is to detect content about {domain} in the text provided, and mark the severity of that content.\n",
    "\n",
    "## {domain}\n",
    "\n",
    "### Criteria\n",
    "\n",
    "{scoring_criteria}\n",
    "\n",
    "### Instructions\n",
    "\n",
    "{scoring_steps}\n",
    "\n",
    "### Content\n",
    "\n",
    "{content}\n",
    "\n",
    "### Evaluation (score only!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e3fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def moderation_guardrail(chat_response):\n",
    "    print(\"Checking moderation guardrail\")\n",
    "    mod_messages = [\n",
    "        {\"role\": \"user\", \"content\": moderation_system_prompt.format(\n",
    "            domain=domain,\n",
    "            scoring_criteria=animal_advice_criteria,\n",
    "            scoring_steps=animal_advice_steps,\n",
    "            content=chat_response\n",
    "        )},\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MODEL, messages=mod_messages, temperature=0\n",
    "    )\n",
    "    print(\"Got moderation response\")\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "    \n",
    "async def execute_all_guardrails(user_request):\n",
    "    topical_guardrail_task = asyncio.create_task(topical_guardrail(user_request))\n",
    "    chat_task = asyncio.create_task(get_chat_response(user_request))\n",
    "\n",
    "    while True:\n",
    "        done, _ = await asyncio.wait(\n",
    "            [topical_guardrail_task, chat_task], return_when=asyncio.FIRST_COMPLETED\n",
    "        )\n",
    "        if topical_guardrail_task in done:\n",
    "            guardrail_response = topical_guardrail_task.result()\n",
    "            if guardrail_response == \"not_allowed\":\n",
    "                chat_task.cancel()\n",
    "                print(\"Topical guardrail triggered\")\n",
    "                return \"I can only talk about cats and dogs, the best animals that ever lived.\"\n",
    "            elif chat_task in done:\n",
    "                chat_response = chat_task.result()\n",
    "                moderation_response = await moderation_guardrail(chat_response)\n",
    "\n",
    "                if int(moderation_response) >= 3:\n",
    "                    print(f\"Moderation guardrail flagged with a score of {int(moderation_response)}\")\n",
    "                    return \"Sorry, we're not permitted to give animal breed advice. I can help you with any general queries you might have.\"\n",
    "\n",
    "                else:\n",
    "                    print('Passed moderation')\n",
    "                    return chat_response\n",
    "        else:\n",
    "            await asyncio.sleep(0.1)  # sleep for a bit before checking the tasks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beea1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a request that should pass both our topical guardrail and our moderation guardrail\n",
    "great_request = 'What is some advice you can give to a new dog owner?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c582b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "Checking moderation guardrail\n",
      "Got moderation response\n",
      "Moderation guardrail flagged with a score of 5\n",
      "Sorry, we're not permitted to give animal breed advice. I can help you with any general queries you might have.\n",
      "\n",
      "\n",
      "\n",
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "Topical guardrail triggered\n",
      "I can only talk about cats and dogs, the best animals that ever lived.\n",
      "\n",
      "\n",
      "\n",
      "Checking topical guardrail\n",
      "Got guardrail response\n",
      "Getting LLM response\n",
      "Got LLM response\n",
      "Checking moderation guardrail\n",
      "Got moderation response\n",
      "Moderation guardrail flagged with a score of 3\n",
      "Sorry, we're not permitted to give animal breed advice. I can help you with any general queries you might have.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tests = [good_request,bad_request,great_request]\n",
    "\n",
    "for test in tests:\n",
    "    result = await execute_all_guardrails(test)\n",
    "    print(result)\n",
    "    print('\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763dd2d",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "ガードレールはLLMにおいて活発で進化し続けるトピックであり、このノートブックがガードレールの中核概念について効果的な導入となったことを願っています。要約すると：\n",
    "\n",
    "- ガードレールは、有害なコンテンツがアプリケーションやユーザーに到達することを防ぎ、本番環境でのLLMに操縦性を追加することを目的とした検出制御です。\n",
    "- ガードレールは、LLMに到達する前のコンテンツを対象とする入力ガードレールと、LLMの応答を制御する出力ガードレールの形を取ることができます。\n",
    "- ガードレールの設計と閾値の設定は、精度、レイテンシ、コストの間のトレードオフです。あなたの決定は、ガードレールのパフォーマンスの明確な評価と、偽陰性と偽陽性があなたのビジネスにとってどのようなコストになるかの理解に基づくべきです。\n",
    "- 非同期設計原則を採用することで、ガードレールの数と範囲が増加してもユーザーへの影響を最小限に抑えるために、ガードレールを水平方向にスケールできます。\n",
    "\n",
    "皆さんがこれをどのように発展させ、エコシステムが成熟するにつれてガードレールに関する考え方がどのように進化するかを楽しみにしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7b04d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
