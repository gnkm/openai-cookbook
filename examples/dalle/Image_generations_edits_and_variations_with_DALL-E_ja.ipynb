{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALL·E APIの使用方法\n",
    "\n",
    "このノートブックでは、OpenAIのDALL·E画像APIエンドポイントの使用方法を説明します。\n",
    "\n",
    "3つのAPIエンドポイントがあります：\n",
    "- **Generations:** 入力されたキャプションに基づいて画像を生成する\n",
    "- **Edits:** 既存の画像を編集または拡張する\n",
    "- **Variations:** 入力画像のバリエーションを生成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "- 必要なパッケージをインポートする\n",
    "- OpenAI APIキーをインポートする：ターミナルで \\``export OPENAI_API_KEY=\"your API key\"`\\` を実行することで行えます。\n",
    "- 画像を保存するディレクトリを設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from openai import OpenAI  # OpenAI Python library to make API calls\n",
    "import requests  # used to download images\n",
    "import os  # used to access filepaths\n",
    "from PIL import Image  # used to print and edit images\n",
    "\n",
    "# initialize OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_dir='./images'\n"
     ]
    }
   ],
   "source": [
    "# set a directory to save DALL·E images to\n",
    "image_dir_name = \"images\"\n",
    "image_dir = os.path.join(os.curdir, image_dir_name)\n",
    "\n",
    "# create the directory if it doesn't yet exist\n",
    "if not os.path.isdir(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "# print the directory to save to\n",
    "print(f\"{image_dir=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成\n",
    "\n",
    "生成APIエンドポイントは、テキストプロンプトに基づいて画像を作成します。[APIリファレンス](https://platform.openai.com/docs/api-reference/images/create)\n",
    "\n",
    "**必須入力:**\n",
    "- `prompt` (str): 希望する画像の説明文。最大長はdall-e-2で1000文字、dall-e-3で4000文字です。\n",
    "\n",
    "**オプション入力:**\n",
    "- `model` (str): 画像生成に使用するモデル。デフォルトはdall-e-2\n",
    "- `n` (int): 生成する画像の数。1から10の間である必要があります。デフォルトは1。\n",
    "- `quality` (str): 生成される画像の品質。hdはより細かいディテールと画像全体でのより高い一貫性を持つ画像を作成します。このパラメータはdall-e-3でのみサポートされています。\n",
    "- `response_format` (str): 生成された画像が返される形式。\"url\"または\"b64_json\"のいずれかである必要があります。デフォルトは\"url\"。\n",
    "- `size` (str): 生成される画像のサイズ。dall-e-2では256x256、512x512、または1024x1024のいずれかである必要があります。dall-e-3モデルでは1024x1024、1792x1024、または1024x1792のいずれかである必要があります。デフォルトは\"1024x1024\"。\n",
    "- `style`(str | null): 生成される画像のスタイル。vividまたはnaturalのいずれかである必要があります。vividはモデルがハイパーリアルで劇的な画像の生成に傾くようにします。naturalはモデルがより自然で、ハイパーリアルでない見た目の画像を生成するようにします。このパラメータはdall-e-3でのみサポートされています。\n",
    "- `user` (str): エンドユーザーを表す一意の識別子で、OpenAIが悪用を監視・検出するのに役立ちます。[詳細はこちら。](https://beta.openai.com/docs/usage-policies/end-user-ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagesResponse(created=1701994117, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-9HXYFy8ux4r6aboFyec2OLRf/user-8OA8IvMYkfdAcUZXgzAXHS7d/img-ced13hkOk3lXkccQgW1fAQjm.png?st=2023-12-07T23%3A08%3A37Z&se=2023-12-08T01%3A08%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-07T16%3A41%3A48Z&ske=2023-12-08T16%3A41%3A48Z&sks=b&skv=2021-08-06&sig=tcD0iyU0ABOvWAKsY89gp5hLVIYkoSXQnrcmH%2Brkric%3D')])\n"
     ]
    }
   ],
   "source": [
    "# create an image\n",
    "\n",
    "# set the prompt\n",
    "prompt = \"A cyberpunk monkey hacker dreaming of a beautiful bunch of bananas, digital art\"\n",
    "\n",
    "# call the OpenAI API\n",
    "generation_response = client.images.generate(\n",
    "    model = \"dall-e-3\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\",\n",
    ")\n",
    "\n",
    "# print response\n",
    "print(generation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "generated_image_name = \"generated_image.png\"  # any name you like; the filetype should be .png\n",
    "generated_image_filepath = os.path.join(image_dir, generated_image_name)\n",
    "generated_image_url = generation_response.data[0].url  # extract image URL from response\n",
    "generated_image = requests.get(generated_image_url).content  # download the image\n",
    "\n",
    "with open(generated_image_filepath, \"wb\") as image_file:\n",
    "    image_file.write(generated_image)  # write the image to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the image\n",
    "print(generated_image_filepath)\n",
    "display(Image.open(generated_image_filepath))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バリエーション\n",
    "\n",
    "バリエーションエンドポイントは、入力画像に類似した新しい画像（バリエーション）を生成します。[API Reference](https://platform.openai.com/docs/api-reference/images/createVariation)\n",
    "\n",
    "ここでは、上記で生成した画像のバリエーションを生成します。\n",
    "\n",
    "**必須入力項目：**\n",
    "- `image` (str): バリエーションの基礎として使用する画像。有効なPNGファイルで、4MB未満、正方形である必要があります。\n",
    "\n",
    "**オプション入力項目：**\n",
    "- `model` (str): 画像バリエーションに使用するモデル。現在はdall-e-2のみサポートされています。\n",
    "- `n` (int): 生成する画像の数。1から10の間である必要があります。デフォルトは1です。\n",
    "- `size` (str): 生成される画像のサイズ。\"256x256\"、\"512x512\"、または\"1024x1024\"のいずれかである必要があります。小さい画像の方が高速です。デフォルトは\"1024x1024\"です。\n",
    "- `response_format` (str): 生成された画像が返される形式。\"url\"または\"b64_json\"のいずれかである必要があります。デフォルトは\"url\"です。\n",
    "- `user` (str): エンドユーザーを表す一意の識別子で、OpenAIが悪用を監視・検出するのに役立ちます。[詳細はこちら。](https://beta.openai.com/docs/usage-policies/end-user-ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagesResponse(created=1701994139, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-9HXYFy8ux4r6aboFyec2OLRf/user-8OA8IvMYkfdAcUZXgzAXHS7d/img-noNRGgwaaotRGIe6Y2GVeSpr.png?st=2023-12-07T23%3A08%3A59Z&se=2023-12-08T01%3A08%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-07T16%3A39%3A11Z&ske=2023-12-08T16%3A39%3A11Z&sks=b&skv=2021-08-06&sig=ER5RUglhtIk9LWJXw1DsolorT4bnEmFostfnUjY21ns%3D'), Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-9HXYFy8ux4r6aboFyec2OLRf/user-8OA8IvMYkfdAcUZXgzAXHS7d/img-oz952tL11FFhf9iXXJVIRUZX.png?st=2023-12-07T23%3A08%3A59Z&se=2023-12-08T01%3A08%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-07T16%3A39%3A11Z&ske=2023-12-08T16%3A39%3A11Z&sks=b&skv=2021-08-06&sig=99rJOQwDKsfIeerlMXMHholhAhrHfYaQRFJBF8FKv74%3D')])\n"
     ]
    }
   ],
   "source": [
    "# create variations\n",
    "\n",
    "# call the OpenAI API, using `create_variation` rather than `create`\n",
    "variation_response = client.images.create_variation(\n",
    "    image=generated_image,  # generated_image is the image generated above\n",
    "    n=2,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\",\n",
    ")\n",
    "\n",
    "# print response\n",
    "print(variation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the images\n",
    "variation_urls = [datum.url for datum in variation_response.data]  # extract URLs\n",
    "variation_images = [requests.get(url).content for url in variation_urls]  # download images\n",
    "variation_image_names = [f\"variation_image_{i}.png\" for i in range(len(variation_images))]  # create names\n",
    "variation_image_filepaths = [os.path.join(image_dir, name) for name in variation_image_names]  # create filepaths\n",
    "for image, filepath in zip(variation_images, variation_image_filepaths):  # loop through the variations\n",
    "    with open(filepath, \"wb\") as image_file:  # open the file\n",
    "        image_file.write(image)  # write the image to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the original image\n",
    "print(generated_image_filepath)\n",
    "display(Image.open(generated_image_filepath))\n",
    "\n",
    "# print the new variations\n",
    "for variation_image_filepaths in variation_image_filepaths:\n",
    "    print(variation_image_filepaths)\n",
    "    display(Image.open(variation_image_filepaths))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編集\n",
    "\n",
    "編集エンドポイントはDALL·Eを使用して、既存の画像の指定された部分を生成します。3つの入力が必要です：編集する画像、再生成する部分を指定するマスク、および希望する画像を説明するプロンプトです。[API Reference](https://platform.openai.com/docs/api-reference/images/createEdit)\n",
    "\n",
    "**必須入力：**\n",
    "- `image` (str): 編集する画像。有効なPNGファイルで、4MB未満、正方形である必要があります。マスクが提供されない場合、画像は透明度を持つ必要があり、それがマスクとして使用されます。\n",
    "- `prompt` (str): 希望する画像の文字による説明。最大長は1000文字です。\n",
    "\n",
    "**オプション入力：**\n",
    "- `mask` (file): 完全に透明な領域（例：アルファ値がゼロの箇所）が画像を編集すべき場所を示す追加画像。有効なPNGファイルで、4MB未満、かつ画像と同じ寸法である必要があります。\n",
    "- `model` (str): 画像編集に使用するモデル。現在はdall-e-2のみサポートされています。\n",
    "- `n` (int): 生成する画像の数。1から10の間である必要があります。デフォルトは1です。\n",
    "- `size` (str): 生成される画像のサイズ。\"256x256\"、\"512x512\"、または\"1024x1024\"のいずれかである必要があります。小さい画像の方が高速です。デフォルトは\"1024x1024\"です。\n",
    "- `response_format` (str): 生成された画像が返される形式。\"url\"または\"b64_json\"のいずれかである必要があります。デフォルトは\"url\"です。\n",
    "- `user` (str): エンドユーザーを表すユニークな識別子で、OpenAIが悪用を監視・検出するのに役立ちます。[詳細はこちら。](https://beta.openai.com/docs/usage-policies/end-user-ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編集エリアの設定\n",
    "\n",
    "編集には、画像のどの部分を再生成するかを指定する「マスク」が必要です。アルファ値が0（透明）のピクセルが再生成されます。以下のコードは、下半分が透明な1024x1024のマスクを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask\n",
    "width = 1024\n",
    "height = 1024\n",
    "mask = Image.new(\"RGBA\", (width, height), (0, 0, 0, 1))  # create an opaque image mask\n",
    "\n",
    "# set the bottom half to be transparent\n",
    "for x in range(width):\n",
    "    for y in range(height // 2, height):  # only loop over the bottom half of the mask\n",
    "        # set alpha (A) to zero to turn pixel transparent\n",
    "        alpha = 0\n",
    "        mask.putpixel((x, y), (0, 0, 0, alpha))\n",
    "\n",
    "# save the mask\n",
    "mask_name = \"bottom_half_mask.png\"\n",
    "mask_filepath = os.path.join(image_dir, mask_name)\n",
    "mask.save(mask_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編集の実行\n",
    "\n",
    "次に、画像、キャプション、マスクをAPIに提供して、画像の編集例を5つ取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImagesResponse(created=1701994167, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-9HXYFy8ux4r6aboFyec2OLRf/user-8OA8IvMYkfdAcUZXgzAXHS7d/img-9UOVGC7wB8MS2Q7Rwgj0fFBq.png?st=2023-12-07T23%3A09%3A27Z&se=2023-12-08T01%3A09%3A27Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-07T16%3A40%3A37Z&ske=2023-12-08T16%3A40%3A37Z&sks=b&skv=2021-08-06&sig=MsRMZ1rN434bVdWr%2B9kIoqu9CIrvZypZBfkQPTOhCl4%3D')])\n"
     ]
    }
   ],
   "source": [
    "# edit an image\n",
    "\n",
    "# call the OpenAI API\n",
    "edit_response = client.images.edit(\n",
    "    image=open(generated_image_filepath, \"rb\"),  # from the generation section\n",
    "    mask=open(mask_filepath, \"rb\"),  # from right above\n",
    "    prompt=prompt,  # from the generation section\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\",\n",
    ")\n",
    "\n",
    "# print response\n",
    "print(edit_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "edited_image_name = \"edited_image.png\"  # any name you like; the filetype should be .png\n",
    "edited_image_filepath = os.path.join(image_dir, edited_image_name)\n",
    "edited_image_url = edit_response.data[0].url  # extract image URL from response\n",
    "edited_image = requests.get(edited_image_url).content  # download the image\n",
    "\n",
    "with open(edited_image_filepath, \"wb\") as image_file:\n",
    "    image_file.write(edited_image)  # write the image to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the original image\n",
    "print(generated_image_filepath)\n",
    "display(Image.open(generated_image_filepath))\n",
    "\n",
    "# print edited image\n",
    "print(edited_image_filepath)\n",
    "display(Image.open(edited_image_filepath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
