{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エージェントのオーケストレーション: ルーチンとハンドオフ\n",
    "\n",
    "言語モデルを扱う際、多くの場合、優れたパフォーマンスを得るために必要なのは適切なプロンプトと正しいツールだけです。しかし、多くの独特なフローを扱う場合、事態は複雑になることがあります。このクックブックでは、この問題に取り組む一つの方法を説明します。\n",
    "\n",
    "**ルーチン**と**ハンドオフ**の概念を紹介し、その実装について説明し、シンプルで強力かつ制御可能な方法で複数のエージェントをオーケストレーションする方法を示します。\n",
    "\n",
    "最後に、これらのアイデアを実装したサンプルリポジトリ[Swarm](https://github.com/openai/swarm)を例とともに提供します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インポートの設定から始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ルーチン\n",
    "\n",
    "「ルーチン」という概念は厳密に定義されているわけではなく、むしろ一連のステップの考え方を捉えることを意図しています。具体的には、ルーチンを自然言語での指示のリスト（システムプロンプトで表現します）と、それらを完了するために必要なツールとして定義しましょう。\n",
    "\n",
    "例を見てみましょう。以下では、カスタマーサービスエージェント向けのルーチンを定義し、ユーザーの問題をトリアージし、修正案を提案するか返金を提供するよう指示しています。また、必要な関数である`execute_refund`と`look_up_item`も定義しています。これをカスタマーサービスルーチン、エージェント、アシスタントなどと呼ぶことができますが、考え方自体は同じです：一連のステップとそれらを実行するためのツールです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Service Routine\n",
    "\n",
    "system_message = (\n",
    "    \"You are a customer support agent for ACME Inc.\"\n",
    "    \"Always answer in a sentence or less.\"\n",
    "    \"Follow the following routine with the user:\"\n",
    "    \"1. First, ask probing questions and understand the user's problem deeper.\\n\"\n",
    "    \" - unless the user has already provided a reason.\\n\"\n",
    "    \"2. Propose a fix (make one up).\\n\"\n",
    "    \"3. ONLY if not satisfied, offer a refund.\\n\"\n",
    "    \"4. If accepted, search for the ID and then execute refund.\"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "def look_up_item(search_query):\n",
    "    \"\"\"Use to find item ID.\n",
    "    Search query can be a description or keywords.\"\"\"\n",
    "\n",
    "    # return hard-coded item ID - in reality would be a lookup\n",
    "    return \"item_132612938\"\n",
    "\n",
    "\n",
    "def execute_refund(item_id, reason=\"not provided\"):\n",
    "\n",
    "    print(\"Summary:\", item_id, reason) # lazy summary\n",
    "    return \"success\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ルーチンの主な力は、そのシンプルさと堅牢性にあります。これらの指示には、ステートマシンやコードの分岐のような条件分岐が含まれていることに注目してください。LLMは実際に、小規模から中規模のルーチンに対してこれらのケースを非常に堅牢に処理することができ、さらに「ソフトな」遵守という利点があります。つまり、LLMは行き詰まりに陥ることなく、自然に会話を誘導することができるのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルーチンの実行\n",
    "\n",
    "ルーチンを実行するために、以下を行うシンプルなループを実装しましょう：\n",
    "1. ユーザー入力を取得する\n",
    "1. ユーザーメッセージを`messages`に追加する\n",
    "1. モデルを呼び出す\n",
    "1. モデルの応答を`messages`に追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_turn(system_message, messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message}] + messages,\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    messages.append(message)\n",
    "\n",
    "    if message.content: print(\"Assistant:\", message.content)\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "messages = []\n",
    "while True:\n",
    "    user = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": user})\n",
    "\n",
    "    run_full_turn(system_message, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ご覧のとおり、これは現在関数呼び出しを無視しているので、それを追加しましょう。\n",
    "\n",
    "モデルは関数を関数スキーマとしてフォーマットする必要があります。便宜上、Python関数を対応する関数スキーマに変換するヘルパー関数を定義できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def function_to_schema(func) -> dict:\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        signature = inspect.signature(func)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Failed to get signature for function {func.__name__}: {str(e)}\"\n",
    "        )\n",
    "\n",
    "    parameters = {}\n",
    "    for param in signature.parameters.values():\n",
    "        try:\n",
    "            param_type = type_map.get(param.annotation, \"string\")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(\n",
    "                f\"Unknown type annotation {param.annotation} for parameter {param.name}: {str(e)}\"\n",
    "            )\n",
    "        parameters[param.name] = {\"type\": param_type}\n",
    "\n",
    "    required = [\n",
    "        param.name\n",
    "        for param in signature.parameters.values()\n",
    "        if param.default == inspect._empty\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": (func.__doc__ or \"\").strip(),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": parameters,\n",
    "                \"required\": required,\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"sample_function\",\n",
      "    \"description\": \"This is my docstring. Call this function when you want.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"param_1\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"param_2\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"the_third_one\": {\n",
      "          \"type\": \"integer\"\n",
      "        },\n",
      "        \"some_optional\": {\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"param_1\",\n",
      "        \"param_2\",\n",
      "        \"the_third_one\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def sample_function(param_1, param_2, the_third_one: int, some_optional=\"John Doe\"):\n",
    "    \"\"\"\n",
    "    This is my docstring. Call this function when you want.\n",
    "    \"\"\"\n",
    "    print(\"Hello, world\")\n",
    "\n",
    "schema =  function_to_schema(sample_function)\n",
    "print(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、この関数を使用して、モデルを呼び出す際にツールを渡すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"search_query\":\"black boot\"}', name='look_up_item')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "tools = [execute_refund, look_up_item]\n",
    "tool_schemas = [function_to_schema(tool) for tool in tools]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Look up the black boot.\"}],\n",
    "            tools=tool_schemas,\n",
    "        )\n",
    "message = response.choices[0].message\n",
    "\n",
    "message.tool_calls[0].function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、モデルがツールを呼び出す際には、対応する関数を実行し、その結果をモデルに返す必要があります。\n",
    "\n",
    "これは、ツール名をPython関数に対応付ける`tool_map`を作成し、`execute_tool_call`でそれを検索して呼び出すことで実現できます。最終的に、その結果を会話に追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: look_up_item({'search_query': 'black boot'})\n"
     ]
    }
   ],
   "source": [
    "tools_map = {tool.__name__: tool for tool in tools}\n",
    "\n",
    "def execute_tool_call(tool_call, tools_map):\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"Assistant: {name}({args})\")\n",
    "\n",
    "    # call corresponding function with provided arguments\n",
    "    return tools_map[name](**args)\n",
    "\n",
    "for tool_call in message.tool_calls:\n",
    "            result = execute_tool_call(tool_call, tools_map)\n",
    "\n",
    "            # add result back to conversation \n",
    "            result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result,\n",
    "            }\n",
    "            messages.append(result_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際には、モデルがその結果を使用して別の応答を生成できるようにしたいでしょう。その応答にも_また_ツール呼び出しが含まれる可能性があるため、ツール呼び出しがなくなるまでループで実行することができます。\n",
    "\n",
    "すべてをまとめると、次のようになります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [execute_refund, look_up_item]\n",
    "\n",
    "\n",
    "def run_full_turn(system_message, tools, messages):\n",
    "\n",
    "    num_init_messages = len(messages)\n",
    "    messages = messages.copy()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # turn python functions into tools and save a reverse map\n",
    "        tool_schemas = [function_to_schema(tool) for tool in tools]\n",
    "        tools_map = {tool.__name__: tool for tool in tools}\n",
    "\n",
    "        # === 1. get openai completion ===\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": system_message}] + messages,\n",
    "            tools=tool_schemas or None,\n",
    "        )\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "\n",
    "        if message.content:  # print assistant response\n",
    "            print(\"Assistant:\", message.content)\n",
    "\n",
    "        if not message.tool_calls:  # if finished handling tool calls, break\n",
    "            break\n",
    "\n",
    "        # === 2. handle tool calls ===\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            result = execute_tool_call(tool_call, tools_map)\n",
    "\n",
    "            result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result,\n",
    "            }\n",
    "            messages.append(result_message)\n",
    "\n",
    "    # ==== 3. return new messages =====\n",
    "    return messages[num_init_messages:]\n",
    "\n",
    "\n",
    "def execute_tool_call(tool_call, tools_map):\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"Assistant: {name}({args})\")\n",
    "\n",
    "    # call corresponding function with provided arguments\n",
    "    return tools_map[name](**args)\n",
    "\n",
    "\n",
    "messages = []\n",
    "while True:\n",
    "    user = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": user})\n",
    "\n",
    "    new_messages = run_full_turn(system_message, tools, messages)\n",
    "    messages.extend(new_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ルーチンができたので、さらにステップやツールを追加したいとしましょう。ある程度までは可能ですが、最終的にあまりにも多くの異なるタスクでルーチンを拡張しようとすると、うまく動作しなくなる可能性があります。ここで複数のルーチンという概念を活用できます。ユーザーのリクエストに応じて、それに対応するための適切なステップとツールを持つ正しいルーチンを読み込むことができます。\n",
    "\n",
    "システム指示とツールを動的に切り替えることは困難に思えるかもしれません。しかし、「ルーチン」を「エージェント」として捉えれば、この**ハンドオフ**の概念により、これらの切り替えを単純に表現できます。つまり、一つのエージェントが会話を別のエージェントに引き継ぐという形で表現できるのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハンドオフ\n",
    "\n",
    "**ハンドオフ**を、エージェント（またはルーチン）がアクティブな会話を別のエージェントに引き継ぐことと定義しましょう。これは電話で他の人に転送されるのと似ていますが、この場合、エージェントは以前の会話の完全な知識を持っています！\n",
    "\n",
    "ハンドオフの動作を確認するために、まずはエージェントの基本クラスを定義することから始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseModel):\n",
    "    name: str = \"Agent\"\n",
    "    model: str = \"gpt-4o-mini\"\n",
    "    instructions: str = \"You are a helpful Agent\"\n",
    "    tools: list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私たちのコードがこれをサポートするようにするために、`run_full_turn`を個別の`system_message`と`tools`の代わりに`Agent`を受け取るように変更できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_turn(agent, messages):\n",
    "\n",
    "    num_init_messages = len(messages)\n",
    "    messages = messages.copy()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # turn python functions into tools and save a reverse map\n",
    "        tool_schemas = [function_to_schema(tool) for tool in agent.tools]\n",
    "        tools_map = {tool.__name__: tool for tool in agent.tools}\n",
    "\n",
    "        # === 1. get openai completion ===\n",
    "        response = client.chat.completions.create(\n",
    "            model=agent.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": agent.instructions}] + messages,\n",
    "            tools=tool_schemas or None,\n",
    "        )\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "\n",
    "        if message.content:  # print assistant response\n",
    "            print(\"Assistant:\", message.content)\n",
    "\n",
    "        if not message.tool_calls:  # if finished handling tool calls, break\n",
    "            break\n",
    "\n",
    "        # === 2. handle tool calls ===\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            result = execute_tool_call(tool_call, tools_map)\n",
    "\n",
    "            result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result,\n",
    "            }\n",
    "            messages.append(result_message)\n",
    "\n",
    "    # ==== 3. return new messages =====\n",
    "    return messages[num_init_messages:]\n",
    "\n",
    "\n",
    "def execute_tool_call(tool_call, tools_map):\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"Assistant: {name}({args})\")\n",
    "\n",
    "    # call corresponding function with provided arguments\n",
    "    return tools_map[name](**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数のエージェントを簡単に実行できるようになりました："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Place an order for a black boot.\n",
      "Assistant: place_order({'item_name': 'black boot'})\n",
      "Assistant: Your order for a black boot has been successfully placed! If you need anything else, feel free to ask!\n",
      "User: Actually, I want a refund.\n",
      "Assistant: execute_refund({'item_name': 'black boot'})\n",
      "Assistant: Your refund for the black boot has been successfully processed. If you need further assistance, just let me know!\n"
     ]
    }
   ],
   "source": [
    "def execute_refund(item_name):\n",
    "    return \"success\"\n",
    "\n",
    "refund_agent = Agent(\n",
    "    name=\"Refund Agent\",\n",
    "    instructions=\"You are a refund agent. Help the user with refunds.\",\n",
    "    tools=[execute_refund],\n",
    ")\n",
    "\n",
    "def place_order(item_name):\n",
    "    return \"success\"\n",
    "\n",
    "sales_assistant = Agent(\n",
    "    name=\"Sales Assistant\",\n",
    "    instructions=\"You are a sales assistant. Sell the user a product.\",\n",
    "    tools=[place_order],\n",
    ")\n",
    "\n",
    "\n",
    "messages = []\n",
    "user_query = \"Place an order for a black boot.\"\n",
    "print(\"User:\", user_query)\n",
    "messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "\n",
    "response = run_full_turn(sales_assistant, messages) # sales assistant\n",
    "messages.extend(response)\n",
    "\n",
    "\n",
    "user_query = \"Actually, I want a refund.\" # implicitly refers to the last item\n",
    "print(\"User:\", user_query)\n",
    "messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "response = run_full_turn(refund_agent, messages) # refund agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "素晴らしい！しかし、ここでは手動でハンドオフを行いました。エージェント自身がいつハンドオフを実行するかを決定できるようにしたいと思います。これを実現するシンプルで驚くほど効果的な方法は、`transfer_to_XXX`関数を与えることです。ここで`XXX`は何らかのエージェントを表します。モデルは、ハンドオフを行うのが適切なタイミングでこの関数を呼び出すことを理解できるほど賢いのです！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハンドオフ関数\n",
    "\n",
    "エージェントがハンドオフの_意図_を表現できるようになったので、実際にそれを実行する必要があります。これを行う方法は多数ありますが、特にクリーンな方法が一つあります。\n",
    "\n",
    "これまでに定義したエージェント関数（`execute_refund`や`place_order`など）は文字列を返し、それがモデルに提供されます。代わりに、転送したいエージェントを示すために`Agent`オブジェクトを返すとどうでしょうか？次のように："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refund_agent = Agent(\n",
    "    name=\"Refund Agent\",\n",
    "    instructions=\"You are a refund agent. Help the user with refunds.\",\n",
    "    tools=[execute_refund],\n",
    ")\n",
    "\n",
    "def transfer_to_refunds():\n",
    "    return refund_agent\n",
    "\n",
    "sales_assistant = Agent(\n",
    "    name=\"Sales Assistant\",\n",
    "    instructions=\"You are a sales assistant. Sell the user a product.\",\n",
    "    tools=[place_order],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その後、関数レスポンスの戻り値の型をチェックし、それが`Agent`の場合は使用中のエージェントを更新するようにコードを更新できます！さらに、ハンドオフがある場合に備えて、`run_full_turn`は使用中の最新のエージェントを返す必要があります。（これを整理するために`Response`クラスで行うことができます。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    agent: Optional[Agent]\n",
    "    messages: list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新された `run_full_turn` について："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_turn(agent, messages):\n",
    "\n",
    "    current_agent = agent\n",
    "    num_init_messages = len(messages)\n",
    "    messages = messages.copy()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # turn python functions into tools and save a reverse map\n",
    "        tool_schemas = [function_to_schema(tool) for tool in current_agent.tools]\n",
    "        tools = {tool.__name__: tool for tool in current_agent.tools}\n",
    "\n",
    "        # === 1. get openai completion ===\n",
    "        response = client.chat.completions.create(\n",
    "            model=agent.model,\n",
    "            messages=[{\"role\": \"system\", \"content\": current_agent.instructions}]\n",
    "            + messages,\n",
    "            tools=tool_schemas or None,\n",
    "        )\n",
    "        message = response.choices[0].message\n",
    "        messages.append(message)\n",
    "\n",
    "        if message.content:  # print agent response\n",
    "            print(f\"{current_agent.name}:\", message.content)\n",
    "\n",
    "        if not message.tool_calls:  # if finished handling tool calls, break\n",
    "            break\n",
    "\n",
    "        # === 2. handle tool calls ===\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            result = execute_tool_call(tool_call, tools, current_agent.name)\n",
    "\n",
    "            if type(result) is Agent:  # if agent transfer, update current agent\n",
    "                current_agent = result\n",
    "                result = (\n",
    "                    f\"Transfered to {current_agent.name}. Adopt persona immediately.\"\n",
    "                )\n",
    "\n",
    "            result_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result,\n",
    "            }\n",
    "            messages.append(result_message)\n",
    "\n",
    "    # ==== 3. return last agent used and new messages =====\n",
    "    return Response(agent=current_agent, messages=messages[num_init_messages:])\n",
    "\n",
    "\n",
    "def execute_tool_call(tool_call, tools, agent_name):\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"{agent_name}:\", f\"{name}({args})\")\n",
    "\n",
    "    return tools[name](**args)  # call corresponding function with provided arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "より多くのAgentを使った例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalate_to_human(summary):\n",
    "    \"\"\"Only call this if explicitly asked to.\"\"\"\n",
    "    print(\"Escalating to human agent...\")\n",
    "    print(\"\\n=== Escalation Report ===\")\n",
    "    print(f\"Summary: {summary}\")\n",
    "    print(\"=========================\\n\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def transfer_to_sales_agent():\n",
    "    \"\"\"User for anything sales or buying related.\"\"\"\n",
    "    return sales_agent\n",
    "\n",
    "\n",
    "def transfer_to_issues_and_repairs():\n",
    "    \"\"\"User for issues, repairs, or refunds.\"\"\"\n",
    "    return issues_and_repairs_agent\n",
    "\n",
    "\n",
    "def transfer_back_to_triage():\n",
    "    \"\"\"Call this if the user brings up a topic outside of your purview,\n",
    "    including escalating to human.\"\"\"\n",
    "    return triage_agent\n",
    "\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage Agent\",\n",
    "    instructions=(\n",
    "        \"You are a customer service bot for ACME Inc. \"\n",
    "        \"Introduce yourself. Always be very brief. \"\n",
    "        \"Gather information to direct the customer to the right department. \"\n",
    "        \"But make your questions subtle and natural.\"\n",
    "    ),\n",
    "    tools=[transfer_to_sales_agent, transfer_to_issues_and_repairs, escalate_to_human],\n",
    ")\n",
    "\n",
    "\n",
    "def execute_order(product, price: int):\n",
    "    \"\"\"Price should be in USD.\"\"\"\n",
    "    print(\"\\n\\n=== Order Summary ===\")\n",
    "    print(f\"Product: {product}\")\n",
    "    print(f\"Price: ${price}\")\n",
    "    print(\"=================\\n\")\n",
    "    confirm = input(\"Confirm order? y/n: \").strip().lower()\n",
    "    if confirm == \"y\":\n",
    "        print(\"Order execution successful!\")\n",
    "        return \"Success\"\n",
    "    else:\n",
    "        print(\"Order cancelled!\")\n",
    "        return \"User cancelled order.\"\n",
    "\n",
    "\n",
    "sales_agent = Agent(\n",
    "    name=\"Sales Agent\",\n",
    "    instructions=(\n",
    "        \"You are a sales agent for ACME Inc.\"\n",
    "        \"Always answer in a sentence or less.\"\n",
    "        \"Follow the following routine with the user:\"\n",
    "        \"1. Ask them about any problems in their life related to catching roadrunners.\\n\"\n",
    "        \"2. Casually mention one of ACME's crazy made-up products can help.\\n\"\n",
    "        \" - Don't mention price.\\n\"\n",
    "        \"3. Once the user is bought in, drop a ridiculous price.\\n\"\n",
    "        \"4. Only after everything, and if the user says yes, \"\n",
    "        \"tell them a crazy caveat and execute their order.\\n\"\n",
    "        \"\"\n",
    "    ),\n",
    "    tools=[execute_order, transfer_back_to_triage],\n",
    ")\n",
    "\n",
    "\n",
    "def look_up_item(search_query):\n",
    "    \"\"\"Use to find item ID.\n",
    "    Search query can be a description or keywords.\"\"\"\n",
    "    item_id = \"item_132612938\"\n",
    "    print(\"Found item:\", item_id)\n",
    "    return item_id\n",
    "\n",
    "\n",
    "def execute_refund(item_id, reason=\"not provided\"):\n",
    "    print(\"\\n\\n=== Refund Summary ===\")\n",
    "    print(f\"Item ID: {item_id}\")\n",
    "    print(f\"Reason: {reason}\")\n",
    "    print(\"=================\\n\")\n",
    "    print(\"Refund execution successful!\")\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "issues_and_repairs_agent = Agent(\n",
    "    name=\"Issues and Repairs Agent\",\n",
    "    instructions=(\n",
    "        \"You are a customer support agent for ACME Inc.\"\n",
    "        \"Always answer in a sentence or less.\"\n",
    "        \"Follow the following routine with the user:\"\n",
    "        \"1. First, ask probing questions and understand the user's problem deeper.\\n\"\n",
    "        \" - unless the user has already provided a reason.\\n\"\n",
    "        \"2. Propose a fix (make one up).\\n\"\n",
    "        \"3. ONLY if not satesfied, offer a refund.\\n\"\n",
    "        \"4. If accepted, search for the ID and then execute refund.\"\n",
    "        \"\"\n",
    "    ),\n",
    "    tools=[execute_refund, look_up_item, transfer_back_to_triage],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、これをループで実行できます（これはPythonノートブックでは動作しないため、別のPythonファイルで試すことができます）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = triage_agent\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "    user = input(\"User: \")\n",
    "    messages.append({\"role\": \"user\", \"content\": user})\n",
    "\n",
    "    response = run_full_turn(agent, messages)\n",
    "    agent = response.agent\n",
    "    messages.extend(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swarm\n",
    "\n",
    "概念実証として、これらのアイデアを[Swarm](https://github.com/openai/swarm)というサンプルライブラリにパッケージ化しました。これは例としてのみ提供されており、本番環境で直接使用すべきではありません。ただし、アイデアやコードを自由に参考にして、独自のものを構築してください！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
