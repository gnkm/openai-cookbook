{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure チャット補完の例\n",
    "\n",
    "この例では、Azure OpenAI サービスを使用したチャット補完について説明します。また、コンテンツフィルタリングに関する情報も含まれています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "まず、必要な依存関係をインストールし、使用するライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"openai>=1.0.0,<2.0.0\"\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 認証\n",
    "\n",
    "Azure OpenAI サービスは、APIキーとAzure Active Directoryトークン認証情報を含む複数の認証メカニズムをサポートしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_azure_active_directory = False  # Set this flag to True if you are using Azure Active Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APIキーを使用した認証\n",
    "\n",
    "OpenAI SDKを*Azure APIキー*を使用するように設定するには、`api_key`をエンドポイントに関連付けられたキーに設定する必要があります（このキーは[Azure Portal](https://portal.azure.com)の*「リソース管理」*の下にある*「キーとエンドポイント」*で確認できます）。リソースのエンドポイントもここで確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_azure_active_directory:\n",
    "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Active Directoryを使用した認証\n",
    "次に、Azure Active Directoryを使用して認証する方法を見てみましょう。まず、`azure-identity`ライブラリをインストールします。このライブラリは、認証に必要なトークン認証情報を提供し、`get_bearer_token_provider`ヘルパー関数を通じてトークン認証情報プロバイダーの構築を支援します。`AzureOpenAI`に静的トークンを提供するよりも`get_bearer_token_provider`を使用することが推奨されます。なぜなら、このAPIは自動的にトークンをキャッシュし、更新してくれるからです。\n",
    "\n",
    "Azure OpenAIでAzure Active Directory認証を設定する方法の詳細については、[ドキュメント](https://learn.microsoft.com/azure/ai-services/openai/how-to/managed-identity)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"azure-identity>=1.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意: AzureOpenAIは、以下の引数が提供されていない場合、対応する環境変数から推論します：\n",
    "\n",
    "- `api_key` は `AZURE_OPENAI_API_KEY` から\n",
    "- `azure_ad_token` は `AZURE_OPENAI_AD_TOKEN` から\n",
    "- `api_version` は `OPENAI_API_VERSION` から\n",
    "- `azure_endpoint` は `AZURE_OPENAI_ENDPOINT` から"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デプロイメント\n",
    "\n",
    "このセクションでは、チャット補完を作成するために使用できるGPTモデルのデプロイメントを作成します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### デプロイメント: Azure OpenAI Studioで作成する\n",
    "チャット補完で使用するモデルをデプロイしましょう。https://portal.azure.com にアクセスし、Azure OpenAIリソースを見つけて、Azure OpenAI Studioに移動します。「Deployments」タブをクリックし、チャット補完に使用したいモデルのデプロイメントを作成します。モデルに付けるデプロイメント名は、以下のコードで使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"\" # Fill in the deployment name from the portal here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チャット補完の作成\n",
    "\n",
    "それでは、作成したクライアントを使用してチャット補完を作成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all possible arguments see https://platform.openai.com/docs/api-reference/chat-completions/create\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミングチャット補完の作成\n",
    "\n",
    "レスポンスをストリーミングすることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    if len(chunk.choices) > 0:\n",
    "        delta = chunk.choices[0].delta\n",
    "\n",
    "        if delta.role:\n",
    "            print(delta.role + \": \", end=\"\", flush=True)\n",
    "        if delta.content:\n",
    "            print(delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コンテンツフィルタリング\n",
    "\n",
    "Azure OpenAIサービスには、プロンプトと完了レスポンスのコンテンツフィルタリングが含まれています。コンテンツフィルタリングとその設定方法について詳しくは[こちら](https://learn.microsoft.com/azure/ai-services/openai/concepts/content-filter)をご覧ください。\n",
    "\n",
    "プロンプトがコンテンツフィルターによってフラグ付けされた場合、ライブラリは`content_filter`エラーコードを持つ`BadRequestError`例外を発生させます。そうでない場合は、レスポンスの`prompt_filter_results`と`content_filter_results`にアクセスして、コンテンツフィルタリングの結果とどのカテゴリがフラグ付けされたかを確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コンテンツフィルターによってフラグ付けされたプロンプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"<text violating the content policy>\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=deployment,\n",
    "    )\n",
    "except openai.BadRequestError as e:\n",
    "    err = json.loads(e.response.text)\n",
    "    if err[\"error\"][\"code\"] == \"content_filter\":\n",
    "        print(\"Content filter triggered!\")\n",
    "        content_filter_result = err[\"error\"][\"innererror\"][\"content_filter_result\"]\n",
    "        for category, details in content_filter_result.items():\n",
    "            print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コンテンツフィルターの結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the biggest city in Washington?\"}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    ")\n",
    "print(f\"Answer: {completion.choices[0].message.content}\")\n",
    "\n",
    "# prompt content filter result in \"model_extra\" for azure\n",
    "prompt_filter_result = completion.model_extra[\"prompt_filter_results\"][0][\"content_filter_results\"]\n",
    "print(\"\\nPrompt content filter results:\")\n",
    "for category, details in prompt_filter_result.items():\n",
    "    print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")\n",
    "\n",
    "# completion content filter result\n",
    "print(\"\\nCompletion content filter results:\")\n",
    "completion_filter_result = completion.choices[0].model_extra[\"content_filter_results\"]\n",
    "for category, details in completion_filter_result.items():\n",
    "    print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
