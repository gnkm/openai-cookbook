{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure DALL·E 画像生成の例\n",
    "\n",
    "> 注意: openaiライブラリの新しいバージョンが利用可能です。https://github.com/openai/openai-python/discussions/742 を参照してください\n",
    "\n",
    "このノートブックでは、Azure OpenAIサービスを使用して画像を生成する方法を示します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ\n",
    "\n",
    "まず、必要な依存関係をインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"openai>=0.28.1,<1.0.0\"\n",
    "# We need requests to retrieve the generated image\n",
    "! pip install requests\n",
    "# We use Pillow to display the generated image\n",
    "! pip install pillow \n",
    "# (Optional) If you want to use Microsoft Active Directory\n",
    "! pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、Azure OpenAI Serviceに適切にアクセスするために、[Azure Portal](https://portal.azure.com)で適切なリソースを作成する必要があります（詳細な手順については[Microsoft Docs](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal)で確認できます）。\n",
    "\n",
    "リソースが作成されたら、最初に必要なのはそのエンドポイントです。エンドポイントは、*「リソース管理」*セクション内の*「キーとエンドポイント」*セクションで確認できます。この情報を使用して、SDKをセットアップします："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = '' # Add your endpoint here\n",
    "\n",
    "# At the moment DALL·E is only supported by the 2023-06-01-preview API version\n",
    "openai.api_version = '2023-06-01-preview'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 認証\n",
    "\n",
    "Azure OpenAI サービスは、APIキーとAzure認証情報を含む複数の認証メカニズムをサポートしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_azure_active_directory = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APIキーを使用した認証\n",
    "\n",
    "OpenAI SDKを*Azure APIキー*を使用するように設定するには、`api_type`を`azure`に設定し、`api_key`をエンドポイントに関連付けられたキーに設定する必要があります（このキーは[Azure Portal](https://portal.azure.com)の*「リソース管理」*の下にある*「キーとエンドポイント」*で確認できます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_azure_active_directory:\n",
    "    openai.api_type = 'azure'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意: この例では、コード内で変数を設定することでライブラリがAzure APIを使用するように設定しました。開発時には、代わりに環境変数を設定することを検討してください：\n",
    "\n",
    "```\n",
    "OPENAI_API_BASE\n",
    "OPENAI_API_KEY\n",
    "OPENAI_API_TYPE\n",
    "OPENAI_API_VERSION\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Microsoft Active Directoryを使用した認証\n",
    "それでは、Microsoft Active Directory認証を通じてキーを取得する方法を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    default_credential = DefaultAzureCredential()\n",
    "    token = default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    openai.api_type = 'azure_ad'\n",
    "    openai.api_key = token.token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トークンは一定期間有効で、その後期限切れになります。すべてのリクエストで有効なトークンが送信されるようにするために、`requests.auth`にフックすることで期限切れのトークンを更新できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import time\n",
    "import requests\n",
    "\n",
    "if typing.TYPE_CHECKING:\n",
    "    from azure.core.credentials import TokenCredential\n",
    "\n",
    "class TokenRefresh(requests.auth.AuthBase):\n",
    "\n",
    "    def __init__(self, credential: \"TokenCredential\", scopes: typing.List[str]) -> None:\n",
    "        self.credential = credential\n",
    "        self.scopes = scopes\n",
    "        self.cached_token: typing.Optional[str] = None\n",
    "\n",
    "    def __call__(self, req):\n",
    "        if not self.cached_token or self.cached_token.expires_on - time.time() < 300:\n",
    "            self.cached_token = self.credential.get_token(*self.scopes)\n",
    "        req.headers[\"Authorization\"] = f\"Bearer {self.cached_token.token}\"\n",
    "        return req\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    session = requests.Session()\n",
    "    session.auth = TokenRefresh(default_credential, [\"https://cognitiveservices.azure.com/.default\"])\n",
    "\n",
    "    openai.requestssession = session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成\n",
    "\n",
    "セットアップと認証が完了したので、Azure OpenAIサービスで画像を生成し、返されたURLから画像を取得できるようになりました。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 画像を生成する\n",
    "\n",
    "このプロセスの最初のステップは、実際に画像を生成することです："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_response = openai.Image.create(\n",
    "    prompt='A cyberpunk monkey hacker dreaming of a beautiful bunch of bananas, digital art',\n",
    "    size='1024x1024',\n",
    "    n=2\n",
    ")\n",
    "\n",
    "print(generation_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Image.create`の呼び出しからのレスポンスを受け取った後、`requests`を使用してURLからダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# First a little setup\n",
    "image_dir = os.path.join(os.curdir, 'images')\n",
    "# If the directory doesn't exist, create it\n",
    "if not os.path.isdir(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "# With the directory in place, we can initialize the image path (note that filetype should be png)\n",
    "image_path = os.path.join(image_dir, 'generated_image.png')\n",
    "\n",
    "# Now we can retrieve the generated image\n",
    "image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "generated_image = requests.get(image_url).content  # download the image\n",
    "with open(image_path, \"wb\") as image_file:\n",
    "    image_file.write(generated_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像をダウンロードした後、[Pillow](https://pypi.org/project/Pillow/)ライブラリを使用して画像を開いて表示します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "\n",
    "display(Image.open(image_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a5103089ab7e7c666b279eeded403fcec76de49a40685dbdfe9f9c78ad97c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
