{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40b4db2",
   "metadata": {},
   "source": [
    "# Hugging Faceã‚’ä½¿ç”¨ã—ãŸå¤šè¨€èªæ¨è«–å™¨ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "\n",
    "è‘—è€…: [Edward Beeching](https://huggingface.co/edbeeching), [Quentin GallouÃ©dec](https://huggingface.co/qgallouedec), [Lewis Tunstall](https://huggingface.co/lewtun)\n",
    "\n",
    "[OpenAI o3](https://openai.com/index/introducing-o3-and-o4-mini/)ã®ã‚ˆã†ãªå¤§è¦æ¨¡æ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯ã€å¿œç­”ã®ç²¾åº¦ã¨å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«æ€è€ƒã®é€£é–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã—ã‹ã—ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®å¤šãã¯ã€ä»–ã®è¨€èªã§è³ªå•ã•ã‚Œã¦ã‚‚è‹±èªã§æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€OpenAIã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆæ¨è«–ãƒ¢ãƒ‡ãƒ«[OpenAI gpt-oss-20b](https://huggingface.co/openai/gpt-oss-20b)ã‚’è¤‡æ•°ã®è¨€èªã§åŠ¹æœçš„ã«æ¨è«–ã§ãã‚‹ã‚ˆã†ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–°ã—ã„_ã€Œæ¨è«–è¨€èªã€_ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã—ã€å¤šè¨€èªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Hugging Faceã®[TRLãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://github.com/huggingface/trl)ã‚’ä½¿ç”¨ã—ã¦[æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](https://huggingface.co/learn/llm-course/chapter11/1)ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚’å®Ÿç¾ã—ã¾ã™ã€‚\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’èª¬æ˜ã—ã¾ã™ï¼š\n",
    "\n",
    "1. **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—:** å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚\n",
    "2. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™:** ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¾ã™ã€‚\n",
    "3. **ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™:** ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªæŠ€è¡“ã§ã‚ã‚‹[LoRA](https://huggingface.co/learn/llm-course/chapter11/4)ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "4. **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°:** å¤šè¨€èªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã™ã€‚\n",
    "5. **æ¨è«–:** ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ç•°ãªã‚‹è¨€èªã§æ¨è«–å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "\n",
    "æœ€çµ‚çš„ãªçµæœã¯ã€è‹±èªã€ã‚¹ãƒšã‚¤ãƒ³èªã€ãƒ•ãƒ©ãƒ³ã‚¹èªã€ã‚¤ã‚¿ãƒªã‚¢èªã€ã¾ãŸã¯ãƒ‰ã‚¤ãƒ„èªã§æ€è€ƒã®é€£é–ã‚’ç”Ÿæˆã§ãã‚‹å¤šè¨€èªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚_è¨€èªã‚’æ··åœ¨_ã•ã›ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ä¾‹ãˆã°ã€ã‚¹ãƒšã‚¤ãƒ³èªã§è³ªå•ã—ã€ãƒ‰ã‚¤ãƒ„èªã§ã®æ¨è«–ã‚’è¦æ±‚ã—ã€æœ€çµ‚çš„ãªå¿œç­”ã‚’ã‚¹ãƒšã‚¤ãƒ³èªã§å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š\n",
    "\n",
    "```txt\n",
    "User:\n",
    "    Â¿CuÃ¡l es el capital de Australia?\n",
    "Assistant reasoning:\n",
    "    Okay, der Benutzer fragt nach der Hauptstadt Australiens. Ich erinnere mich, dass Canberra die Hauptstadt ist. Ich\n",
    "    sollte das bestÃ¤tigen. Lass mich sehen, ob es irgendwelche potenziellen Verwirrungen gibt. Der Benutzer kÃ¶nnte auch\n",
    "    an der grÃ¶ÃŸten Stadt interessiert sein. Die grÃ¶ÃŸte Stadt ist Sydney, aber die Hauptstadt ist Canberra. Ich sollte\n",
    "    das klarstellen. Vielleicht auch erwÃ¤hnen, dass Canberra eine geplante Stadt ist und nicht die grÃ¶ÃŸte. Der Benutzer\n",
    "    kÃ¶nnte auch nach der Geografie fragen. Vielleicht erwÃ¤hne ich, dass Canberra im sÃ¼dwestlichen Teil der Australian\n",
    "    Capital Territory liegt. Ich sollte die Antwort prÃ¤zise und freundlich halten. Vielleicht auch erwÃ¤hnen, dass\n",
    "    Canberra oft mit Sydney verwechselt wird. Ich sollte sicherstellen, dass die Antwort klar und korrekt ist.\n",
    "Assistant response:\n",
    "    La capital de Australia es **Canberra**. Aunque es la ciudad mÃ¡s pequeÃ±a de las principales capitales del paÃ­s, fue\n",
    "    elegida en 1908 como la sede del gobierno federal para equilibrar la influencia entre las ciudades de Sydney y\n",
    "    Melbourne. Canberra estÃ¡ ubicada en el Territorio de la Capital Australiana (ACT), en el este de Australia.\n",
    "```\n",
    "\n",
    "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ãŒã€ååˆ†ã«ä»£è¡¨ã•ã‚Œã¦ã„ãªã„è¨€èªã§ä½œæ¥­ã™ã‚‹AIé–‹ç™ºè€…ãŒã€æ¯å›½èªã§ã®[`openai/gpt-oss-20b`](https://huggingface.co/openai/gpt-oss-20b)ã®è§£é‡ˆå¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "> **æ³¨æ„:** ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€80GBãƒ¡ãƒ¢ãƒªã‚’æ­è¼‰ã—ãŸå˜ä¸€ã®H100 GPUã§å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šå°ã•ãªGPUã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d0215",
   "metadata": {},
   "source": [
    "## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "\n",
    "å§‹ã‚ã‚‹ãŸã‚ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ã‚‡ã†ã€‚ã¾ãšPyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6f749",
   "metadata": {},
   "source": [
    "æ¬¡ã«ã€æ®‹ã‚Šã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bad857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"trl>=0.20.0\" \"peft>=0.17.0\" \"transformers>=4.55.0\" trackio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7497b7",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ä»¥ä¸‹ã®ã‚ˆã†ã«Hugging Faceã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b235c41",
   "metadata": {},
   "source": [
    "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã®ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9534203",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™\n",
    "\n",
    "[Multilingual-Thinking](https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€æ€è€ƒã®é€£é–ãŒãƒ•ãƒ©ãƒ³ã‚¹èªã€ã‚¹ãƒšã‚¤ãƒ³èªã€ãƒ‰ã‚¤ãƒ„èªãªã©ã®è¤‡æ•°ã®è¨€èªã«ç¿»è¨³ã•ã‚ŒãŸæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§`openai/gpt-oss-20b`ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã“ã‚Œã‚‰ã®è¨€èªã§æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€ãã‚Œã‚‰ã®è¨€èªã‚’è©±ã™ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f9b34",
   "metadata": {},
   "source": [
    "```html\n",
    "<iframe\n",
    "  src=\"https://huggingface.co/datasets/HuggingFaceH4/Multilingual-Thinking/embed/viewer/default/train\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"560px\"\n",
    "></iframe>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f77056",
   "metadata": {},
   "source": [
    "Hugging Face Hubã‹ã‚‰ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/Multilingual-Thinking\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c50d00",
   "metadata": {},
   "source": [
    "ã“ã‚Œã¯1,000ä¾‹ã®å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ãŒã€åºƒç¯„å›²ã«ã‚ãŸã‚‹ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å—ã‘ãŸ`openai/gpt-oss-20b`ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã«ã¯é€šå¸¸ã“ã‚Œã§ååˆ†ã§ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®ä¸€ã¤ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c44ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba75fde",
   "metadata": {},
   "source": [
    "`gpt-oss`ãƒ¢ãƒ‡ãƒ«ã¯ã€ä¼šè©±æ§‹é€ ã®å®šç¾©ã€æ¨è«–å‡ºåŠ›ã®ç”Ÿæˆã€é–¢æ•°å‘¼ã³å‡ºã—ã®æ§‹é€ åŒ–ã®ãŸã‚ã®Harmonyå¿œç­”å½¢å¼ã§è¨“ç·´ã•ã‚Œã¾ã—ãŸã€‚ã“ã®å½¢å¼ã¯OpenAI Responses APIã‚’æ¨¡å€£ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ä»¥ä¸‹ã®è¡¨ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä½¿ç”¨ã•ã‚Œã‚‹ç•°ãªã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b01cef",
   "metadata": {},
   "source": [
    "|||\n",
    "| :---- | :--|\n",
    "| `developer` | developer ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã‚’æä¾›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ï¼ˆé€šå¸¸ `system` ãƒ­ãƒ¼ãƒ«ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ï¼‰ã€‚ |\n",
    "| `user` | user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã‚’æä¾›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ |\n",
    "| `assistant` | ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‡ºåŠ›ã•ã‚Œã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¾ãŸã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡ºåŠ›ã®ã„ãšã‚Œã‹ã«ãªã‚Šã¾ã™ã€‚å‡ºåŠ›ã¯ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ„å›³ã‚’è­˜åˆ¥ã™ã‚‹ç‰¹å®šã®ã€Œãƒãƒ£ãƒ³ãƒãƒ«ã€ã«é–¢é€£ä»˜ã‘ã‚‰ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚ |\n",
    "| `analysis` | ã“ã‚Œã‚‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒæ€è€ƒã®é€£é–ã«ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚ |\n",
    "| `final` | final ãƒãƒ£ãƒ³ãƒãƒ«ã§ã‚¿ã‚°ä»˜ã‘ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¡¨ç¤ºã™ã‚‹ã“ã¨ã‚’æ„å›³ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã‚’è¡¨ã—ã¾ã™ã€‚ |\n",
    "| `messages` | ä¸Šè¨˜ã®å†…å®¹ã‚’çµ„ã¿åˆã‚ã›ã¦å®Œå…¨ãªä¼šè©±ã‚’ä½œæˆã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã§ã™ã€‚ã“ã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã¨ãªã‚Šã¾ã™ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d496f0",
   "metadata": {},
   "source": [
    "[OpenAI ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼](https://platform.openai.com/docs/api-reference/messages/object)ã«é¦´æŸ“ã¿ãŒã‚ã‚‹æ–¹ã¯ã€ã“ã‚ŒãŒéå¸¸ã«ä¼¼ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã§ã—ã‚‡ã†ãŒã€é‡è¦ãªé•ã„ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "> `assistant` ã‚¿ãƒ¼ãƒ³ã«ã¯2ã¤ã®ç‰¹åˆ¥ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼šãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’å«ã‚€ `thinking` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚çš„ãªå¿œç­”ã‚’å«ã‚€ `content` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã™ã€‚\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ã€ã“ã‚Œã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å®Ÿéš›ã«ã¯ã€å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ¢ãƒ‡ãƒ«ã®[_ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ_](https://huggingface.co/docs/transformers/chat_templating)ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã€ãã®çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã™ã‚‹ã“ã¨ã§è¡Œã‚ã‚Œã¾ã™ã€‚TRLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã“ã‚Œã‚’è‡ªå‹•çš„ã«è¡Œã„ã¾ã™ãŒã€ã©ã®ã‚ˆã†ã«å‹•ä½œã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "ãã®ãŸã‚ã«ã€ã¾ãšãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d11c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee27751",
   "metadata": {},
   "source": [
    "ãã®å¾Œã€tokenizerã®`apply_chat_template()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86445ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = dataset[0][\"messages\"]\n",
    "conversation = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74423b1",
   "metadata": {},
   "source": [
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯éå¸¸ã«æ´—ç·´ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€è©³ã—ãè¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼ã¾ãšã€å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é–‹å§‹ã¨çµ‚äº†ã‚’ç¤ºã™ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³`<|start|>`ã¨`<|end|>`ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã¾ãŸã€ä¼šè©±ã®çµ‚äº†ã‚’ç¤ºã™`<|return|>`ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒä¼šè©±ã®æ§‹é€ ã‚’ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\n",
    "ã¾ãŸã€**2ã¤**ã®ã‚¿ã‚¤ãƒ—ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹ã“ã¨ã‚‚ã‚ã‹ã‚Šã¾ã™ï¼š\n",
    "\n",
    "* ã™ã¹ã¦ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®`system`ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ã“ã‚Œã¯_ã€ŒYou are ChatGPT, a large language model trained by OpenAI...ã€_ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡ã—ã¾ã™\n",
    "* ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã‚’å«ã‚€ç‰¹åˆ¥ãª`developer`ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆ`messages`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®`system`ãƒ­ãƒ¼ãƒ«ã§å®šç¾©ã•ã‚Œã‚‹ï¼‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ä¼šè©±ã§ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã†ã¹ãã‹ã«ã¤ã„ã¦ã€è¿½åŠ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æä¾›ã§ãã¾ã™ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ã“ã‚Œã¯_ã€ŒYou are an AI chatbot with a lively and energetic personality.ã€_ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡ã—ã¾ã™\n",
    "\n",
    "æœ€å¾Œã«ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ãŒä¸€é€£ã®**ãƒãƒ£ãƒ³ãƒãƒ«**ã«å«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼š\n",
    "\n",
    "* `analysis`ãƒãƒ£ãƒ³ãƒãƒ«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«ä½¿ç”¨ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ã¤ã„ã¦æ®µéšçš„ã«è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ã“ã‚Œã¯ãƒ•ãƒ©ãƒ³ã‚¹èªã®ãƒ†ã‚­ã‚¹ãƒˆ_ã€ŒD'accord, l'utilisateur demande les tendances Twitter...ã€_ã‚’æŒ‡ã—ã¾ã™\n",
    "* `final`ãƒãƒ£ãƒ³ãƒãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚çš„ãªå¿œç­”ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ã“ã‚Œã¯_ã€ŒHey there! While I can't check Twitter...ã€_ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc392a9",
   "metadata": {},
   "source": [
    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™æ–¹æ³•ã‚’ç†è§£ã—ãŸã®ã§ã€æ¬¡ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«é€²ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1186ef",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ã™ã‚‹ãŸã‚ã€ã¾ãš[Hugging Face Hub](https://huggingface.co)ã‹ã‚‰é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚ğŸ¤— Transformersã®`AutoModelForCausalLM`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, Mxfp4Config\n",
    "\n",
    "quantization_config = Mxfp4Config(dequantize=True)\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"eager\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai/gpt-oss-20b\", **model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f349ee8",
   "metadata": {},
   "source": [
    "ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªè¨­å®šã§ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚`attn_implementation`ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã«`eager`ã«è¨­å®šã•ã‚Œã€`use_cache`ã¯å‹¾é…ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚`False`ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "ğŸ¤— Transformersã«æ…£ã‚Œã¦ã„ã‚‹æ–¹ã¯ã€é‡å­åŒ–ã«`Mxfp4Config`ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã«ãŠæ°—ã¥ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã‚Œã¯OpenAIãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®è¨­å®šã§ã€AIãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«æœ€é©åŒ–ã•ã‚ŒãŸ[MXFP4](https://en.wikipedia.org/wiki/Block_floating_point)ã¨å‘¼ã°ã‚Œã‚‹ç‰¹åˆ¥ãª4ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹å½¢å¼ã‚’ä½¿ç”¨ã—ãŸæ··åˆç²¾åº¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å‰ã«ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã‚µãƒ³ãƒ—ãƒ«å¿œç­”ã‚’ç”Ÿæˆã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãã®ãŸã‚ã«ã¯ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Â¿CuÃ¡l es el capital de Australia?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "output_ids = model.generate(input_ids, max_new_tokens=512)\n",
    "response = tokenizer.batch_decode(output_ids)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb2ba1",
   "metadata": {},
   "source": [
    "ã“ã®ä¾‹ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒæœ€åˆã«è‹±èªã§è³ªå•ã«ã¤ã„ã¦æ¨è«–ã—ã€ãã®å¾Œã‚¹ãƒšã‚¤ãƒ³èªã§æœ€çµ‚çš„ãªå›ç­”ã‚’æä¾›ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œã§ã™ãŒã€å°‘ã—ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§å¤‰æ›´ã§ãã‚‹ã‹ã©ã†ã‹è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "ãã®ãŸã‚ã«ã€[LoRA](https://huggingface.co/learn/llm-course/chapter11/4)ï¼ˆLow-Rank Adaptationï¼‰ã¨å‘¼ã°ã‚Œã‚‹æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã“ã®æŠ€è¡“ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®šã®å±¤ã‚’ã„ãã¤ã‹èª¿æ•´ã™ã‚‹ã“ã¨ãŒã§ãã€`openai/gpt-oss-20b`ã®ã‚ˆã†ãªå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã«ç‰¹ã«æœ‰ç”¨ã§ã™ã€‚\n",
    "\n",
    "ã¾ãšã€ãƒ¢ãƒ‡ãƒ«ã‚’`PeftModel`ã¨ã—ã¦ãƒ©ãƒƒãƒ—ã—ã€LoRAè¨­å®šã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’è¡Œã†ãŸã‚ã«ã€[PEFTãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://github.com/huggingface/peft)ã®`LoraConfig`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=\"all-linear\",\n",
    "    target_parameters=[\n",
    "        \"7.mlp.experts.gate_up_proj\",\n",
    "        \"7.mlp.experts.down_proj\",\n",
    "        \"15.mlp.experts.gate_up_proj\",\n",
    "        \"15.mlp.experts.down_proj\",\n",
    "        \"23.mlp.experts.gate_up_proj\",\n",
    "        \"23.mlp.experts.down_proj\",\n",
    "    ],\n",
    ")\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb24bb",
   "metadata": {},
   "source": [
    "ã“ã“ã§ã¯ã€LoRAã®åŸºæœ¬çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã—ãŸãŒã€ç•°ãªã‚‹å€¤ã‚’è©¦ã—ã¦ã€ãã‚Œã‚‰ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€`r`ã‚’å¢—ã‚„ã™ã¨ã€ã‚ˆã‚Šå¤šãã®è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ã«ãªã‚Šã€ã‚ˆã‚Šå¤šãã®VRAMã¨è¨“ç·´æ™‚é–“ãŒå¿…è¦ã«ãªã‚‹ä»£ã‚ã‚Šã«ã€ã‚ˆã‚Šè‰¯ã„ãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "**æ³¨æ„ï¼š** `openai/gpt-oss-20b`ãƒ¢ãƒ‡ãƒ«ã¯[Mixture-of-Experts (MoE)](https://huggingface.co/blog/moe)ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹ï¼ˆ`target_modules=\"all-linear\"`ï¼‰ã“ã¨ã«åŠ ãˆã¦ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å±¤ã‚‚å«ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚PEFTã¯`target_parameters`å¼•æ•°ã‚’é€šã˜ã¦ã“ã‚Œã‚’ä¿ƒé€²ã—ã€`mlp.experts.down_proj`ã‚„`mlp.experts.gate_up_proj`ãªã©ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆå›ºæœ‰ã®å±¤ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å±¤ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ã„ã¾ã™ãŒã€ç•°ãªã‚‹æ§‹æˆã§å®Ÿé¨“ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1328c16",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ãŒã§ããŸã®ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40347f0d",
   "metadata": {},
   "source": [
    "## ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fb02e",
   "metadata": {},
   "source": [
    "TRLã¯ã€`SFTConfig`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã™ã‚‹ä¾¿åˆ©ãªæ–¹æ³•ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’ç‡ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã€ã‚¨ãƒãƒƒã‚¯æ•°ã€ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    learning_rate=2e-4,\n",
    "    gradient_checkpointing=True,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    max_length=2048,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine_with_min_lr\",\n",
    "    lr_scheduler_kwargs={\"min_lr_rate\": 0.1},\n",
    "    output_dir=\"gpt-oss-20b-multilingual-reasoner\",\n",
    "    report_to=\"trackio\",\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337d6cc",
   "metadata": {},
   "source": [
    "`per_device_train_batch_size`ãŒ4ã«è¨­å®šã•ã‚Œã€`gradient_accumulation_steps`ãŒ4ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã€1ã¤ã®GPUä¸Šã§å®Ÿè³ªçš„ã«4 x 4 = 16ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŒã¤ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆã«åŸºã¥ã„ã¦ã€ã“ã‚Œã‚‰ã®å€¤ã‚’èª¿æ•´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®é€²æ—ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ãŸã‚ã«[Trackio](https://huggingface.co/blog/trackio)ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€ãŠå¥½ã¿ã®ä»–ã®ãƒ­ã‚®ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde26ee3",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã™ã¹ã¦ã®è¦ç´ ãŒæƒã„ã¾ã—ãŸã€‚TRLã®`SFTTrainer`ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‡¦ç†ã—ã¾ã™ã€‚ã“ã®ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®é©ç”¨ã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’å‡¦ç†ã—ã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe048a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af29870",
   "metadata": {},
   "source": [
    "H100 GPUã§ã¯ã€ã“ã‚Œã¯ç´„18åˆ†ã§è¨“ç·´ãŒå®Œäº†ã—ã¾ã™ãŒã€ãŠä½¿ã„ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«ã‚ˆã£ã¦ã¯ã‚ˆã‚Šé•·ã„æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3296e42f",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦Hugging Face Hubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ebaa4",
   "metadata": {},
   "source": [
    "æœ€å¾Œã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’Hubãƒªãƒã‚¸ãƒˆãƒªã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)\n",
    "trainer.push_to_hub(dataset_name=\"HuggingFaceH4/Multilingual-Thinking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa03d3",
   "metadata": {},
   "source": [
    "**æ³¨æ„**: ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOMï¼‰ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€ã“ã®æ™‚ç‚¹ã§ã‚«ãƒ¼ãƒãƒ«ã‚’å†èµ·å‹•ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ã¾ã GPUãƒ¡ãƒ¢ãƒªã‚’å æœ‰ã—ã¦ã„ã¾ã™ãŒã€ã‚‚ã¯ã‚„å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf67472",
   "metadata": {},
   "source": [
    "## æ¨è«–\n",
    "\n",
    "ãƒ¢ãƒ‡ãƒ«ãŒHubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰ã€æ¨è«–ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ãã®ãŸã‚ã«ã¯ã€ã¾ãšå…ƒã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚æ¬¡ã«ã€é«˜é€Ÿæ¨è«–ã®ãŸã‚ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸé‡ã¿ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ¼ã‚¸ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "\n",
    "# Load the original model first\n",
    "model_kwargs = dict(attn_implementation=\"eager\", torch_dtype=\"auto\", use_cache=True, device_map=\"auto\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"openai/gpt-oss-20b\", **model_kwargs).cuda()\n",
    "\n",
    "# Merge fine-tuned weights with the base model\n",
    "peft_model_id = \"gpt-oss-20b-multilingual-reasoner\"\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bd360",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã®ã§ã€æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ï¼ã“ã“ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®`generate`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦å‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã¾ãšã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©ã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082afb43",
   "metadata": {},
   "source": [
    "ã“ã‚Œã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¦å‡ºåŠ›ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚æœ€å¾Œã«ã€å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦æœ€çµ‚çš„ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã§ãã¾ã™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "REASONING_LANGUAGE = \"German\"\n",
    "SYSTEM_PROMPT = f\"reasoning language: {REASONING_LANGUAGE}\"\n",
    "USER_PROMPT = \"Â¿CuÃ¡l es el capital de Australia?\"  # Spanish for \"What is the capital of Australia?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "gen_kwargs = {\"max_new_tokens\": 512, \"do_sample\": True, \"temperature\": 0.6, \"top_p\": None, \"top_k\": None}\n",
    "\n",
    "output_ids = model.generate(input_ids, **gen_kwargs)\n",
    "response = tokenizer.batch_decode(output_ids)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28452ff8",
   "metadata": {},
   "source": [
    "ãƒ¢ãƒ‡ãƒ«ãŒæ˜ç¤ºçš„ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ãªã„è¨€èªã€ä¾‹ãˆã°ä¸­å›½èªã‚„ãƒ’ãƒ³ãƒ‡ã‚£ãƒ¼èªã§ã‚‚è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "REASONING_LANGUAGE = \"Chinese\"  # or Hindi, or any other language...\n",
    "SYSTEM_PROMPT = f\"reasoning language: {REASONING_LANGUAGE}\"\n",
    "USER_PROMPT = \"What is the national symbol of Canada?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "output_ids = model.generate(input_ids, **gen_kwargs)\n",
    "response = tokenizer.batch_decode(output_ids)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b7b03",
   "metadata": {},
   "source": [
    "ç´ æ™´ã‚‰ã—ã„ã€ã†ã¾ãå‹•ä½œã—ã¾ã—ãŸ - `openai/gpt-oss-20b`ã‚’è¤‡æ•°ã®è¨€èªã§æ¨è«–ã§ãã‚‹ã‚ˆã†ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ff811",
   "metadata": {},
   "source": [
    "## çµè«–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404075f",
   "metadata": {},
   "source": [
    "ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼TRLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨LoRAã‚’ä½¿ç”¨ã—ã¦ã€å¤šè¨€èªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«æˆåŠŸã—ã¾ã—ãŸã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æ‰‹é †ã¯ã€Hugging Face Hubä¸Šã®ä»–ã®å¤šãã®[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://huggingface.co/datasets)ã§[`openai/gpt-oss-20b`](https://huggingface.co/openai/gpt-oss-20b)ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«å¿œç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚ãªãŸãŒä½•ã‚’æ§‹ç¯‰ã™ã‚‹ã‹ã‚’æ¥½ã—ã¿ã«ã—ã¦ã„ã¾ã™ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-tsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
