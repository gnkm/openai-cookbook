# ウェブ上の関連リソース

GPTの出力を改善するための優れたツールや論文が多く書かれています。以下に、私たちが見つけた素晴らしいものをいくつか紹介します：

## プロンプトライブラリ＆ツール（アルファベット順）

- [Arthur Shield](https://www.arthur.ai/get-started): 毒性、幻覚、プロンプトインジェクションなどを検出する有料製品。
- [Baserun](https://baserun.ai/): LLMベースのアプリのテスト、デバッグ、監視を行う有料製品。
- [Chainlit](https://docs.chainlit.io/overview): チャットボットインターフェースを作成するPythonライブラリ。
- [ElatoAI](https://github.com/akdeb/ElatoAI): Deno Edge RuntimeとSupabaseを使用してArduino上のESP32でOpenAI Realtime API Speechを実行するプラットフォーム。
- [Embedchain](https://github.com/embedchain/embedchain): 非構造化データをLLMと管理・同期するPythonライブラリ。
- [FLAML (A Fast Library for Automated Machine Learning & Tuning)](https://microsoft.github.io/FLAML/docs/Getting-Started/): モデル、ハイパーパラメータ、その他の調整可能な選択肢の自動選択を行うPythonライブラリ。
- [Guidance](https://github.com/microsoft/guidance): Handlebarsテンプレートを使用して生成、プロンプト、論理制御を組み合わせるMicrosoftの便利なPythonライブラリ。
- [Haystack](https://github.com/deepset-ai/haystack): Pythonでカスタマイズ可能な本番対応LLMアプリケーションを構築するオープンソースLLMオーケストレーションフレームワーク。
- [HoneyHive](https://honeyhive.ai): LLMアプリの評価、デバッグ、監視を行うエンタープライズプラットフォーム。
- [LangChain](https://github.com/hwchase17/langchain): 言語モデルプロンプトのシーケンスをチェーンするための人気のPython/JavaScriptライブラリ。
- [LiteLLM](https://github.com/BerriAI/litellm): 一貫したフォーマットでLLM APIを呼び出すための最小限のPythonライブラリ。
- [LlamaIndex](https://github.com/jerryjliu/llama_index): データでLLMアプリを拡張するPythonライブラリ。
- [LLMOps Database](https://www.reddit.com/r/LocalLLaMA/comments/1h4u7au/a_nobs_database_of_how_companies_actually_deploy/): 企業が実際に本番環境でLLMをデプロイする方法のデータベース。
- [LMQL](https://lmql.ai): 型付きプロンプト、制御フロー、制約、ツールをサポートするLLM相互作用のプログラミング言語。
- [OpenAI Evals](https://github.com/openai/evals): 言語モデルとプロンプトのタスクパフォーマンスを評価するオープンソースライブラリ。
- [Outlines](https://github.com/normal-computing/outlines): プロンプトを簡素化し、生成を制約するドメイン固有言語を提供するPythonライブラリ。
- [Parea AI](https://www.parea.ai): LLMアプリのデバッグ、テスト、監視を行うプラットフォーム。
- [Portkey](https://portkey.ai/): LLMアプリの観測可能性、モデル管理、評価、セキュリティのためのプラットフォーム。
- [Promptify](https://github.com/promptslab/Promptify): 言語モデルを使用してNLPタスクを実行する小さなPythonライブラリ。
- [PromptPerfect](https://promptperfect.jina.ai/prompts): プロンプトのテストと改善を行う有料製品。
- [Prompttools](https://github.com/hegelai/prompttools): モデル、ベクトルDB、プロンプトのテストと評価を行うオープンソースPythonツール。
- [Scale Spellbook](https://scale.com/spellbook): 言語モデルアプリの構築、比較、出荷を行う有料製品。
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel): プロンプトテンプレート、関数チェーン、ベクトル化メモリ、インテリジェント計画をサポートするMicrosoftのPython/C#/Javaライブラリ。
- [Vellum](https://www.vellum.ai/): 高度なLLMアプリの実験、評価、デプロイを行う有料AI製品開発プラットフォーム。
- [Weights & Biases](https://wandb.ai/site/solutions/llmops): モデル訓練とプロンプトエンジニアリング実験を追跡する有料製品。
- [YiVal](https://github.com/YiVal/YiVal): カスタマイズ可能なデータセット、評価方法、進化戦略を使用してプロンプト、検索設定、モデルパラメータを調整・評価するオープンソースGenAI-Opsツール。

## プロンプトガイド

- [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering): Brexによる言語モデルとプロンプトエンジニアリングの入門書。
- [learnprompting.org](https://learnprompting.org/): プロンプトエンジニアリングの入門コース。
- [Lil'Log Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/): OpenAI研究者によるプロンプトエンジニアリング文献のレビュー（2023年3月時点）。
- [OpenAI Cookbook: Techniques to improve reliability](https://cookbook.openai.com/articles/techniques_to_improve_reliability): 言語モデルのプロンプト技術に関するやや古い（2022年9月）レビュー。
- [promptingguide.ai](https://www.promptingguide.ai/): 多くの技術を実演するプロンプトエンジニアリングガイド。
- [Xavi Amatriain's Prompt Engineering 101 Introduction to Prompt Engineering](https://amatriain.net/blog/PromptEngineering)と[202 Advanced Prompt Engineering](https://amatriain.net/blog/prompt201): プロンプトエンジニアリングの基本的だが独自の見解による入門書と、CoTから始まる多くの高度な手法を含むフォローアップコレクション。

## ビデオコース

- [Andrew Ng's DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): 開発者向けプロンプトエンジニアリングの短期コース。
- [Andrej Karpathy's Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY): GPTの基盤となる機械学習の詳細な解説。
- [Prompt Engineering by DAIR.AI](https://www.youtube.com/watch?v=dOxUroR57xs): 様々なプロンプトエンジニアリング技術に関する1時間のビデオ。
- [Scrimba course about Assistants API](https://scrimba.com/learn/openaiassistants): Assistants APIに関する30分のインタラクティブコース。
- [LinkedIn course: Introduction to Prompt Engineering: How to talk to the AIs](https://www.linkedin.com/learning/prompt-engineering-how-to-talk-to-the-ais/talking-to-the-ais?u=0): プロンプトエンジニアリングの短いビデオ入門。

## 推論改善のための高度なプロンプトに関する論文

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022)](https://arxiv.org/abs/2201.11903): few-shotプロンプトを使用してモデルに段階的に考えるよう求めることで推論が改善される。PaLMの数学文章問題（GSM8K）のスコアが18%から57%に上昇。
- [Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022)](https://arxiv.org/abs/2203.11171): 複数の出力からの投票により精度がさらに向上。40の出力での投票により、PaLMの数学文章問題のスコアが57%から74%に、`code-davinci-002`が60%から78%に上昇。
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models (2023)](https://arxiv.org/abs/2305.10601): 段階的推論の木を探索することで、思考の連鎖での投票よりもさらに効果的。`GPT-4`の創作文章とクロスワードのスコアが向上。
- [Language Models are Zero-Shot Reasoners (2022)](https://arxiv.org/abs/2205.11916): 指示に従うモデルに段階的に考えるよう伝えることで推論が改善。`text-davinci-002`の数学文章問題（GSM8K）のスコアが13%から41%に上昇。
- [Large Language Models Are Human-Level Prompt Engineers (2023)](https://arxiv.org/abs/2211.01910): 可能なプロンプトの自動探索により、数学文章問題（GSM8K）のスコアを43%に押し上げるプロンプトを発見。これは「Language Models are Zero-Shot Reasoners」の人間が書いたプロンプトより2ポイント上。
- [Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (2023)](https://arxiv.org/abs/2305.09993): 可能な思考の連鎖プロンプトの自動探索により、ChatGPTのいくつかのベンチマークでのスコアが0-20ポイント改善。
- [Faithful Reasoning Using Large Language Models (2022)](https://arxiv.org/abs/2208.14271): 推論は以下を組み合わせたシステムにより改善可能：代替選択と推論プロンプトによって生成された思考の連鎖、選択-推論ループの停止時期を選択するハルターモデル、複数の推論パスを探索する価値関数、幻覚を避けるのに役立つ文ラベル。
- [STaR: Bootstrapping Reasoning With Reasoning (2022)](https://arxiv.org/abs/2203.14465): 思考の連鎖推論はファインチューニングによりモデルに組み込める。答えキーがあるタスクでは、思考の連鎖の例を言語モデルで生成可能。
- [ReAct: Synergizing Reasoning and Acting in Language Models (2023)](https://arxiv.org/abs/2210.03629): ツールや環境があるタスクでは、**Re**asoning（何をするかを考える）ステップと**Act**ing（ツールや環境から情報を得る）を規定的に交互に行うと思考の連鎖がより効果的。
- [Reflexion: an autonomous agent with dynamic memory and self-reflection (2023)](https://arxiv.org/abs/2303.11366): 過去の失敗の記憶を持ってタスクを再試行することで、その後のパフォーマンスが向上。
- [Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (2023)](https://arxiv.org/abs/2212.14024): 「検索してから読む」により知識で拡張されたモデルは、マルチホップ検索の連鎖で改善可能。
- [Improving Factuality and Reasoning in Language Models through Multiagent Debate (2023)](https://arxiv.org/abs/2305.14325): 数ラウンドにわたる複数のChatGPTエージェント間での議論の生成により、様々なベンチマークのスコアが改善。数学文章問題のスコアが77%から85%に上昇。