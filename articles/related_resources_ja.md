# Web 上の関連リソース

人々は GPT の出力を改善するための優れたツールや論文を書いています。以下は、私たちが見たクールなものです：

## プロンプティングライブラリとツール（アルファベット順）

- [Arthur Shield](https://www.arthur.ai/get-started)：毒性、幻覚、プロンプトインジェクションなどを検出するための有料製品。
- [Baserun](https://baserun.ai/)：LLM ベースのアプリのテスト、デバッグ、監視のための有料製品。
- [Chainlit](https://docs.chainlit.io/overview)：チャットボットインターフェースを作成するための Python ライブラリ。
- [ElatoAI](https://github.com/akdeb/ElatoAI)：Deno Edge Runtime と Supabase を使用して、Arduino 上の ESP32 で OpenAI Realtime API Speech を実行するためのプラットフォーム。
- [Embedchain](https://github.com/embedchain/embedchain)：LLM で非構造化データを管理および同期するための Python ライブラリ。
- [FLAML (A Fast Library for Automated Machine Learning & Tuning)](https://microsoft.github.io/FLAML/docs/Getting-Started/)：モデル、ハイパーパラメータ、その他の調整可能な選択肢の選択を自動化するための Python ライブラリ。
- [Guidance](https://github.com/microsoft/guidance)：Handlebars テンプレートを使用して生成、プロンプティング、論理制御をインターリーブする、Microsoft の便利な Python ライブラリ。
- [Haystack](https://github.com/deepset-ai/haystack)：Python でカスタマイズ可能な本番環境対応の LLM アプリケーションを構築するためのオープンソース LLM オーケストレーションフレームワーク。
- [HoneyHive](https://honeyhive.ai)：LLM アプリを評価、デバッグ、監視するためのエンタープライズプラットフォーム。
- [LangChain](https://github.com/hwchase17/langchain)：言語モデルプロンプトのシーケンスをチェーンするための人気の Python/JavaScript ライブラリ。
- [LiteLLM](https://github.com/BerriAI/litellm)：一貫した形式で LLM API を呼び出すための最小限の Python ライブラリ。
- [LlamaIndex](https://github.com/jerryjliu/llama_index)：データで LLM アプリを拡張するための Python ライブラリ。
- [LLMOps Database](https://www.reddit.com/r/LocalLLaMA/comments/1h4u7au/a_nobs_database_of_how_companies_actually_deploy/)：企業が実際に本番環境で LLM をデプロイする方法のデータベース。
- [LMQL](https://lmql.ai)：型付きプロンプティング、制御フロー、制約、ツールをサポートする LLM インタラクション用のプログラミング言語。
- [OpenAI Evals](https://github.com/openai/evals)：言語モデルとプロンプトのタスクパフォーマンスを評価するためのオープンソースライブラリ。
- [Outlines](https://github.com/normal-computing/outlines)：プロンプティングを簡素化し、生成を制約するドメイン固有言語を提供する Python ライブラリ。
- [Parea AI](https://www.parea.ai)：LLM アプリのデバッグ、テスト、監視のためのプラットフォーム。
- [Portkey](https://portkey.ai/)：LLM アプリの観測可能性、モデル管理、評価、セキュリティのためのプラットフォーム。
- [Promptify](https://github.com/promptslab/Promptify)：言語モデルを使用して NLP タスクを実行するための小さな Python ライブラリ。
- [PromptPerfect](https://promptperfect.jina.ai/prompts)：プロンプトをテストおよび改善するための有料製品。
- [Prompttools](https://github.com/hegelai/prompttools)：モデル、ベクトル DB、プロンプトをテストおよび評価するためのオープンソース Python ツール。
- [Scale Spellbook](https://scale.com/spellbook)：言語モデルアプリを構築、比較、出荷するための有料製品。
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel)：プロンプトテンプレート、関数チェーン、ベクトル化されたメモリ、インテリジェントプランニングをサポートする Microsoft の Python/C#/Java ライブラリ。
- [Vellum](https://www.vellum.ai/)：高度な LLM アプリを実験、評価、デプロイするための有料 AI 製品開発プラットフォーム。
- [Weights & Biases](https://wandb.ai/site/solutions/llmops)：モデルトレーニングとプロンプトエンジニアリング実験を追跡するための有料製品。
- [YiVal](https://github.com/YiVal/YiVal)：カスタマイズ可能なデータセット、評価方法、進化戦略を使用して、プロンプト、検索構成、モデルパラメータを調整および評価するためのオープンソース GenAI-Ops ツール。

## プロンプティングガイド

- [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering)：Brex による言語モデルとプロンプトエンジニアリングの入門。
- [learnprompting.org](https://learnprompting.org/)：プロンプトエンジニアリングの入門コース。
- [Lil'Log Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)：OpenAI 研究者によるプロンプトエンジニアリング文献のレビュー（2023年3月時点）。
- [OpenAI Cookbook: Techniques to improve reliability](https://cookbook.openai.com/articles/techniques_to_improve_reliability)：言語モデルのプロンプティング技術に関するやや古い（2022年9月）レビュー。
- [promptingguide.ai](https://www.promptingguide.ai/)：多くの技術を実証するプロンプトエンジニアリングガイド。
- [Xavi Amatriain's Prompt Engineering 101 Introduction to Prompt Engineering](https://amatriain.net/blog/PromptEngineering) と [202 Advanced Prompt Engineering](https://amatriain.net/blog/prompt201)：プロンプトエンジニアリングの基本的だが意見のある入門と、CoT から始まる多くの高度な方法を含むフォローアップコレクション。

## ビデオコース

- [Andrew Ng's DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)：開発者向けのプロンプトエンジニアリングに関する短期コース。
- [Andrej Karpathy's Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)：GPT の基礎となる機械学習への詳細な探求。
- [Prompt Engineering by DAIR.AI](https://www.youtube.com/watch?v=dOxUroR57xs)：さまざまなプロンプトエンジニアリング技術に関する1時間のビデオ。
- [Scrimba course about Assistants API](https://scrimba.com/learn/openaiassistants)：Assistants API に関する30分のインタラクティブコース。
- [LinkedIn course: Introduction to Prompt Engineering: How to talk to the AIs](https://www.linkedin.com/learning/prompt-engineering-how-to-talk-to-the-ais/talking-to-the-ais?u=0)：プロンプトエンジニアリングへの短いビデオ入門。

## 推論を改善するための高度なプロンプティングに関する論文

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022)](https://arxiv.org/abs/2201.11903)：few-shot プロンプトを使用してモデルにステップバイステップで考えるように依頼すると、推論が改善されます。PaLM の数学の文章題（GSM8K）のスコアは18%から57%に上昇します。
- [Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022)](https://arxiv.org/abs/2203.11171)：複数の出力から投票を取ることで、精度がさらに向上します。40の出力にわたる投票により、PaLM の数学の文章題のスコアは57%から74%に、`code-davinci-002` のスコアは60%から78%に上昇します。
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models (2023)](https://arxiv.org/abs/2305.10601)：ステップバイステップの推論のツリーを検索することは、思考の連鎖にわたる投票よりもさらに役立ちます。これにより、`GPT-4` のクリエイティブライティングとクロスワードのスコアが向上します。
- [Language Models are Zero-Shot Reasoners (2022)](https://arxiv.org/abs/2205.11916)：指示に従うモデルにステップバイステップで考えるように伝えると、推論が改善されます。これにより、`text-davinci-002` の数学の文章題（GSM8K）のスコアは13%から41%に上昇します。
- [Large Language Models Are Human-Level Prompt Engineers (2023)](https://arxiv.org/abs/2211.01910)：可能なプロンプトの自動検索により、数学の文章題（GSM8K）のスコアを43%に引き上げるプロンプトが見つかり、Language Models are Zero-Shot Reasoners の人間が書いたプロンプトより2パーセントポイント高くなります。
- [Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling (2023)](https://arxiv.org/abs/2305.09993)：可能な思考の連鎖プロンプトの自動検索により、ChatGPT のいくつかのベンチマークでのスコアが0〜20パーセントポイント改善されました。
- [Faithful Reasoning Using Large Language Models (2022)](https://arxiv.org/abs/2208.14271)：推論は、代替選択と推論プロンプトによって生成された思考の連鎖、選択-推論ループを停止するタイミングを選択する停止モデル、複数の推論パスを検索する価値関数、幻覚を避けるのに役立つ文ラベルを組み合わせたシステムによって改善できます。
- [STaR: Bootstrapping Reasoning With Reasoning (2022)](https://arxiv.org/abs/2203.14465)：思考の連鎖推論は、ファインチューニングを介してモデルに組み込むことができます。答えのキーがあるタスクの場合、思考の連鎖の例は言語モデルによって生成できます。
- [ReAct: Synergizing Reasoning and Acting in Language Models (2023)](https://arxiv.org/abs/2210.03629)：ツールや環境があるタスクの場合、**Re**asoning ステップ（何をすべきかを考える）と **Act**ing（ツールや環境から情報を取得する）を規定的に交互に行うと、思考の連鎖がより効果的に機能します。
- [Reflexion: an autonomous agent with dynamic memory and self-reflection (2023)](https://arxiv.org/abs/2303.11366)：以前の失敗の記憶を持ってタスクを再試行すると、その後のパフォーマンスが向上します。
- [Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP (2023)](https://arxiv.org/abs/2212.14024)：「retrieve-then-read」を介して知識で拡張されたモデルは、マルチホップ検索のチェーンで改善できます。
- [Improving Factuality and Reasoning in Language Models through Multiagent Debate (2023)](https://arxiv.org/abs/2305.14325)：数ラウンドにわたって数人の ChatGPT エージェント間で議論を生成すると、さまざまなベンチマークでスコアが向上します。数学の文章題のスコアは77%から85%に上昇します。

